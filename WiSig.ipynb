{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities Functions"
      ],
      "metadata": {
        "id": "XGHPnr95xZ5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_from_full_dataset(full_dataset_path, capture_date,rx_name,prefix=None):\n",
        "    src=full_dataset_path\n",
        "\n",
        "    if prefix is None: \n",
        "        dataset_path = '{}pkl_wifi_{}/dataset_{}_node{}.pkl'.format(src,capture_date,capture_date,rx_name)\n",
        "    else:\n",
        "        dataset_path = '{}pkl_wifi_{}_{}/dataset_{}_node{}.pkl'.format(src,prefix,capture_date,capture_date,rx_name)\n",
        "   \n",
        "    if os.path.isfile(dataset_path) :\n",
        "        with open(dataset_path,'rb') as f:\n",
        "            dataset = pickle.load(f)\n",
        "    else:\n",
        "            dataset = None\n",
        "#             print('Not Found')\n",
        "#             print(dataset_path)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_compact_pkl_dataset(dataset_path,dataset_name):\n",
        "    with open(dataset_path+dataset_name+'.pkl','rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def shuffle(vec1,vec2,seed = 0):\n",
        "    np.random.seed(0)\n",
        "#     print(vec1.shape[0],vec2.shape[0])\n",
        "    shfl_indx = np.arange(vec1.shape[0])\n",
        "    np.random.shuffle(shfl_indx)\n",
        "    shfl_indx = shfl_indx.astype('int')\n",
        "    vec1 = vec1[shfl_indx]\n",
        "    vec2 = np.copy(vec2[shfl_indx])\n",
        "    return vec1,vec2\n",
        "\n",
        "\n",
        "def norm(sig_u):\n",
        "    if len(sig_u.shape)==3:\n",
        "        pwr = np.sqrt(np.mean(np.sum(sig_u**2,axis = -1),axis = -1))\n",
        "        sig_u = sig_u/pwr[:,None,None]\n",
        "    if len(sig_u.shape)==2:\n",
        "        pwr =  np.sqrt(np.mean(np.sum(sig_u**2,axis = -1),axis = -1))\n",
        "        sig_u = sig_u/pwr\n",
        "    # print(sig_u.shape)\n",
        "    return sig_u\n",
        "\n",
        "def split3(vec,n1,n2):\n",
        "    vec1 = vec[0:n1]\n",
        "    vec2 = vec[n1:n1+n2]\n",
        "    vec3 = vec[n1+n2:]\n",
        "    return vec3,vec1,vec2\n",
        "\n",
        "def split_set3(st,f1,f2):\n",
        "    [sig,txid] = st\n",
        "\n",
        "    n_samples  = sig.shape[0]\n",
        "    n1 = int(f1*n_samples)\n",
        "    n2 = int(f2*n_samples)\n",
        "\n",
        "    sig1,sig2,sig3 = split3(sig,n1,n2)\n",
        "    txid1,txid2,txid3 = split3(txid,n1,n2)\n",
        "    st1 = [sig1,txid1]\n",
        "    st2 = [sig2,txid2]\n",
        "    st3 = [sig3,txid3]\n",
        "    return st1,st2,st3 \n",
        "\n",
        "def get_node_indices(tx_name_list,node_name_list):\n",
        "    op_list = []\n",
        "    for tx in tx_name_list:\n",
        "        if tx in node_name_list:\n",
        "            op_list.append(node_name_list.index(tx))\n",
        "        else:\n",
        "            op_list.append(None)\n",
        "    return op_list\n",
        "    \n",
        "def parse_nodes(dataset,node_list,seed = 0):\n",
        "    cat_sig = []\n",
        "    cat_txid = []\n",
        "    data = dataset['data']\n",
        "    \n",
        "    \n",
        "    for i,node in enumerate(node_list):\n",
        "        if (not node  is  None) and  node < len(data):\n",
        "            cat_sig.append(data[node])\n",
        "            cat_txid.append(np.ones( (data[node].shape[0]) )*i)\n",
        "    cat_sig = np.concatenate(cat_sig)\n",
        "    cat_txid = np.concatenate(cat_txid)\n",
        "    np.random.seed(seed)\n",
        "    cat_sig,cat_txid = shuffle(cat_sig,cat_txid)\n",
        "    cat_sig = norm(cat_sig)\n",
        "    return (cat_sig,cat_txid)\n",
        "\n",
        "def to_categorical(y, num_classes=None, dtype='float32'):\n",
        "    y = np.array(y, dtype='int')\n",
        "    input_shape = y.shape\n",
        "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
        "        input_shape = tuple(input_shape[:-1])\n",
        "    y = y.ravel()\n",
        "    if not num_classes:\n",
        "        num_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    output_shape = input_shape + (num_classes,)\n",
        "    categorical = np.reshape(categorical, output_shape)\n",
        "    return categorical\n",
        "\n",
        "def prepare_txid_and_weights(st,n):\n",
        "    sig,txid = st\n",
        "    txid_oh = to_categorical(txid,n)\n",
        "    stat= np.sum(txid_oh,axis=0)\n",
        "    cls_weights = np.max(stat,axis=0)/stat \n",
        "    cls_weights = cls_weights.tolist()\n",
        "    augset = [sig,txid,txid_oh,cls_weights]\n",
        "    return augset\n",
        "\n",
        "def prepare_dataset(dataset,tx_name_list,val_frac=0.1, test_frac=0.1):\n",
        "    tx_list = get_node_indices(tx_name_list,dataset['node_list'])\n",
        "    all_set = parse_nodes(dataset,tx_list,seed = 0)\n",
        "    train_set,val_set,test_set = split_set3(all_set,val_frac, test_frac)\n",
        "    train_augset = prepare_txid_and_weights(train_set,len(tx_list))\n",
        "    val_augset = prepare_txid_and_weights(val_set,len(tx_list))\n",
        "    test_augset = prepare_txid_and_weights(test_set,len(tx_list))\n",
        "    return train_augset,val_augset,test_augset\n",
        "\n",
        "\n",
        "def create_dataset_impl(tx_list,rx_list,capture_date_list,max_sig=None,equalized_list=[0],full_dataset_path = 'data/',op_dataset_file = None):\n",
        "    dataset = {}\n",
        "    dataset['tx_list'] = tx_list\n",
        "    dataset['rx_list'] = rx_list\n",
        "    dataset['capture_date_list']=capture_date_list\n",
        "    dataset['equalized_list'] = equalized_list\n",
        "    dataset['max_sig'] = max_sig\n",
        "    \n",
        "    n_tx = len(tx_list)\n",
        "    n_rx = len(rx_list)\n",
        "    n_day = len(capture_date_list)\n",
        "    n_eq = len(equalized_list)\n",
        "    \n",
        "    prefix_lut = [None,'eq']\n",
        "    \n",
        "    prefix_list = [prefix_lut[tt] for tt in  equalized_list]\n",
        "    \n",
        "    dataset['data'] = [ [ [ [ [ ] for _ in range(n_eq)] for _ in range(n_day) ] for _ in range(n_rx) ]  for _ in range(n_tx)     ]\n",
        "    \n",
        "    \n",
        "    missing_rx_dict = {}\n",
        "    \n",
        "    missing_files = False\n",
        "\n",
        "    \n",
        "    with open('IdSig_info.pkl','rb') as f:\n",
        "        IdSig_info=pickle.load(f)\n",
        "    \n",
        "    slc = slice(None,max_sig)\n",
        "    for day_i,capture_date in enumerate(capture_date_list):\n",
        "        for rx_i,rx_train in enumerate(rx_list):\n",
        "            for eq_i,prefix in enumerate(prefix_list):\n",
        "                tdataset = load_from_full_dataset(full_dataset_path,capture_date,rx_train,prefix=prefix)\n",
        "                if not tdataset is None:\n",
        "                    for tx_i,tx in enumerate(tx_list):\n",
        "                        if tx in tdataset['node_list']:\n",
        "                            tx_indx = tdataset['node_list'].index(tx)\n",
        "                            dataset['data'][tx_i][rx_i][day_i][eq_i]= tdataset['data'][tx_indx][slc]  \n",
        "                        else:\n",
        "                            dataset['data'][tx_i][rx_i][day_i][eq_i]=np.zeros((0,256,2))\n",
        "                else:\n",
        "                    missing_rx_name =rx_list[rx_i]  \n",
        "                    eq_val = equalized_list[eq_i]\n",
        "                    IdSig_info_sub  = IdSig_info[eq_val][capture_date]\n",
        "                    if missing_rx_name  in IdSig_info_sub.keys():\n",
        "                            missing_files = True\n",
        "                            if not eq_val in  missing_rx_dict.keys():\n",
        "                                missing_rx_dict[eq_val]={}\n",
        "                            if not capture_date in  missing_rx_dict[eq_val].keys():\n",
        "                                missing_rx_dict[eq_val][capture_date]=[]\n",
        "                            missing_rx_info  = IdSig_info_sub[missing_rx_name]\n",
        "                            missing_rx_dict[eq_val][capture_date].append(   (missing_rx_info['name'], missing_rx_info['link'],missing_rx_info['size']) )\n",
        "\n",
        "    \n",
        "    if missing_files:\n",
        "        ii=1\n",
        "        total_file_sizes = 0\n",
        "        print('You have missing files that you need to download.')\n",
        "        \n",
        "        for eq_k  in missing_rx_dict.keys():  \n",
        "            if len(missing_rx_dict[eq_val])>0:\n",
        "                print('')\n",
        "                if eq_k==0:\n",
        "                    print('You need to download the following files for the non equalized dataset')\n",
        "                else:\n",
        "                    print('You need to download the following files for the equalized dataset')\n",
        "                \n",
        "                print('')\n",
        "                \n",
        "                for date_k  in missing_rx_dict[eq_k].keys():  \n",
        "                    for missing_rx in missing_rx_dict[eq_val][date_k]:\n",
        "                        print('{}) Name: {} , Size: {} MB'.format(ii,missing_rx[0],missing_rx[2]/1e6))\n",
        "                        total_file_sizes=total_file_sizes+missing_rx[2]\n",
        "                        ii=ii+1\n",
        "                print('Links:')\n",
        "                for date_k  in missing_rx_dict[eq_k].keys():  \n",
        "                    for missing_rx in missing_rx_dict[eq_val][date_k]:\n",
        "                        print('https://drive.google.com/u/0/uc?export=download&id={}'.format(missing_rx[1]))               \n",
        "        print('')\n",
        "        print('You need to dowlnoad {} GB'.format(total_file_sizes/1e9))\n",
        "        print('Note the following:')\n",
        "        print('1) The non-equalized and eqalized files need to be downloaded in different fodlers because they share the same exact names')\n",
        "        print('2) The  non-equalized folders needs to be grouped by date and equalization using the same structure as the following google drive folder')\n",
        "        print('https://drive.google.com/drive/folders/1r8cd4zZ7fwvN_iiyI_uDKbIFGZve49lw?usp=sharing')\n",
        "        print('3) If you have already downloaded the files make sure that the full dataset path is configured correctly.')\n",
        "        dataset = None\n",
        "    else:\n",
        "        if not op_dataset_file is None:\n",
        "            with open(op_dataset_file,'wb') as f:\n",
        "                pickle.dump(dataset,f)\n",
        "                print('Dataset saved in {}'.format(op_dataset_file))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_list,max_sig=None,equalized=0):\n",
        "    dataset = {}\n",
        "    dataset['node_list'] = tx_list\n",
        "    dataset['data'] = [ () for _ in range(len(tx_list))]\n",
        "    \n",
        "    if not type(capture_date) is list: \n",
        "        capture_date_list = [capture_date]\n",
        "    else:\n",
        "        capture_date_list = capture_date\n",
        "    slc = slice(None,max_sig)\n",
        "    for capture_date in capture_date_list:\n",
        "        for rx_train in rx_list:\n",
        "            for indx,tx in enumerate(tx_list):\n",
        "                tx_i=compact_dataset['tx_list'].index(tx)\n",
        "                rx_i=compact_dataset['rx_list'].index(rx_train)\n",
        "                date_i=compact_dataset['capture_date_list'].index(capture_date)\n",
        "                eq_i=compact_dataset['equalized_list'].index(equalized)\n",
        "                dataset['data'][indx]  +=  (compact_dataset['data'][tx_i][rx_i][date_i][eq_i][slc],)\n",
        "    for indx in range(len(tx_list)):\n",
        "        if len(dataset['data'][indx])>0:\n",
        "            dataset['data'][indx] =  np.concatenate(dataset['data'][indx])\n",
        "        else:\n",
        "            dataset['data'][indx] =np.zeros((0,256,2))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "6U6A7mWsxYPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "AHdL7PFfxieU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioakfsp4teKh",
        "outputId": "105ad1b9-2f2f-440a-e10d-916a8fa32e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import scipy,scipy.spatial\n",
        "import matplotlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/ManyRx.pkl.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "metadata": {
        "id": "REjUQSlQu9Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_compact_pkl_dataset(dataset_path,dataset_name):\n",
        "    with open(dataset_path+dataset_name+'.pkl','rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    return dataset\n",
        "\n",
        "compact_dataset = load_compact_pkl_dataset(\"./\",\"ManyRx\")\n",
        "\n",
        "tx_list = compact_dataset['tx_list']\n",
        "rx_list = compact_dataset['rx_list']\n",
        "\n",
        "equalized = 0\n",
        "\n",
        "capture_date_list = compact_dataset['capture_date_list']\n",
        "capture_date = capture_date_list[0]\n",
        "n_tx = len(tx_list)\n",
        "n_rx = len(rx_list)\n",
        "print(n_tx,n_rx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06y2qsqnuasY",
        "outputId": "ef2ba868-4383-42fa-982b-c9c5177fed07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compact_dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiI8yA2vcUc",
        "outputId": "f55cce86-e577-49ce-c247-7c0d4176c2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tx_list', 'rx_list', 'capture_date_list', 'equalized_list', 'max_sig', 'data'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "n_real = 5\n",
        "rx_list_real = []\n",
        "for i in range(n_real):\n",
        "    np.random.shuffle(rx_list)\n",
        "    rx_list_real.append(np.copy(rx_list).tolist())\n",
        "print(rx_list_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ikdXBivkhR",
        "outputId": "1f2766a6-f56e-4838-e93e-5e623d997937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['19-20', '24-13', '19-2', '1-20', '20-20', '20-1', '7-7', '3-19', '23-6', '2-19', '24-5', '14-7', '23-1', '19-1', '8-7', '24-6', '24-16', '1-19', '8-8', '18-19', '13-7', '23-3', '8-14', '23-5', '19-19', '18-2', '7-14', '13-14', '1-1', '23-7', '20-19', '2-1'], ['1-1', '23-1', '24-6', '8-8', '1-19', '23-3', '23-5', '7-14', '19-19', '13-14', '23-6', '7-7', '19-1', '20-1', '20-20', '24-16', '8-14', '19-2', '14-7', '1-20', '13-7', '24-5', '18-2', '2-19', '24-13', '19-20', '3-19', '8-7', '20-19', '2-1', '23-7', '18-19'], ['24-5', '23-7', '18-19', '23-3', '24-6', '8-14', '2-1', '13-7', '19-19', '19-2', '18-2', '1-20', '20-1', '24-16', '3-19', '1-19', '24-13', '23-6', '19-1', '8-7', '20-19', '1-1', '14-7', '20-20', '7-7', '2-19', '23-5', '8-8', '19-20', '13-14', '7-14', '23-1'], ['1-20', '1-19', '20-19', '23-7', '2-1', '20-1', '19-19', '14-7', '23-1', '3-19', '8-8', '7-7', '13-7', '20-20', '24-16', '18-2', '8-7', '23-5', '7-14', '18-19', '24-6', '19-1', '13-14', '2-19', '19-20', '24-5', '23-3', '19-2', '8-14', '23-6', '24-13', '1-1'], ['18-19', '20-1', '13-14', '18-2', '14-7', '20-20', '13-7', '19-20', '2-19', '19-19', '19-1', '1-20', '24-5', '20-19', '8-7', '23-1', '7-7', '8-8', '2-1', '1-19', '3-19', '23-3', '23-6', '23-5', '24-6', '8-14', '24-16', '7-14', '1-1', '19-2', '24-13', '23-7']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "xl_wGK6twy2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_net():\n",
        "\n",
        "    inputs = Input(shape=(256,2))\n",
        "    x = Reshape((256,2,1))(inputs)\n",
        "    x = Conv2D(8,(3,2),activation='relu',padding = 'same')(x)\n",
        "    x = MaxPool2D((2,1))(x)\n",
        "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
        "    x = MaxPool2D((2,1))(x)\n",
        "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
        "    x = MaxPool2D((2,2))(x)\n",
        "    x = Conv2D(32,(3,1),activation='relu',padding = 'same')(x)\n",
        "    x = MaxPool2D((2,1))(x)\n",
        "    x = Conv2D(16,(3,1),activation='relu',padding = 'same')(x)\n",
        "    #x = resnet(x,64,(3,2),'6')\n",
        "    #x = MaxPool2D((2,2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "\n",
        "\n",
        "    x = Dense(100, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    x = Dense(80, activation='relu',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(n_tx, activation='softmax',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    ops = x\n",
        "\n",
        "    classifier = Model(inputs,ops)\n",
        "    classifier.compile(loss='categorical_crossentropy',metrics=['categorical_accuracy'],optimizer=keras.optimizers.Adam(0.0005))\n",
        "    \n",
        "    return classifier\n",
        "\n",
        "classifier = create_net()\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk4QxIuTw2TO",
        "outputId": "b38e7478-338e-4758-e9c7-afb7219d6789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 2)]          0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 256, 2, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 2, 8)         56        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 2, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2, 16)        784       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 2, 16)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 2, 16)         1552      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 1, 16)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 1, 32)         1568      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 1, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 1, 16)         1552      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               25700     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 80)                8080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 80)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,102\n",
            "Trainable params: 40,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(classifier):\n",
        "    pred = classifier.predict(sig_dfTest)\n",
        "    acc = np.mean(np.argmax(pred,1)==txidNum_dfTest)\n",
        "\n",
        "    test_indx = ()\n",
        "    for indx in range(len(tx_list)):\n",
        "        cls_indx = np.where(txidNum_dfTest == indx)\n",
        "        test_indx = test_indx + (cls_indx[0][:n_test_samples],)\n",
        "    test_indx = np.concatenate(test_indx) \n",
        "    acc_bal = np.mean(np.argmax(pred[test_indx,:],1)==txidNum_dfTest[test_indx])\n",
        "    return acc,acc_bal"
      ],
      "metadata": {
        "id": "nay21tfQw68X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test_rx = 5"
      ],
      "metadata": {
        "id": "a-kavuVYxD72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights"
      ],
      "metadata": {
        "id": "A3Onf_eF2Yix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "-bYoPE9b3ECj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True\n",
        "continue_training = True\n",
        "nreal = 5\n",
        "\n",
        "real_list = list(range(nreal))\n",
        "nrx_list =  list(range( 0,len(rx_list_real[0])-n_test_rx+1,5))  # [0,len(rx_list_real[0])-1] #\n",
        "\n",
        "patience = 5\n",
        "n_epochs = 100\n",
        "\n",
        "smTest_results = []\n",
        "dfTest_results = []\n",
        "dfTestBal_results = []\n",
        "\n",
        "for real in real_list:\n",
        "    rx_list = rx_list_real[real]\n",
        "    rx_test_list = rx_list[-n_test_rx:]\n",
        "    test_dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_test_list)\n",
        "    test_augset_dfRx,_,_ = prepare_dataset(test_dataset,tx_list,val_frac=0.0, test_frac=0.0)\n",
        "\n",
        "    [sig_dfTest,txidNum_dfTest,txid_dfTest,cls_weights] = test_augset_dfRx\n",
        "    \n",
        "    cnt=np.histogram(txidNum_dfTest,bins=np.arange(len(tx_list)+1)-0.5)\n",
        "    n_test_samples = int(np.min(cnt[0]))\n",
        "\n",
        "    smTest_results_real = []\n",
        "    dfTest_results_real = []\n",
        "    dfTestBal_results_real = []\n",
        "    for nrx in nrx_list:\n",
        "        print(\"\");print(\"\")\n",
        "        print(\"nrx: {} - real: {} \".format(nrx,real))\n",
        "        fname_w = 'weights/d003_{:02d}_{:02d}.hd5'.format(nrx,real)\n",
        "        rx_train_list= rx_list[:nrx+1]\n",
        "\n",
        "        dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_train_list)\n",
        "\n",
        "        train_augset,val_augset,test_augset_smRx =  prepare_dataset(dataset,tx_list,\n",
        "                                                            val_frac=0.1, test_frac=0.1)\n",
        "        [sig_train,txidNum_train,txid_train,cls_weights] = train_augset\n",
        "        [sig_valid,txidNum_valid,txid_valid,_] = val_augset\n",
        "        [sig_smTest,txidNum_smTest,txid_smTest,cls_weights] = test_augset_smRx\n",
        "        \n",
        "        spl_weights = np.zeros((len(sig_train)))\n",
        "        for index in range(len(txid_train)):\n",
        "          spl_weights[index] = cls_weights[np.argmax(txid_train[index])]\n",
        "\n",
        "\n",
        "        if continue_training:\n",
        "            skip = os.path.isfile(fname_w)\n",
        "        else:\n",
        "            skip = False\n",
        "        classifier = create_net()\n",
        "        if TRAIN and not skip:\n",
        "            filepath = 't_weights_0'\n",
        "            c=[ keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "              keras.callbacks.EarlyStopping(monitor='val_loss',  patience=patience)]\n",
        "            #history = classifier.fit(sig_train,txid_train,class_weight=cls_weights,validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs)\n",
        "            history = classifier.fit(sig_train,txid_train,sample_weight=spl_weights,\n",
        "                                     validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs, verbose=2)\n",
        "            classifier.load_weights(filepath)\n",
        "            classifier.save_weights(fname_w,save_format=\"h5\")\n",
        "        else:\n",
        "            classifier.load_weights(fname_w)\n",
        "\n",
        "        smTest_r = classifier.evaluate(sig_smTest,txid_smTest,verbose=0)[1]\n",
        "    #     dfTest_r = classifier.evaluate(sig_dfTest,txid_dfTest)[1]\n",
        "        dfTest_r,dfTestBal_r = evaluate_test(classifier)\n",
        "\n",
        "        print(smTest_r,dfTest_r)\n",
        "        smTest_results_real.append(smTest_r)\n",
        "        dfTest_results_real.append(dfTest_r)\n",
        "        dfTestBal_results_real.append(dfTestBal_r)\n",
        "        K.clear_session()\n",
        "    smTest_results.append(smTest_results_real)\n",
        "    dfTest_results.append(dfTest_results_real)\n",
        "    dfTestBal_results.append(dfTestBal_results_real)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE952-bIxID7",
        "outputId": "6fa87a8a-b68d-439a-c336-cda70c2ce033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e7494fe5acc6>:119: RuntimeWarning: invalid value encountered in true_divide\n",
            "  cls_weights = np.max(stat,axis=0)/stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "nrx: 0 - real: 0 \n",
            "313/313 [==============================] - 4s 11ms/step\n",
            "0.9649999737739563 0.1343\n",
            "\n",
            "\n",
            "nrx: 5 - real: 0 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9161016941070557 0.2622\n",
            "\n",
            "\n",
            "nrx: 10 - real: 0 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9353210926055908 0.3665\n",
            "\n",
            "\n",
            "nrx: 15 - real: 0 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9270700812339783 0.468\n",
            "\n",
            "\n",
            "nrx: 20 - real: 0 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9065533876419067 0.6142\n",
            "\n",
            "\n",
            "nrx: 25 - real: 0 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9243597388267517 0.7225\n",
            "\n",
            "\n",
            "nrx: 0 - real: 1 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "1.0 0.1714\n",
            "\n",
            "\n",
            "nrx: 5 - real: 1 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9666666388511658 0.2513\n",
            "\n",
            "\n",
            "nrx: 10 - real: 1 \n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "0.9624999761581421 0.4348\n",
            "\n",
            "\n",
            "nrx: 15 - real: 1 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.948051929473877 0.5921\n",
            "\n",
            "\n",
            "nrx: 20 - real: 1 \n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "0.9211443066596985 0.8031\n",
            "\n",
            "\n",
            "nrx: 25 - real: 1 \n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "0.9160853028297424 0.6118\n",
            "\n",
            "\n",
            "nrx: 0 - real: 2 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9950000047683716 0.16040816326530613\n",
            "\n",
            "\n",
            "nrx: 5 - real: 2 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9622806906700134 0.22969387755102041\n",
            "\n",
            "\n",
            "nrx: 10 - real: 2 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9206424355506897 0.3245918367346939\n",
            "\n",
            "\n",
            "nrx: 15 - real: 2 \n",
            "307/307 [==============================] - 3s 9ms/step\n",
            "0.9428014159202576 0.40714285714285714\n",
            "\n",
            "\n",
            "nrx: 20 - real: 2 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9212656617164612 0.6733673469387755\n",
            "\n",
            "\n",
            "nrx: 25 - real: 2 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9292070269584656 0.5823469387755102\n",
            "\n",
            "\n",
            "nrx: 0 - real: 3 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e7494fe5acc6>:119: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  cls_weights = np.max(stat,axis=0)/stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9833333492279053 0.17704081632653063\n",
            "\n",
            "\n",
            "nrx: 5 - real: 3 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9612069129943848 0.26112244897959186\n",
            "\n",
            "\n",
            "nrx: 10 - real: 3 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9523584842681885 0.22642857142857142\n",
            "\n",
            "\n",
            "nrx: 15 - real: 3 \n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9461020231246948 0.4223469387755102\n",
            "\n",
            "\n",
            "nrx: 20 - real: 3 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.46895, saving model to t_weights_0\n",
            "1015/1015 - 25s - loss: 2.0833 - categorical_accuracy: 0.2905 - val_loss: 1.4690 - val_categorical_accuracy: 0.4915 - 25s/epoch - 24ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.46895 to 1.14326, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 1.5263 - categorical_accuracy: 0.5081 - val_loss: 1.1433 - val_categorical_accuracy: 0.6125 - 21s/epoch - 21ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.14326 to 0.83015, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 1.2007 - categorical_accuracy: 0.6199 - val_loss: 0.8302 - val_categorical_accuracy: 0.7382 - 21s/epoch - 21ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.83015 to 0.59530, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.9038 - categorical_accuracy: 0.7323 - val_loss: 0.5953 - val_categorical_accuracy: 0.8134 - 21s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.59530 to 0.46052, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.6919 - categorical_accuracy: 0.7989 - val_loss: 0.4605 - val_categorical_accuracy: 0.8607 - 21s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.46052 to 0.37559, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.5664 - categorical_accuracy: 0.8411 - val_loss: 0.3756 - val_categorical_accuracy: 0.8960 - 21s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.37559 to 0.33276, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.4799 - categorical_accuracy: 0.8675 - val_loss: 0.3328 - val_categorical_accuracy: 0.9073 - 21s/epoch - 21ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.33276 to 0.32522, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.4296 - categorical_accuracy: 0.8817 - val_loss: 0.3252 - val_categorical_accuracy: 0.9086 - 21s/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.32522 to 0.28734, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.3848 - categorical_accuracy: 0.8957 - val_loss: 0.2873 - val_categorical_accuracy: 0.9196 - 21s/epoch - 21ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.28734\n",
            "1015/1015 - 19s - loss: 0.3574 - categorical_accuracy: 0.9046 - val_loss: 0.2941 - val_categorical_accuracy: 0.9201 - 19s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.28734 to 0.27430, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.3377 - categorical_accuracy: 0.9094 - val_loss: 0.2743 - val_categorical_accuracy: 0.9253 - 21s/epoch - 21ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.27430\n",
            "1015/1015 - 19s - loss: 0.3113 - categorical_accuracy: 0.9172 - val_loss: 0.2757 - val_categorical_accuracy: 0.9295 - 19s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 0.27430 to 0.24207, saving model to t_weights_0\n",
            "1015/1015 - 21s - loss: 0.3014 - categorical_accuracy: 0.9176 - val_loss: 0.2421 - val_categorical_accuracy: 0.9352 - 21s/epoch - 21ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.24207\n",
            "1015/1015 - 19s - loss: 0.2864 - categorical_accuracy: 0.9233 - val_loss: 0.2530 - val_categorical_accuracy: 0.9334 - 19s/epoch - 19ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.24207\n",
            "1015/1015 - 19s - loss: 0.2689 - categorical_accuracy: 0.9278 - val_loss: 0.2468 - val_categorical_accuracy: 0.9359 - 19s/epoch - 19ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.24207\n",
            "1015/1015 - 19s - loss: 0.2638 - categorical_accuracy: 0.9287 - val_loss: 0.2662 - val_categorical_accuracy: 0.9298 - 19s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.24207\n",
            "1015/1015 - 19s - loss: 0.2534 - categorical_accuracy: 0.9323 - val_loss: 0.2488 - val_categorical_accuracy: 0.9399 - 19s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.24207\n",
            "1015/1015 - 23s - loss: 0.2464 - categorical_accuracy: 0.9340 - val_loss: 0.2498 - val_categorical_accuracy: 0.9403 - 23s/epoch - 23ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9295045733451843 0.5076530612244898\n",
            "\n",
            "\n",
            "nrx: 25 - real: 3 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.44847, saving model to t_weights_0\n",
            "1265/1265 - 27s - loss: 2.0342 - categorical_accuracy: 0.2942 - val_loss: 1.4485 - val_categorical_accuracy: 0.5005 - 27s/epoch - 22ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.44847 to 1.08957, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 1.4814 - categorical_accuracy: 0.5184 - val_loss: 1.0896 - val_categorical_accuracy: 0.6334 - 26s/epoch - 21ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.08957 to 0.92257, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 1.1878 - categorical_accuracy: 0.6271 - val_loss: 0.9226 - val_categorical_accuracy: 0.6793 - 26s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.92257 to 0.65450, saving model to t_weights_0\n",
            "1265/1265 - 27s - loss: 0.9604 - categorical_accuracy: 0.7086 - val_loss: 0.6545 - val_categorical_accuracy: 0.7878 - 27s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.65450 to 0.53642, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.7832 - categorical_accuracy: 0.7668 - val_loss: 0.5364 - val_categorical_accuracy: 0.8363 - 26s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.53642 to 0.46661, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.6605 - categorical_accuracy: 0.8092 - val_loss: 0.4666 - val_categorical_accuracy: 0.8592 - 26s/epoch - 21ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.46661 to 0.37747, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.5679 - categorical_accuracy: 0.8389 - val_loss: 0.3775 - val_categorical_accuracy: 0.8873 - 26s/epoch - 21ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.37747 to 0.35632, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.4994 - categorical_accuracy: 0.8615 - val_loss: 0.3563 - val_categorical_accuracy: 0.8948 - 26s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.35632 to 0.32775, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.4561 - categorical_accuracy: 0.8735 - val_loss: 0.3277 - val_categorical_accuracy: 0.9053 - 26s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.32775 to 0.31584, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.4100 - categorical_accuracy: 0.8881 - val_loss: 0.3158 - val_categorical_accuracy: 0.9104 - 26s/epoch - 21ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.31584 to 0.30784, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.3822 - categorical_accuracy: 0.8956 - val_loss: 0.3078 - val_categorical_accuracy: 0.9136 - 26s/epoch - 20ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.30784 to 0.28249, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.3570 - categorical_accuracy: 0.9022 - val_loss: 0.2825 - val_categorical_accuracy: 0.9189 - 26s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 0.28249 to 0.27966, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.3375 - categorical_accuracy: 0.9079 - val_loss: 0.2797 - val_categorical_accuracy: 0.9166 - 26s/epoch - 21ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.27966\n",
            "1265/1265 - 24s - loss: 0.3191 - categorical_accuracy: 0.9142 - val_loss: 0.3050 - val_categorical_accuracy: 0.9098 - 24s/epoch - 19ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss improved from 0.27966 to 0.26550, saving model to t_weights_0\n",
            "1265/1265 - 25s - loss: 0.3089 - categorical_accuracy: 0.9161 - val_loss: 0.2655 - val_categorical_accuracy: 0.9268 - 25s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.26550 to 0.26470, saving model to t_weights_0\n",
            "1265/1265 - 25s - loss: 0.2939 - categorical_accuracy: 0.9202 - val_loss: 0.2647 - val_categorical_accuracy: 0.9290 - 25s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 0.26470 to 0.25733, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.2901 - categorical_accuracy: 0.9221 - val_loss: 0.2573 - val_categorical_accuracy: 0.9320 - 26s/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.25733 to 0.25220, saving model to t_weights_0\n",
            "1265/1265 - 26s - loss: 0.2733 - categorical_accuracy: 0.9270 - val_loss: 0.2522 - val_categorical_accuracy: 0.9316 - 26s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.25220\n",
            "1265/1265 - 24s - loss: 0.2669 - categorical_accuracy: 0.9275 - val_loss: 0.2656 - val_categorical_accuracy: 0.9308 - 24s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss improved from 0.25220 to 0.24079, saving model to t_weights_0\n",
            "1265/1265 - 25s - loss: 0.2562 - categorical_accuracy: 0.9312 - val_loss: 0.2408 - val_categorical_accuracy: 0.9351 - 25s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.24079\n",
            "1265/1265 - 23s - loss: 0.2488 - categorical_accuracy: 0.9325 - val_loss: 0.2548 - val_categorical_accuracy: 0.9363 - 23s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.24079\n",
            "1265/1265 - 23s - loss: 0.2444 - categorical_accuracy: 0.9342 - val_loss: 0.2432 - val_categorical_accuracy: 0.9363 - 23s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.24079\n",
            "1265/1265 - 27s - loss: 0.2420 - categorical_accuracy: 0.9355 - val_loss: 0.2428 - val_categorical_accuracy: 0.9353 - 27s/epoch - 21ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.24079\n",
            "1265/1265 - 23s - loss: 0.2306 - categorical_accuracy: 0.9387 - val_loss: 0.2755 - val_categorical_accuracy: 0.9338 - 23s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.24079\n",
            "1265/1265 - 24s - loss: 0.2353 - categorical_accuracy: 0.9369 - val_loss: 0.2475 - val_categorical_accuracy: 0.9395 - 24s/epoch - 19ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9428514838218689 0.4851020408163265\n",
            "\n",
            "\n",
            "nrx: 0 - real: 4 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e7494fe5acc6>:119: RuntimeWarning: invalid value encountered in true_divide\n",
            "  cls_weights = np.max(stat,axis=0)/stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.29756, saving model to t_weights_0\n",
            "50/50 - 4s - loss: 2.9755 - categorical_accuracy: 0.1250 - val_loss: 2.2976 - val_categorical_accuracy: 0.1200 - 4s/epoch - 86ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 2.29756 to 2.09984, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 2.8624 - categorical_accuracy: 0.1994 - val_loss: 2.0998 - val_categorical_accuracy: 0.3850 - 3s/epoch - 57ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 2.09984 to 1.49297, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 2.3109 - categorical_accuracy: 0.3688 - val_loss: 1.4930 - val_categorical_accuracy: 0.5550 - 3s/epoch - 56ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 1.49297 to 1.01063, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 1.7177 - categorical_accuracy: 0.4975 - val_loss: 1.0106 - val_categorical_accuracy: 0.7450 - 3s/epoch - 63ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 1.01063 to 0.71795, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 1.2190 - categorical_accuracy: 0.6350 - val_loss: 0.7179 - val_categorical_accuracy: 0.8400 - 3s/epoch - 56ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.71795 to 0.47820, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.8793 - categorical_accuracy: 0.7425 - val_loss: 0.4782 - val_categorical_accuracy: 0.8700 - 3s/epoch - 61ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.47820 to 0.31773, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.6635 - categorical_accuracy: 0.7969 - val_loss: 0.3177 - val_categorical_accuracy: 0.9100 - 3s/epoch - 58ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.31773 to 0.24528, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.4870 - categorical_accuracy: 0.8706 - val_loss: 0.2453 - val_categorical_accuracy: 0.9900 - 3s/epoch - 58ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.24528 to 0.16519, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.3776 - categorical_accuracy: 0.9062 - val_loss: 0.1652 - val_categorical_accuracy: 0.9900 - 3s/epoch - 55ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.16519 to 0.14834, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.2958 - categorical_accuracy: 0.9325 - val_loss: 0.1483 - val_categorical_accuracy: 0.9900 - 3s/epoch - 64ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.14834 to 0.10334, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.2233 - categorical_accuracy: 0.9613 - val_loss: 0.1033 - val_categorical_accuracy: 0.9900 - 3s/epoch - 56ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.10334 to 0.09023, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.2014 - categorical_accuracy: 0.9581 - val_loss: 0.0902 - val_categorical_accuracy: 0.9900 - 3s/epoch - 63ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.09023\n",
            "50/50 - 1s - loss: 0.1630 - categorical_accuracy: 0.9669 - val_loss: 0.1035 - val_categorical_accuracy: 0.9900 - 983ms/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss improved from 0.09023 to 0.08665, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.1725 - categorical_accuracy: 0.9669 - val_loss: 0.0866 - val_categorical_accuracy: 0.9850 - 3s/epoch - 56ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss improved from 0.08665 to 0.08352, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.1380 - categorical_accuracy: 0.9731 - val_loss: 0.0835 - val_categorical_accuracy: 0.9900 - 3s/epoch - 55ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.08352 to 0.07437, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.1350 - categorical_accuracy: 0.9719 - val_loss: 0.0744 - val_categorical_accuracy: 0.9900 - 3s/epoch - 63ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.07437\n",
            "50/50 - 1s - loss: 0.1101 - categorical_accuracy: 0.9844 - val_loss: 0.0869 - val_categorical_accuracy: 0.9900 - 960ms/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.07437 to 0.06961, saving model to t_weights_0\n",
            "50/50 - 3s - loss: 0.1072 - categorical_accuracy: 0.9831 - val_loss: 0.0696 - val_categorical_accuracy: 0.9900 - 3s/epoch - 56ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.06961\n",
            "50/50 - 1s - loss: 0.1017 - categorical_accuracy: 0.9862 - val_loss: 0.1020 - val_categorical_accuracy: 0.9800 - 999ms/epoch - 20ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.06961\n",
            "50/50 - 1s - loss: 0.0873 - categorical_accuracy: 0.9869 - val_loss: 0.0928 - val_categorical_accuracy: 0.9900 - 985ms/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.06961\n",
            "50/50 - 1s - loss: 0.0796 - categorical_accuracy: 0.9900 - val_loss: 0.0801 - val_categorical_accuracy: 0.9900 - 952ms/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.06961\n",
            "50/50 - 1s - loss: 0.0567 - categorical_accuracy: 0.9925 - val_loss: 0.0763 - val_categorical_accuracy: 0.9900 - 962ms/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.06961\n",
            "50/50 - 1s - loss: 0.0637 - categorical_accuracy: 0.9931 - val_loss: 0.0791 - val_categorical_accuracy: 0.9900 - 1s/epoch - 20ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9950000047683716 0.22163265306122448\n",
            "\n",
            "\n",
            "nrx: 5 - real: 4 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.84688, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 2.3590 - categorical_accuracy: 0.1983 - val_loss: 1.8469 - val_categorical_accuracy: 0.3934 - 8s/epoch - 28ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.84688 to 1.51170, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 1.8272 - categorical_accuracy: 0.3988 - val_loss: 1.5117 - val_categorical_accuracy: 0.4613 - 8s/epoch - 27ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.51170 to 1.22718, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 1.5206 - categorical_accuracy: 0.5013 - val_loss: 1.2272 - val_categorical_accuracy: 0.5888 - 7s/epoch - 25ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 1.22718 to 1.00167, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 1.2796 - categorical_accuracy: 0.5834 - val_loss: 1.0017 - val_categorical_accuracy: 0.6602 - 7s/epoch - 25ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 1.00167 to 0.87837, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 1.0946 - categorical_accuracy: 0.6473 - val_loss: 0.8784 - val_categorical_accuracy: 0.6899 - 8s/epoch - 26ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.87837 to 0.76340, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.9259 - categorical_accuracy: 0.7004 - val_loss: 0.7634 - val_categorical_accuracy: 0.7494 - 7s/epoch - 25ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.76340 to 0.61234, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.8055 - categorical_accuracy: 0.7400 - val_loss: 0.6123 - val_categorical_accuracy: 0.8012 - 7s/epoch - 25ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.61234 to 0.54763, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.6946 - categorical_accuracy: 0.7855 - val_loss: 0.5476 - val_categorical_accuracy: 0.8309 - 8s/epoch - 27ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.54763 to 0.45754, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.6258 - categorical_accuracy: 0.8042 - val_loss: 0.4575 - val_categorical_accuracy: 0.8717 - 8s/epoch - 26ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.45754 to 0.40860, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.5440 - categorical_accuracy: 0.8374 - val_loss: 0.4086 - val_categorical_accuracy: 0.8980 - 8s/epoch - 25ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.40860 to 0.37511, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.4864 - categorical_accuracy: 0.8576 - val_loss: 0.3751 - val_categorical_accuracy: 0.9057 - 8s/epoch - 26ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.37511 to 0.33974, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.4292 - categorical_accuracy: 0.8790 - val_loss: 0.3397 - val_categorical_accuracy: 0.9167 - 7s/epoch - 25ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 0.33974 to 0.32704, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.3876 - categorical_accuracy: 0.8924 - val_loss: 0.3270 - val_categorical_accuracy: 0.9142 - 8s/epoch - 27ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss improved from 0.32704 to 0.31674, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.3629 - categorical_accuracy: 0.8956 - val_loss: 0.3167 - val_categorical_accuracy: 0.9227 - 8s/epoch - 25ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss improved from 0.31674 to 0.29748, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.3272 - categorical_accuracy: 0.9078 - val_loss: 0.2975 - val_categorical_accuracy: 0.9303 - 7s/epoch - 25ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.29748 to 0.29594, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.3166 - categorical_accuracy: 0.9126 - val_loss: 0.2959 - val_categorical_accuracy: 0.9295 - 8s/epoch - 26ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 0.29594 to 0.29176, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.3023 - categorical_accuracy: 0.9133 - val_loss: 0.2918 - val_categorical_accuracy: 0.9329 - 7s/epoch - 25ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.29176 to 0.26672, saving model to t_weights_0\n",
            "295/295 - 7s - loss: 0.2860 - categorical_accuracy: 0.9209 - val_loss: 0.2667 - val_categorical_accuracy: 0.9397 - 7s/epoch - 25ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss improved from 0.26672 to 0.25303, saving model to t_weights_0\n",
            "295/295 - 8s - loss: 0.2838 - categorical_accuracy: 0.9231 - val_loss: 0.2530 - val_categorical_accuracy: 0.9448 - 8s/epoch - 26ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.25303\n",
            "295/295 - 5s - loss: 0.2621 - categorical_accuracy: 0.9269 - val_loss: 0.2745 - val_categorical_accuracy: 0.9363 - 5s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.25303\n",
            "295/295 - 5s - loss: 0.2471 - categorical_accuracy: 0.9314 - val_loss: 0.2629 - val_categorical_accuracy: 0.9405 - 5s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.25303\n",
            "295/295 - 6s - loss: 0.2432 - categorical_accuracy: 0.9333 - val_loss: 0.2913 - val_categorical_accuracy: 0.9303 - 6s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.25303\n",
            "295/295 - 5s - loss: 0.2394 - categorical_accuracy: 0.9348 - val_loss: 0.2629 - val_categorical_accuracy: 0.9380 - 5s/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.25303\n",
            "295/295 - 6s - loss: 0.2117 - categorical_accuracy: 0.9425 - val_loss: 0.2594 - val_categorical_accuracy: 0.9414 - 6s/epoch - 19ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9235343933105469 0.33316326530612245\n",
            "\n",
            "\n",
            "nrx: 10 - real: 4 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.60327, saving model to t_weights_0\n",
            "540/540 - 13s - loss: 2.2696 - categorical_accuracy: 0.2636 - val_loss: 1.6033 - val_categorical_accuracy: 0.4261 - 13s/epoch - 24ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.60327 to 1.23479, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 1.6955 - categorical_accuracy: 0.4783 - val_loss: 1.2348 - val_categorical_accuracy: 0.5851 - 12s/epoch - 22ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.23479 to 0.98565, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 1.3278 - categorical_accuracy: 0.5981 - val_loss: 0.9857 - val_categorical_accuracy: 0.6579 - 12s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.98565 to 0.76129, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 1.0857 - categorical_accuracy: 0.6787 - val_loss: 0.7613 - val_categorical_accuracy: 0.7515 - 12s/epoch - 22ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.76129 to 0.58688, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.8887 - categorical_accuracy: 0.7432 - val_loss: 0.5869 - val_categorical_accuracy: 0.8243 - 12s/epoch - 22ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.58688 to 0.51562, saving model to t_weights_0\n",
            "540/540 - 13s - loss: 0.7598 - categorical_accuracy: 0.7840 - val_loss: 0.5156 - val_categorical_accuracy: 0.8549 - 13s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.51562 to 0.45662, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.6563 - categorical_accuracy: 0.8186 - val_loss: 0.4566 - val_categorical_accuracy: 0.8637 - 12s/epoch - 22ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.45662 to 0.41573, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.5733 - categorical_accuracy: 0.8437 - val_loss: 0.4157 - val_categorical_accuracy: 0.8776 - 12s/epoch - 22ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.41573 to 0.35559, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.5183 - categorical_accuracy: 0.8614 - val_loss: 0.3556 - val_categorical_accuracy: 0.9003 - 12s/epoch - 23ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.35559 to 0.32814, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.4671 - categorical_accuracy: 0.8764 - val_loss: 0.3281 - val_categorical_accuracy: 0.9156 - 12s/epoch - 23ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.32814 to 0.30419, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.4372 - categorical_accuracy: 0.8842 - val_loss: 0.3042 - val_categorical_accuracy: 0.9152 - 12s/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.30419\n",
            "540/540 - 10s - loss: 0.4097 - categorical_accuracy: 0.8923 - val_loss: 0.3092 - val_categorical_accuracy: 0.9101 - 10s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 0.30419 to 0.27885, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.3889 - categorical_accuracy: 0.8964 - val_loss: 0.2789 - val_categorical_accuracy: 0.9207 - 12s/epoch - 23ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.27885\n",
            "540/540 - 10s - loss: 0.3549 - categorical_accuracy: 0.9077 - val_loss: 0.2858 - val_categorical_accuracy: 0.9193 - 10s/epoch - 19ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.27885\n",
            "540/540 - 10s - loss: 0.3466 - categorical_accuracy: 0.9083 - val_loss: 0.2840 - val_categorical_accuracy: 0.9263 - 10s/epoch - 19ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.27885\n",
            "540/540 - 10s - loss: 0.3329 - categorical_accuracy: 0.9108 - val_loss: 0.3175 - val_categorical_accuracy: 0.9179 - 10s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 0.27885 to 0.26285, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.3266 - categorical_accuracy: 0.9133 - val_loss: 0.2628 - val_categorical_accuracy: 0.9300 - 12s/epoch - 22ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.26285 to 0.26012, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.3083 - categorical_accuracy: 0.9188 - val_loss: 0.2601 - val_categorical_accuracy: 0.9244 - 12s/epoch - 22ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss improved from 0.26012 to 0.25482, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.3021 - categorical_accuracy: 0.9193 - val_loss: 0.2548 - val_categorical_accuracy: 0.9300 - 12s/epoch - 22ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss improved from 0.25482 to 0.24789, saving model to t_weights_0\n",
            "540/540 - 12s - loss: 0.2972 - categorical_accuracy: 0.9190 - val_loss: 0.2479 - val_categorical_accuracy: 0.9295 - 12s/epoch - 22ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.24789\n",
            "540/540 - 10s - loss: 0.2822 - categorical_accuracy: 0.9265 - val_loss: 0.2788 - val_categorical_accuracy: 0.9244 - 10s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.24789\n",
            "540/540 - 10s - loss: 0.2753 - categorical_accuracy: 0.9287 - val_loss: 0.2719 - val_categorical_accuracy: 0.9226 - 10s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.24789\n",
            "540/540 - 10s - loss: 0.2767 - categorical_accuracy: 0.9264 - val_loss: 0.2683 - val_categorical_accuracy: 0.9328 - 10s/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.24789\n",
            "540/540 - 10s - loss: 0.2717 - categorical_accuracy: 0.9262 - val_loss: 0.2701 - val_categorical_accuracy: 0.9323 - 10s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.24789\n",
            "540/540 - 10s - loss: 0.2622 - categorical_accuracy: 0.9299 - val_loss: 0.2761 - val_categorical_accuracy: 0.9323 - 10s/epoch - 18ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9304589629173279 0.35877551020408166\n",
            "\n",
            "\n",
            "nrx: 15 - real: 4 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.50946, saving model to t_weights_0\n",
            "785/785 - 18s - loss: 2.2024 - categorical_accuracy: 0.2600 - val_loss: 1.5095 - val_categorical_accuracy: 0.4609 - 18s/epoch - 22ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.50946 to 1.13583, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 1.5847 - categorical_accuracy: 0.4855 - val_loss: 1.1358 - val_categorical_accuracy: 0.6143 - 17s/epoch - 22ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.13583 to 0.89115, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 1.2284 - categorical_accuracy: 0.6175 - val_loss: 0.8911 - val_categorical_accuracy: 0.7195 - 16s/epoch - 21ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.89115 to 0.67968, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.9782 - categorical_accuracy: 0.7071 - val_loss: 0.6797 - val_categorical_accuracy: 0.7944 - 17s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67968 to 0.57237, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.7951 - categorical_accuracy: 0.7731 - val_loss: 0.5724 - val_categorical_accuracy: 0.8416 - 16s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.57237 to 0.46963, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.6705 - categorical_accuracy: 0.8139 - val_loss: 0.4696 - val_categorical_accuracy: 0.8696 - 16s/epoch - 21ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.46963 to 0.39018, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.5635 - categorical_accuracy: 0.8507 - val_loss: 0.3902 - val_categorical_accuracy: 0.8951 - 17s/epoch - 21ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.39018 to 0.38509, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.4944 - categorical_accuracy: 0.8712 - val_loss: 0.3851 - val_categorical_accuracy: 0.8938 - 16s/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.38509 to 0.33572, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.4435 - categorical_accuracy: 0.8849 - val_loss: 0.3357 - val_categorical_accuracy: 0.9168 - 17s/epoch - 22ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.33572 to 0.30914, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.4007 - categorical_accuracy: 0.8966 - val_loss: 0.3091 - val_categorical_accuracy: 0.9245 - 17s/epoch - 21ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.30914 to 0.30688, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.3705 - categorical_accuracy: 0.9053 - val_loss: 0.3069 - val_categorical_accuracy: 0.9216 - 16s/epoch - 21ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.30688 to 0.28711, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.3444 - categorical_accuracy: 0.9114 - val_loss: 0.2871 - val_categorical_accuracy: 0.9264 - 16s/epoch - 21ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.28711\n",
            "785/785 - 14s - loss: 0.3212 - categorical_accuracy: 0.9190 - val_loss: 0.2913 - val_categorical_accuracy: 0.9251 - 14s/epoch - 18ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.28711\n",
            "785/785 - 14s - loss: 0.3035 - categorical_accuracy: 0.9225 - val_loss: 0.3344 - val_categorical_accuracy: 0.9095 - 14s/epoch - 18ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.28711\n",
            "785/785 - 14s - loss: 0.2961 - categorical_accuracy: 0.9243 - val_loss: 0.3086 - val_categorical_accuracy: 0.9251 - 14s/epoch - 18ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.28711 to 0.28579, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.2845 - categorical_accuracy: 0.9278 - val_loss: 0.2858 - val_categorical_accuracy: 0.9248 - 17s/epoch - 21ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 0.28579 to 0.28217, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.2685 - categorical_accuracy: 0.9316 - val_loss: 0.2822 - val_categorical_accuracy: 0.9311 - 16s/epoch - 21ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.28217 to 0.26450, saving model to t_weights_0\n",
            "785/785 - 16s - loss: 0.2485 - categorical_accuracy: 0.9392 - val_loss: 0.2645 - val_categorical_accuracy: 0.9372 - 16s/epoch - 21ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss improved from 0.26450 to 0.25729, saving model to t_weights_0\n",
            "785/785 - 17s - loss: 0.2487 - categorical_accuracy: 0.9375 - val_loss: 0.2573 - val_categorical_accuracy: 0.9356 - 17s/epoch - 21ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.25729\n",
            "785/785 - 15s - loss: 0.2527 - categorical_accuracy: 0.9359 - val_loss: 0.2665 - val_categorical_accuracy: 0.9369 - 15s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.25729\n",
            "785/785 - 14s - loss: 0.2345 - categorical_accuracy: 0.9404 - val_loss: 0.2690 - val_categorical_accuracy: 0.9324 - 14s/epoch - 18ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.25729\n",
            "785/785 - 15s - loss: 0.2281 - categorical_accuracy: 0.9423 - val_loss: 0.2750 - val_categorical_accuracy: 0.9388 - 15s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.25729\n",
            "785/785 - 14s - loss: 0.2313 - categorical_accuracy: 0.9419 - val_loss: 0.2667 - val_categorical_accuracy: 0.9388 - 14s/epoch - 18ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.25729\n",
            "785/785 - 14s - loss: 0.2191 - categorical_accuracy: 0.9442 - val_loss: 0.2742 - val_categorical_accuracy: 0.9366 - 14s/epoch - 18ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9426203370094299 0.32602040816326533\n",
            "\n",
            "\n",
            "nrx: 20 - real: 4 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.30564, saving model to t_weights_0\n",
            "1030/1030 - 22s - loss: 2.0027 - categorical_accuracy: 0.3284 - val_loss: 1.3056 - val_categorical_accuracy: 0.5640 - 22s/epoch - 21ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.30564 to 0.75051, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 1.1961 - categorical_accuracy: 0.6294 - val_loss: 0.7505 - val_categorical_accuracy: 0.7675 - 21s/epoch - 21ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 0.75051 to 0.53479, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.8172 - categorical_accuracy: 0.7593 - val_loss: 0.5348 - val_categorical_accuracy: 0.8377 - 21s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.53479 to 0.41856, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.6282 - categorical_accuracy: 0.8222 - val_loss: 0.4186 - val_categorical_accuracy: 0.8790 - 21s/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.41856 to 0.37521, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.5138 - categorical_accuracy: 0.8564 - val_loss: 0.3752 - val_categorical_accuracy: 0.8919 - 21s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.37521 to 0.32203, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.4406 - categorical_accuracy: 0.8792 - val_loss: 0.3220 - val_categorical_accuracy: 0.9077 - 21s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.32203 to 0.30136, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.3894 - categorical_accuracy: 0.8932 - val_loss: 0.3014 - val_categorical_accuracy: 0.9109 - 21s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.30136 to 0.27345, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.3605 - categorical_accuracy: 0.9008 - val_loss: 0.2734 - val_categorical_accuracy: 0.9220 - 21s/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.27345\n",
            "1030/1030 - 19s - loss: 0.3334 - categorical_accuracy: 0.9100 - val_loss: 0.2810 - val_categorical_accuracy: 0.9213 - 19s/epoch - 18ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.27345\n",
            "1030/1030 - 19s - loss: 0.3126 - categorical_accuracy: 0.9147 - val_loss: 0.2862 - val_categorical_accuracy: 0.9181 - 19s/epoch - 18ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss improved from 0.27345 to 0.26062, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.2952 - categorical_accuracy: 0.9193 - val_loss: 0.2606 - val_categorical_accuracy: 0.9293 - 21s/epoch - 20ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.26062 to 0.25053, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.2823 - categorical_accuracy: 0.9231 - val_loss: 0.2505 - val_categorical_accuracy: 0.9327 - 21s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.25053\n",
            "1030/1030 - 19s - loss: 0.2785 - categorical_accuracy: 0.9245 - val_loss: 0.2519 - val_categorical_accuracy: 0.9325 - 19s/epoch - 18ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss improved from 0.25053 to 0.24952, saving model to t_weights_0\n",
            "1030/1030 - 21s - loss: 0.2633 - categorical_accuracy: 0.9282 - val_loss: 0.2495 - val_categorical_accuracy: 0.9349 - 21s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.24952\n",
            "1030/1030 - 19s - loss: 0.2572 - categorical_accuracy: 0.9293 - val_loss: 0.2644 - val_categorical_accuracy: 0.9308 - 19s/epoch - 18ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.24952\n",
            "1030/1030 - 19s - loss: 0.2512 - categorical_accuracy: 0.9331 - val_loss: 0.2604 - val_categorical_accuracy: 0.9327 - 19s/epoch - 18ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.24952\n",
            "1030/1030 - 19s - loss: 0.2459 - categorical_accuracy: 0.9336 - val_loss: 0.2737 - val_categorical_accuracy: 0.9308 - 19s/epoch - 18ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.24952 to 0.23726, saving model to t_weights_0\n",
            "1030/1030 - 22s - loss: 0.2364 - categorical_accuracy: 0.9366 - val_loss: 0.2373 - val_categorical_accuracy: 0.9400 - 22s/epoch - 21ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.23726\n",
            "1030/1030 - 19s - loss: 0.2335 - categorical_accuracy: 0.9373 - val_loss: 0.2455 - val_categorical_accuracy: 0.9373 - 19s/epoch - 18ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.23726\n",
            "1030/1030 - 19s - loss: 0.2295 - categorical_accuracy: 0.9391 - val_loss: 0.2575 - val_categorical_accuracy: 0.9356 - 19s/epoch - 18ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.23726\n",
            "1030/1030 - 19s - loss: 0.2244 - categorical_accuracy: 0.9391 - val_loss: 0.2531 - val_categorical_accuracy: 0.9373 - 19s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.23726\n",
            "1030/1030 - 19s - loss: 0.2172 - categorical_accuracy: 0.9416 - val_loss: 0.2454 - val_categorical_accuracy: 0.9405 - 19s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.23726\n",
            "1030/1030 - 19s - loss: 0.2122 - categorical_accuracy: 0.9443 - val_loss: 0.2451 - val_categorical_accuracy: 0.9407 - 19s/epoch - 18ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.942190945148468 0.6085714285714285\n",
            "\n",
            "\n",
            "nrx: 25 - real: 4 \n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.47314, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 1.9937 - categorical_accuracy: 0.2913 - val_loss: 1.4731 - val_categorical_accuracy: 0.4787 - 26s/epoch - 21ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.47314 to 1.11806, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 1.4829 - categorical_accuracy: 0.4951 - val_loss: 1.1181 - val_categorical_accuracy: 0.6180 - 25s/epoch - 20ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.11806 to 0.86927, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 1.1894 - categorical_accuracy: 0.6149 - val_loss: 0.8693 - val_categorical_accuracy: 0.7270 - 25s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.86927 to 0.68430, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.9457 - categorical_accuracy: 0.7074 - val_loss: 0.6843 - val_categorical_accuracy: 0.7840 - 25s/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 0.68430 to 0.51417, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.7627 - categorical_accuracy: 0.7723 - val_loss: 0.5142 - val_categorical_accuracy: 0.8467 - 25s/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.51417 to 0.44576, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.6291 - categorical_accuracy: 0.8147 - val_loss: 0.4458 - val_categorical_accuracy: 0.8626 - 25s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 0.44576 to 0.41640, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.5424 - categorical_accuracy: 0.8426 - val_loss: 0.4164 - val_categorical_accuracy: 0.8712 - 25s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.41640 to 0.35621, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.4825 - categorical_accuracy: 0.8596 - val_loss: 0.3562 - val_categorical_accuracy: 0.8892 - 25s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 0.35621 to 0.34582, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.4396 - categorical_accuracy: 0.8746 - val_loss: 0.3458 - val_categorical_accuracy: 0.8962 - 25s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 0.34582 to 0.30868, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.4077 - categorical_accuracy: 0.8832 - val_loss: 0.3087 - val_categorical_accuracy: 0.9061 - 25s/epoch - 20ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.30868\n",
            "1260/1260 - 23s - loss: 0.3829 - categorical_accuracy: 0.8899 - val_loss: 0.3185 - val_categorical_accuracy: 0.9073 - 23s/epoch - 18ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.30868\n",
            "1260/1260 - 23s - loss: 0.3656 - categorical_accuracy: 0.8946 - val_loss: 0.3114 - val_categorical_accuracy: 0.9079 - 23s/epoch - 18ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 0.30868 to 0.29789, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.3479 - categorical_accuracy: 0.8992 - val_loss: 0.2979 - val_categorical_accuracy: 0.9093 - 25s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss improved from 0.29789 to 0.29158, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.3395 - categorical_accuracy: 0.9024 - val_loss: 0.2916 - val_categorical_accuracy: 0.9154 - 25s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.29158\n",
            "1260/1260 - 23s - loss: 0.3230 - categorical_accuracy: 0.9064 - val_loss: 0.3183 - val_categorical_accuracy: 0.9073 - 23s/epoch - 18ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.29158 to 0.27516, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.3106 - categorical_accuracy: 0.9105 - val_loss: 0.2752 - val_categorical_accuracy: 0.9204 - 25s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 0.27516 to 0.27297, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.3059 - categorical_accuracy: 0.9131 - val_loss: 0.2730 - val_categorical_accuracy: 0.9164 - 25s/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 0.27297 to 0.27032, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.3001 - categorical_accuracy: 0.9146 - val_loss: 0.2703 - val_categorical_accuracy: 0.9188 - 25s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss improved from 0.27032 to 0.26511, saving model to t_weights_0\n",
            "1260/1260 - 25s - loss: 0.2831 - categorical_accuracy: 0.9183 - val_loss: 0.2651 - val_categorical_accuracy: 0.9224 - 25s/epoch - 20ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.26511\n",
            "1260/1260 - 23s - loss: 0.2846 - categorical_accuracy: 0.9185 - val_loss: 0.2660 - val_categorical_accuracy: 0.9210 - 23s/epoch - 18ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.26511\n",
            "1260/1260 - 25s - loss: 0.2774 - categorical_accuracy: 0.9207 - val_loss: 0.2805 - val_categorical_accuracy: 0.9160 - 25s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.26511\n",
            "1260/1260 - 24s - loss: 0.2695 - categorical_accuracy: 0.9247 - val_loss: 0.2668 - val_categorical_accuracy: 0.9222 - 24s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss improved from 0.26511 to 0.26122, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.2658 - categorical_accuracy: 0.9244 - val_loss: 0.2612 - val_categorical_accuracy: 0.9273 - 26s/epoch - 21ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.26122\n",
            "1260/1260 - 24s - loss: 0.2573 - categorical_accuracy: 0.9281 - val_loss: 0.2669 - val_categorical_accuracy: 0.9250 - 24s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss improved from 0.26122 to 0.25175, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.2508 - categorical_accuracy: 0.9294 - val_loss: 0.2518 - val_categorical_accuracy: 0.9307 - 26s/epoch - 21ms/step\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.25175\n",
            "1260/1260 - 24s - loss: 0.2489 - categorical_accuracy: 0.9303 - val_loss: 0.2592 - val_categorical_accuracy: 0.9293 - 24s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss improved from 0.25175 to 0.25125, saving model to t_weights_0\n",
            "1260/1260 - 27s - loss: 0.2416 - categorical_accuracy: 0.9335 - val_loss: 0.2512 - val_categorical_accuracy: 0.9313 - 27s/epoch - 21ms/step\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.25125\n",
            "1260/1260 - 25s - loss: 0.2392 - categorical_accuracy: 0.9340 - val_loss: 0.2667 - val_categorical_accuracy: 0.9307 - 25s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.25125\n",
            "1260/1260 - 25s - loss: 0.2348 - categorical_accuracy: 0.9349 - val_loss: 0.2649 - val_categorical_accuracy: 0.9321 - 25s/epoch - 20ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.25125\n",
            "1260/1260 - 24s - loss: 0.2340 - categorical_accuracy: 0.9356 - val_loss: 0.2556 - val_categorical_accuracy: 0.9333 - 24s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.25125\n",
            "1260/1260 - 24s - loss: 0.2261 - categorical_accuracy: 0.9374 - val_loss: 0.2530 - val_categorical_accuracy: 0.9317 - 24s/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 32: val_loss improved from 0.25125 to 0.25086, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.2259 - categorical_accuracy: 0.9380 - val_loss: 0.2509 - val_categorical_accuracy: 0.9313 - 26s/epoch - 21ms/step\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.25086\n",
            "1260/1260 - 24s - loss: 0.2179 - categorical_accuracy: 0.9395 - val_loss: 0.2566 - val_categorical_accuracy: 0.9337 - 24s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: val_loss improved from 0.25086 to 0.24927, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.2179 - categorical_accuracy: 0.9406 - val_loss: 0.2493 - val_categorical_accuracy: 0.9379 - 26s/epoch - 21ms/step\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: val_loss improved from 0.24927 to 0.24668, saving model to t_weights_0\n",
            "1260/1260 - 27s - loss: 0.2186 - categorical_accuracy: 0.9404 - val_loss: 0.2467 - val_categorical_accuracy: 0.9357 - 27s/epoch - 21ms/step\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.24668\n",
            "1260/1260 - 24s - loss: 0.2098 - categorical_accuracy: 0.9429 - val_loss: 0.2683 - val_categorical_accuracy: 0.9335 - 24s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.24668\n",
            "1260/1260 - 24s - loss: 0.2101 - categorical_accuracy: 0.9423 - val_loss: 0.2493 - val_categorical_accuracy: 0.9412 - 24s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.24668\n",
            "1260/1260 - 24s - loss: 0.2133 - categorical_accuracy: 0.9429 - val_loss: 0.2645 - val_categorical_accuracy: 0.9361 - 24s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.24668\n",
            "1260/1260 - 24s - loss: 0.2034 - categorical_accuracy: 0.9453 - val_loss: 0.2569 - val_categorical_accuracy: 0.9389 - 24s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: val_loss improved from 0.24668 to 0.24592, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.2052 - categorical_accuracy: 0.9442 - val_loss: 0.2459 - val_categorical_accuracy: 0.9375 - 26s/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.24592\n",
            "1260/1260 - 24s - loss: 0.1973 - categorical_accuracy: 0.9473 - val_loss: 0.2700 - val_categorical_accuracy: 0.9349 - 24s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.24592\n",
            "1260/1260 - 24s - loss: 0.1990 - categorical_accuracy: 0.9459 - val_loss: 0.2540 - val_categorical_accuracy: 0.9385 - 24s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: val_loss improved from 0.24592 to 0.24255, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.1979 - categorical_accuracy: 0.9469 - val_loss: 0.2425 - val_categorical_accuracy: 0.9392 - 26s/epoch - 21ms/step\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.24255\n",
            "1260/1260 - 24s - loss: 0.1919 - categorical_accuracy: 0.9468 - val_loss: 0.2550 - val_categorical_accuracy: 0.9392 - 24s/epoch - 19ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.24255\n",
            "1260/1260 - 24s - loss: 0.1930 - categorical_accuracy: 0.9476 - val_loss: 0.2475 - val_categorical_accuracy: 0.9426 - 24s/epoch - 19ms/step\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.24255\n",
            "1260/1260 - 24s - loss: 0.1890 - categorical_accuracy: 0.9490 - val_loss: 0.2459 - val_categorical_accuracy: 0.9379 - 24s/epoch - 19ms/step\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.24255\n",
            "1260/1260 - 24s - loss: 0.1868 - categorical_accuracy: 0.9507 - val_loss: 0.2454 - val_categorical_accuracy: 0.9406 - 24s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: val_loss improved from 0.24255 to 0.23476, saving model to t_weights_0\n",
            "1260/1260 - 26s - loss: 0.1903 - categorical_accuracy: 0.9483 - val_loss: 0.2348 - val_categorical_accuracy: 0.9428 - 26s/epoch - 21ms/step\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.23476\n",
            "1260/1260 - 24s - loss: 0.1839 - categorical_accuracy: 0.9505 - val_loss: 0.2688 - val_categorical_accuracy: 0.9394 - 24s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.23476\n",
            "1260/1260 - 23s - loss: 0.1817 - categorical_accuracy: 0.9515 - val_loss: 0.2438 - val_categorical_accuracy: 0.9402 - 23s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.23476\n",
            "1260/1260 - 24s - loss: 0.1799 - categorical_accuracy: 0.9518 - val_loss: 0.2491 - val_categorical_accuracy: 0.9414 - 24s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.23476\n",
            "1260/1260 - 23s - loss: 0.1814 - categorical_accuracy: 0.9511 - val_loss: 0.2616 - val_categorical_accuracy: 0.9406 - 23s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.23476\n",
            "1260/1260 - 24s - loss: 0.1785 - categorical_accuracy: 0.9522 - val_loss: 0.2683 - val_categorical_accuracy: 0.9416 - 24s/epoch - 19ms/step\n",
            "307/307 [==============================] - 3s 8ms/step\n",
            "0.9479849338531494 0.5503061224489796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.dpi'] = 100\n",
        "plt.errorbar(np.array(nrx_list)+1,np.mean(smTest_results,0),np.std(smTest_results,0),capsize=4)\n",
        "plt.errorbar(np.array(nrx_list)+1,np.mean(dfTest_results,0),np.std(dfTest_results,0),capsize=4)\n",
        "plt.legend(['Same Rx(s)','Diff. Rx'])\n",
        "plt.xlabel('N Train Rx')\n",
        "plt.ylabel('Class. Accuracy')\n",
        "#plt.xticks(range(0,len(nrx_list),2))\n",
        "plt.grid()\n",
        "print(np.mean(dfTest_results,0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "9nuftguw1wE5",
        "outputId": "0a8f7214-0f08-4a75-83bb-91a5fecb3cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.17295632653061227, 0.267495918367347, 0.34221918367346943, 0.44312204081632656, 0.6413783673469388, 0.5904110204081633]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/weights /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "SV6l5yVpJcTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}