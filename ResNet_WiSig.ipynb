{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities Functions"
      ],
      "metadata": {
        "id": "XGHPnr95xZ5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_from_full_dataset(full_dataset_path, capture_date,rx_name,prefix=None):\n",
        "    src=full_dataset_path\n",
        "\n",
        "    if prefix is None: \n",
        "        dataset_path = '{}pkl_wifi_{}/dataset_{}_node{}.pkl'.format(src,capture_date,capture_date,rx_name)\n",
        "    else:\n",
        "        dataset_path = '{}pkl_wifi_{}_{}/dataset_{}_node{}.pkl'.format(src,prefix,capture_date,capture_date,rx_name)\n",
        "   \n",
        "    if os.path.isfile(dataset_path) :\n",
        "        with open(dataset_path,'rb') as f:\n",
        "            dataset = pickle.load(f)\n",
        "    else:\n",
        "            dataset = None\n",
        "#             print('Not Found')\n",
        "#             print(dataset_path)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_compact_pkl_dataset(dataset_path,dataset_name):\n",
        "    with open(dataset_path+dataset_name+'.pkl','rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def shuffle(vec1,vec2,seed = 0):\n",
        "    np.random.seed(0)\n",
        "#     print(vec1.shape[0],vec2.shape[0])\n",
        "    shfl_indx = np.arange(vec1.shape[0])\n",
        "    np.random.shuffle(shfl_indx)\n",
        "    shfl_indx = shfl_indx.astype('int')\n",
        "    vec1 = vec1[shfl_indx]\n",
        "    vec2 = np.copy(vec2[shfl_indx])\n",
        "    return vec1,vec2\n",
        "\n",
        "\n",
        "def norm(sig_u):\n",
        "    if len(sig_u.shape)==3:\n",
        "        pwr = np.sqrt(np.mean(np.sum(sig_u**2,axis = -1),axis = -1))\n",
        "        sig_u = sig_u/pwr[:,None,None]\n",
        "    if len(sig_u.shape)==2:\n",
        "        pwr =  np.sqrt(np.mean(np.sum(sig_u**2,axis = -1),axis = -1))\n",
        "        sig_u = sig_u/pwr\n",
        "    # print(sig_u.shape)\n",
        "    return sig_u\n",
        "\n",
        "def split3(vec,n1,n2):\n",
        "    vec1 = vec[0:n1]\n",
        "    vec2 = vec[n1:n1+n2]\n",
        "    vec3 = vec[n1+n2:]\n",
        "    return vec3,vec1,vec2\n",
        "\n",
        "def split_set3(st,f1,f2):\n",
        "    [sig,txid] = st\n",
        "\n",
        "    n_samples  = sig.shape[0]\n",
        "    n1 = int(f1*n_samples)\n",
        "    n2 = int(f2*n_samples)\n",
        "\n",
        "    sig1,sig2,sig3 = split3(sig,n1,n2)\n",
        "    txid1,txid2,txid3 = split3(txid,n1,n2)\n",
        "    st1 = [sig1,txid1]\n",
        "    st2 = [sig2,txid2]\n",
        "    st3 = [sig3,txid3]\n",
        "    return st1,st2,st3 \n",
        "\n",
        "def get_node_indices(tx_name_list,node_name_list):\n",
        "    op_list = []\n",
        "    for tx in tx_name_list:\n",
        "        if tx in node_name_list:\n",
        "            op_list.append(node_name_list.index(tx))\n",
        "        else:\n",
        "            op_list.append(None)\n",
        "    return op_list\n",
        "    \n",
        "def parse_nodes(dataset,node_list,seed = 0):\n",
        "    cat_sig = []\n",
        "    cat_txid = []\n",
        "    data = dataset['data']\n",
        "    \n",
        "    \n",
        "    for i,node in enumerate(node_list):\n",
        "        if (not node  is  None) and  node < len(data):\n",
        "            cat_sig.append(data[node])\n",
        "            cat_txid.append(np.ones( (data[node].shape[0]) )*i)\n",
        "    cat_sig = np.concatenate(cat_sig)\n",
        "    cat_txid = np.concatenate(cat_txid)\n",
        "    np.random.seed(seed)\n",
        "    cat_sig,cat_txid = shuffle(cat_sig,cat_txid)\n",
        "    cat_sig = norm(cat_sig)\n",
        "    return (cat_sig,cat_txid)\n",
        "\n",
        "def to_categorical(y, num_classes=None, dtype='float32'):\n",
        "    y = np.array(y, dtype='int')\n",
        "    input_shape = y.shape\n",
        "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
        "        input_shape = tuple(input_shape[:-1])\n",
        "    y = y.ravel()\n",
        "    if not num_classes:\n",
        "        num_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    output_shape = input_shape + (num_classes,)\n",
        "    categorical = np.reshape(categorical, output_shape)\n",
        "    return categorical\n",
        "\n",
        "def prepare_txid_and_weights(st,n):\n",
        "    sig,txid = st\n",
        "    txid_oh = to_categorical(txid,n)\n",
        "    stat= np.sum(txid_oh,axis=0)\n",
        "    cls_weights = np.max(stat,axis=0)/stat \n",
        "    cls_weights = cls_weights.tolist()\n",
        "    augset = [sig,txid,txid_oh,cls_weights]\n",
        "    return augset\n",
        "\n",
        "def prepare_dataset(dataset,tx_name_list,val_frac=0.1, test_frac=0.1):\n",
        "    tx_list = get_node_indices(tx_name_list,dataset['node_list'])\n",
        "    all_set = parse_nodes(dataset,tx_list,seed = 0)\n",
        "    train_set,val_set,test_set = split_set3(all_set,val_frac, test_frac)\n",
        "    train_augset = prepare_txid_and_weights(train_set,len(tx_list))\n",
        "    val_augset = prepare_txid_and_weights(val_set,len(tx_list))\n",
        "    test_augset = prepare_txid_and_weights(test_set,len(tx_list))\n",
        "    return train_augset,val_augset,test_augset\n",
        "\n",
        "\n",
        "def create_dataset_impl(tx_list,rx_list,capture_date_list,max_sig=None,equalized_list=[0],full_dataset_path = 'data/',op_dataset_file = None):\n",
        "    dataset = {}\n",
        "    dataset['tx_list'] = tx_list\n",
        "    dataset['rx_list'] = rx_list\n",
        "    dataset['capture_date_list']=capture_date_list\n",
        "    dataset['equalized_list'] = equalized_list\n",
        "    dataset['max_sig'] = max_sig\n",
        "    \n",
        "    n_tx = len(tx_list)\n",
        "    n_rx = len(rx_list)\n",
        "    n_day = len(capture_date_list)\n",
        "    n_eq = len(equalized_list)\n",
        "    \n",
        "    prefix_lut = [None,'eq']\n",
        "    \n",
        "    prefix_list = [prefix_lut[tt] for tt in  equalized_list]\n",
        "    \n",
        "    dataset['data'] = [ [ [ [ [ ] for _ in range(n_eq)] for _ in range(n_day) ] for _ in range(n_rx) ]  for _ in range(n_tx)     ]\n",
        "    \n",
        "    \n",
        "    missing_rx_dict = {}\n",
        "    \n",
        "    missing_files = False\n",
        "\n",
        "    \n",
        "    with open('IdSig_info.pkl','rb') as f:\n",
        "        IdSig_info=pickle.load(f)\n",
        "    \n",
        "    slc = slice(None,max_sig)\n",
        "    for day_i,capture_date in enumerate(capture_date_list):\n",
        "        for rx_i,rx_train in enumerate(rx_list):\n",
        "            for eq_i,prefix in enumerate(prefix_list):\n",
        "                tdataset = load_from_full_dataset(full_dataset_path,capture_date,rx_train,prefix=prefix)\n",
        "                if not tdataset is None:\n",
        "                    for tx_i,tx in enumerate(tx_list):\n",
        "                        if tx in tdataset['node_list']:\n",
        "                            tx_indx = tdataset['node_list'].index(tx)\n",
        "                            dataset['data'][tx_i][rx_i][day_i][eq_i]= tdataset['data'][tx_indx][slc]  \n",
        "                        else:\n",
        "                            dataset['data'][tx_i][rx_i][day_i][eq_i]=np.zeros((0,256,2))\n",
        "                else:\n",
        "                    missing_rx_name =rx_list[rx_i]  \n",
        "                    eq_val = equalized_list[eq_i]\n",
        "                    IdSig_info_sub  = IdSig_info[eq_val][capture_date]\n",
        "                    if missing_rx_name  in IdSig_info_sub.keys():\n",
        "                            missing_files = True\n",
        "                            if not eq_val in  missing_rx_dict.keys():\n",
        "                                missing_rx_dict[eq_val]={}\n",
        "                            if not capture_date in  missing_rx_dict[eq_val].keys():\n",
        "                                missing_rx_dict[eq_val][capture_date]=[]\n",
        "                            missing_rx_info  = IdSig_info_sub[missing_rx_name]\n",
        "                            missing_rx_dict[eq_val][capture_date].append(   (missing_rx_info['name'], missing_rx_info['link'],missing_rx_info['size']) )\n",
        "\n",
        "    \n",
        "    if missing_files:\n",
        "        ii=1\n",
        "        total_file_sizes = 0\n",
        "        print('You have missing files that you need to download.')\n",
        "        \n",
        "        for eq_k  in missing_rx_dict.keys():  \n",
        "            if len(missing_rx_dict[eq_val])>0:\n",
        "                print('')\n",
        "                if eq_k==0:\n",
        "                    print('You need to download the following files for the non equalized dataset')\n",
        "                else:\n",
        "                    print('You need to download the following files for the equalized dataset')\n",
        "                \n",
        "                print('')\n",
        "                \n",
        "                for date_k  in missing_rx_dict[eq_k].keys():  \n",
        "                    for missing_rx in missing_rx_dict[eq_val][date_k]:\n",
        "                        print('{}) Name: {} , Size: {} MB'.format(ii,missing_rx[0],missing_rx[2]/1e6))\n",
        "                        total_file_sizes=total_file_sizes+missing_rx[2]\n",
        "                        ii=ii+1\n",
        "                print('Links:')\n",
        "                for date_k  in missing_rx_dict[eq_k].keys():  \n",
        "                    for missing_rx in missing_rx_dict[eq_val][date_k]:\n",
        "                        print('https://drive.google.com/u/0/uc?export=download&id={}'.format(missing_rx[1]))               \n",
        "        print('')\n",
        "        print('You need to dowlnoad {} GB'.format(total_file_sizes/1e9))\n",
        "        print('Note the following:')\n",
        "        print('1) The non-equalized and eqalized files need to be downloaded in different fodlers because they share the same exact names')\n",
        "        print('2) The  non-equalized folders needs to be grouped by date and equalization using the same structure as the following google drive folder')\n",
        "        print('https://drive.google.com/drive/folders/1r8cd4zZ7fwvN_iiyI_uDKbIFGZve49lw?usp=sharing')\n",
        "        print('3) If you have already downloaded the files make sure that the full dataset path is configured correctly.')\n",
        "        dataset = None\n",
        "    else:\n",
        "        if not op_dataset_file is None:\n",
        "            with open(op_dataset_file,'wb') as f:\n",
        "                pickle.dump(dataset,f)\n",
        "                print('Dataset saved in {}'.format(op_dataset_file))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_list,max_sig=None,equalized=0):\n",
        "    dataset = {}\n",
        "    dataset['node_list'] = tx_list\n",
        "    dataset['data'] = [ () for _ in range(len(tx_list))]\n",
        "    \n",
        "    if not type(capture_date) is list: \n",
        "        capture_date_list = [capture_date]\n",
        "    else:\n",
        "        capture_date_list = capture_date\n",
        "    slc = slice(None,max_sig)\n",
        "    for capture_date in capture_date_list:\n",
        "        for rx_train in rx_list:\n",
        "            for indx,tx in enumerate(tx_list):\n",
        "                tx_i=compact_dataset['tx_list'].index(tx)\n",
        "                rx_i=compact_dataset['rx_list'].index(rx_train)\n",
        "                date_i=compact_dataset['capture_date_list'].index(capture_date)\n",
        "                eq_i=compact_dataset['equalized_list'].index(equalized)\n",
        "                dataset['data'][indx]  +=  (compact_dataset['data'][tx_i][rx_i][date_i][eq_i][slc],)\n",
        "    for indx in range(len(tx_list)):\n",
        "        if len(dataset['data'][indx])>0:\n",
        "            dataset['data'][indx] =  np.concatenate(dataset['data'][indx])\n",
        "        else:\n",
        "            dataset['data'][indx] =np.zeros((0,256,2))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "6U6A7mWsxYPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "AHdL7PFfxieU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioakfsp4teKh",
        "outputId": "cb7174ea-a2c7-48b4-9fe9-8c089e943a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import scipy,scipy.spatial\n",
        "import matplotlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/ManyRx.pkl.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "metadata": {
        "id": "REjUQSlQu9Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_compact_pkl_dataset(dataset_path,dataset_name):\n",
        "    with open(dataset_path+dataset_name+'.pkl','rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    return dataset\n",
        "\n",
        "compact_dataset = load_compact_pkl_dataset(\"./\",\"ManyRx\")\n",
        "\n",
        "tx_list = compact_dataset['tx_list']\n",
        "rx_list = compact_dataset['rx_list']\n",
        "\n",
        "equalized = 0\n",
        "\n",
        "capture_date_list = compact_dataset['capture_date_list']\n",
        "capture_date = capture_date_list[0]\n",
        "n_tx = len(tx_list)\n",
        "n_rx = len(rx_list)\n",
        "print(n_tx,n_rx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06y2qsqnuasY",
        "outputId": "39bdbf9d-6e89-465a-a43e-64af1e92c97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compact_dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiI8yA2vcUc",
        "outputId": "7e8654fb-9435-43cf-bacd-f43c189d0500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tx_list', 'rx_list', 'capture_date_list', 'equalized_list', 'max_sig', 'data'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "n_real = 5\n",
        "rx_list_real = []\n",
        "for i in range(n_real):\n",
        "    np.random.shuffle(rx_list)\n",
        "    rx_list_real.append(np.copy(rx_list).tolist())\n",
        "print(rx_list_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ikdXBivkhR",
        "outputId": "cb509537-b51d-4450-dba9-eee80541d733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['19-20', '24-13', '19-2', '1-20', '20-20', '20-1', '7-7', '3-19', '23-6', '2-19', '24-5', '14-7', '23-1', '19-1', '8-7', '24-6', '24-16', '1-19', '8-8', '18-19', '13-7', '23-3', '8-14', '23-5', '19-19', '18-2', '7-14', '13-14', '1-1', '23-7', '20-19', '2-1'], ['1-1', '23-1', '24-6', '8-8', '1-19', '23-3', '23-5', '7-14', '19-19', '13-14', '23-6', '7-7', '19-1', '20-1', '20-20', '24-16', '8-14', '19-2', '14-7', '1-20', '13-7', '24-5', '18-2', '2-19', '24-13', '19-20', '3-19', '8-7', '20-19', '2-1', '23-7', '18-19'], ['24-5', '23-7', '18-19', '23-3', '24-6', '8-14', '2-1', '13-7', '19-19', '19-2', '18-2', '1-20', '20-1', '24-16', '3-19', '1-19', '24-13', '23-6', '19-1', '8-7', '20-19', '1-1', '14-7', '20-20', '7-7', '2-19', '23-5', '8-8', '19-20', '13-14', '7-14', '23-1'], ['1-20', '1-19', '20-19', '23-7', '2-1', '20-1', '19-19', '14-7', '23-1', '3-19', '8-8', '7-7', '13-7', '20-20', '24-16', '18-2', '8-7', '23-5', '7-14', '18-19', '24-6', '19-1', '13-14', '2-19', '19-20', '24-5', '23-3', '19-2', '8-14', '23-6', '24-13', '1-1'], ['18-19', '20-1', '13-14', '18-2', '14-7', '20-20', '13-7', '19-20', '2-19', '19-19', '19-1', '1-20', '24-5', '20-19', '8-7', '23-1', '7-7', '8-8', '2-1', '1-19', '3-19', '23-3', '23-6', '23-5', '24-6', '8-14', '24-16', '7-14', '1-1', '19-2', '24-13', '23-7']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "xl_wGK6twy2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_ESiw2P2nxa",
        "outputId": "30b9f4c8-19a3-4297-b1f1-80557f1577bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attention\n",
            "  Downloading attention-5.0.0-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from attention) (1.22.4)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.10/dist-packages (from attention) (2.12.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (2.12.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (3.20.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (1.54.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (16.0.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (67.7.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (3.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (0.32.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (2.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (23.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1->attention) (23.3.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1->attention) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.1->attention) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.1->attention) (0.1.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.1->attention) (3.2.2)\n",
            "Installing collected packages: attention\n",
            "Successfully installed attention-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_stack(X,Filters,Seq,max_pool):\n",
        "    #1*1 Conv Linear\n",
        "    X = Conv2D(Filters, (1,1), padding='same', name=Seq+\"_conv1\", kernel_initializer='glorot_uniform')(X)\n",
        "    #Residual Unit 1\n",
        "    X_shortcut = X\n",
        "    X = Conv2D(Filters, (3,1), padding='same',activation=\"relu\",name=Seq+\"_conv2\", kernel_initializer='glorot_uniform')(X)\n",
        "    X = Conv2D(Filters, (3,1), padding='same', name=Seq+\"_conv3\", kernel_initializer='glorot_uniform')(X)\n",
        "    X = layers.add([X,X_shortcut])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    #Residual Unit 2\n",
        "    X_shortcut = X\n",
        "    X = Conv2D(Filters, (3,1), padding='same',activation=\"relu\",name=Seq+\"_conv4\", kernel_initializer='glorot_uniform')(X)\n",
        "    X = Conv2D(Filters, (3,1), padding='same', name=Seq+\"_conv5\", kernel_initializer='glorot_uniform')(X)\n",
        "    X = layers.add([X,X_shortcut])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    #MaxPooling\n",
        "    if max_pool:\n",
        "        X = MaxPooling2D(pool_size=(2, 1), strides=(2, 1), padding='valid')(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "def create_net():\n",
        "    '''\n",
        "    inputs = Input(shape=(256,2))\n",
        "    x = Reshape((256,2,1))(inputs)\n",
        "\n",
        "    x = LSTM(64, return_sequences=True)(inputs)\n",
        "\n",
        "    x = Attention(units=32)(x)\n",
        "    #x = resnet(x,64,(3,2),'6')\n",
        "    #x = MaxPool2D((2,2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "\n",
        "\n",
        "    x = Dense(100, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    x = Dense(80, activation='relu',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(n_tx, activation='softmax',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
        "    ops = x\n",
        "\n",
        "    classifier = Model(inputs,ops)\n",
        "    '''\n",
        "\n",
        "    #input layer\n",
        "    inputs = Input(shape=(256,2))\n",
        "    X = Reshape((256,2,1))(inputs)\n",
        "    #Residual Srack 1\n",
        "    X = residual_stack(X,32,\"ReStk1\",False)  #shape:(1,512,32)\n",
        "    X = MaxPooling2D(pool_size=(2, 2), strides=(1, 2), padding='valid')(X)\n",
        "    #Residual Srack 2\n",
        "    X = residual_stack(X,32,\"ReStk2\",True)  #shape:(1,256,32)\n",
        "    #Residual Srack 3\n",
        "    X = residual_stack(X,32,\"ReStk3\",True)  #shape:(1,128,32)\n",
        "    #Residual Srack 4\n",
        "    X = residual_stack(X,32,\"ReStk4\",True)  #shape:(1,64,32)\n",
        "    #Residual Srack 5\n",
        "    X = residual_stack(X,32,\"ReStk5\",True)  #shape:(1,32,32)\n",
        "    #Residual Srack 6\n",
        "    X = residual_stack(X,32,\"ReStk6\",True)  #shape:(1,16,32)\n",
        "    #Full Con 1\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(128, activation='selu', kernel_initializer='he_normal', name=\"dense1\")(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    #Full Con 2\n",
        "    X = Dense(128, activation='selu', kernel_initializer='he_normal', name=\"dense2\")(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    #Full Con 3\n",
        "    X = Dense(n_tx, kernel_initializer='he_normal', name=\"dense3\")(X)\n",
        "    #SoftMax\n",
        "    ops = Activation('softmax')(X)\n",
        "    #Create Model\n",
        "    classifier = Model(inputs,ops)\n",
        "    #classifier = tf.keras.applications.ResNet50(include_top=False, weights=None)\n",
        "    classifier.compile(loss='categorical_crossentropy',metrics=['categorical_accuracy'],optimizer=keras.optimizers.Adam(0.0005))\n",
        "    \n",
        "    return classifier\n",
        "\n",
        "classifier = create_net()\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk4QxIuTw2TO",
        "outputId": "3eafaff5-a79f-4ba9-a45c-103d863b3676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 256, 2)]     0           []                               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 256, 2, 1)    0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " ReStk1_conv1 (Conv2D)          (None, 256, 2, 32)   64          ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " ReStk1_conv2 (Conv2D)          (None, 256, 2, 32)   3104        ['ReStk1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk1_conv3 (Conv2D)          (None, 256, 2, 32)   3104        ['ReStk1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 256, 2, 32)   0           ['ReStk1_conv3[0][0]',           \n",
            "                                                                  'ReStk1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 256, 2, 32)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk1_conv4 (Conv2D)          (None, 256, 2, 32)   3104        ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk1_conv5 (Conv2D)          (None, 256, 2, 32)   3104        ['ReStk1_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 256, 2, 32)   0           ['ReStk1_conv5[0][0]',           \n",
            "                                                                  'activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 256, 2, 32)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 255, 1, 32)  0           ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk2_conv1 (Conv2D)          (None, 255, 1, 32)   1056        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " ReStk2_conv2 (Conv2D)          (None, 255, 1, 32)   3104        ['ReStk2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk2_conv3 (Conv2D)          (None, 255, 1, 32)   3104        ['ReStk2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 255, 1, 32)   0           ['ReStk2_conv3[0][0]',           \n",
            "                                                                  'ReStk2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 255, 1, 32)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk2_conv4 (Conv2D)          (None, 255, 1, 32)   3104        ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk2_conv5 (Conv2D)          (None, 255, 1, 32)   3104        ['ReStk2_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 255, 1, 32)   0           ['ReStk2_conv5[0][0]',           \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 255, 1, 32)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 127, 1, 32)  0           ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk3_conv1 (Conv2D)          (None, 127, 1, 32)   1056        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " ReStk3_conv2 (Conv2D)          (None, 127, 1, 32)   3104        ['ReStk3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk3_conv3 (Conv2D)          (None, 127, 1, 32)   3104        ['ReStk3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 127, 1, 32)   0           ['ReStk3_conv3[0][0]',           \n",
            "                                                                  'ReStk3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 127, 1, 32)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk3_conv4 (Conv2D)          (None, 127, 1, 32)   3104        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk3_conv5 (Conv2D)          (None, 127, 1, 32)   3104        ['ReStk3_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 127, 1, 32)   0           ['ReStk3_conv5[0][0]',           \n",
            "                                                                  'activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 127, 1, 32)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 63, 1, 32)   0           ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk4_conv1 (Conv2D)          (None, 63, 1, 32)    1056        ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " ReStk4_conv2 (Conv2D)          (None, 63, 1, 32)    3104        ['ReStk4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk4_conv3 (Conv2D)          (None, 63, 1, 32)    3104        ['ReStk4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 63, 1, 32)    0           ['ReStk4_conv3[0][0]',           \n",
            "                                                                  'ReStk4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 63, 1, 32)    0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk4_conv4 (Conv2D)          (None, 63, 1, 32)    3104        ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk4_conv5 (Conv2D)          (None, 63, 1, 32)    3104        ['ReStk4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 63, 1, 32)    0           ['ReStk4_conv5[0][0]',           \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 63, 1, 32)    0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 31, 1, 32)   0           ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk5_conv1 (Conv2D)          (None, 31, 1, 32)    1056        ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " ReStk5_conv2 (Conv2D)          (None, 31, 1, 32)    3104        ['ReStk5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk5_conv3 (Conv2D)          (None, 31, 1, 32)    3104        ['ReStk5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 31, 1, 32)    0           ['ReStk5_conv3[0][0]',           \n",
            "                                                                  'ReStk5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 31, 1, 32)    0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk5_conv4 (Conv2D)          (None, 31, 1, 32)    3104        ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk5_conv5 (Conv2D)          (None, 31, 1, 32)    3104        ['ReStk5_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 31, 1, 32)    0           ['ReStk5_conv5[0][0]',           \n",
            "                                                                  'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 31, 1, 32)    0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 15, 1, 32)   0           ['activation_22[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ReStk6_conv1 (Conv2D)          (None, 15, 1, 32)    1056        ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " ReStk6_conv2 (Conv2D)          (None, 15, 1, 32)    3104        ['ReStk6_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " ReStk6_conv3 (Conv2D)          (None, 15, 1, 32)    3104        ['ReStk6_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 15, 1, 32)    0           ['ReStk6_conv3[0][0]',           \n",
            "                                                                  'ReStk6_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 15, 1, 32)    0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " ReStk6_conv4 (Conv2D)          (None, 15, 1, 32)    3104        ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " ReStk6_conv5 (Conv2D)          (None, 15, 1, 32)    3104        ['ReStk6_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 15, 1, 32)    0           ['ReStk6_conv5[0][0]',           \n",
            "                                                                  'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 15, 1, 32)    0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 7, 1, 32)    0           ['activation_24[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 224)          0           ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " dense1 (Dense)                 (None, 128)          28800       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['dense1[0][0]']                 \n",
            "                                                                                                  \n",
            " dense2 (Dense)                 (None, 128)          16512       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 128)          0           ['dense2[0][0]']                 \n",
            "                                                                                                  \n",
            " dense3 (Dense)                 (None, 10)           1290        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 10)           0           ['dense3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,442\n",
            "Trainable params: 126,442\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(classifier):\n",
        "    pred = classifier.predict(sig_dfTest)\n",
        "    acc = np.mean(np.argmax(pred,1)==txidNum_dfTest)\n",
        "\n",
        "    test_indx = ()\n",
        "    for indx in range(len(tx_list)):\n",
        "        cls_indx = np.where(txidNum_dfTest == indx)\n",
        "        test_indx = test_indx + (cls_indx[0][:n_test_samples],)\n",
        "    test_indx = np.concatenate(test_indx) \n",
        "    acc_bal = np.mean(np.argmax(pred[test_indx,:],1)==txidNum_dfTest[test_indx])\n",
        "    return acc,acc_bal"
      ],
      "metadata": {
        "id": "nay21tfQw68X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test_rx = 5"
      ],
      "metadata": {
        "id": "a-kavuVYxD72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights"
      ],
      "metadata": {
        "id": "A3Onf_eF2Yix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "-bYoPE9b3ECj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True\n",
        "continue_training = True\n",
        "nreal = 5\n",
        "\n",
        "real_list = list(range(nreal))\n",
        "nrx_list =  list(range( 0,len(rx_list_real[0])-n_test_rx+1,5))  # [0,len(rx_list_real[0])-1] #\n",
        "\n",
        "patience = 5\n",
        "n_epochs = 100\n",
        "\n",
        "smTest_results = []\n",
        "dfTest_results = []\n",
        "dfTestBal_results = []\n",
        "\n",
        "for real in real_list:\n",
        "    rx_list = rx_list_real[real]\n",
        "    rx_test_list = rx_list[-n_test_rx:]\n",
        "    test_dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_test_list)\n",
        "    test_augset_dfRx,_,_ = prepare_dataset(test_dataset,tx_list,val_frac=0.0, test_frac=0.0)\n",
        "\n",
        "    [sig_dfTest,txidNum_dfTest,txid_dfTest,cls_weights] = test_augset_dfRx\n",
        "    \n",
        "    cnt=np.histogram(txidNum_dfTest,bins=np.arange(len(tx_list)+1)-0.5)\n",
        "    n_test_samples = int(np.min(cnt[0]))\n",
        "\n",
        "    smTest_results_real = []\n",
        "    dfTest_results_real = []\n",
        "    dfTestBal_results_real = []\n",
        "    for nrx in nrx_list:\n",
        "        print(\"\");print(\"\")\n",
        "        print(\"nrx: {} - real: {} \".format(nrx,real))\n",
        "        fname_w = 'weights/d003_{:02d}_{:02d}.hd5'.format(nrx,real)\n",
        "        rx_train_list= rx_list[:nrx+1]\n",
        "\n",
        "        dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_train_list)\n",
        "\n",
        "        train_augset,val_augset,test_augset_smRx =  prepare_dataset(dataset,tx_list,\n",
        "                                                            val_frac=0.1, test_frac=0.1)\n",
        "        [sig_train,txidNum_train,txid_train,cls_weights] = train_augset\n",
        "        [sig_valid,txidNum_valid,txid_valid,_] = val_augset\n",
        "        [sig_smTest,txidNum_smTest,txid_smTest,cls_weights] = test_augset_smRx\n",
        "        \n",
        "        spl_weights = np.zeros((len(sig_train)))\n",
        "        for index in range(len(txid_train)):\n",
        "          spl_weights[index] = cls_weights[np.argmax(txid_train[index])]\n",
        "\n",
        "\n",
        "        if continue_training:\n",
        "            skip = os.path.isfile(fname_w)\n",
        "        else:\n",
        "            skip = False\n",
        "        classifier = create_net()\n",
        "        with tf.device('/device:GPU:0'):\n",
        "          if TRAIN and not skip:\n",
        "              filepath = 't_weights_0'\n",
        "              c=[ keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "                keras.callbacks.EarlyStopping(monitor='val_loss',  patience=patience)]\n",
        "              #history = classifier.fit(sig_train,txid_train,class_weight=cls_weights,validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs)\n",
        "              history = classifier.fit(sig_train,txid_train,sample_weight=spl_weights,\n",
        "                                      validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs, verbose=1)\n",
        "              classifier.load_weights(filepath)\n",
        "              classifier.save_weights(fname_w,save_format=\"h5\")\n",
        "          else:\n",
        "              classifier.load_weights(fname_w)\n",
        "\n",
        "        smTest_r = classifier.evaluate(sig_smTest,txid_smTest,verbose=0)[1]\n",
        "    #     dfTest_r = classifier.evaluate(sig_dfTest,txid_dfTest)[1]\n",
        "        dfTest_r,dfTestBal_r = evaluate_test(classifier)\n",
        "\n",
        "        print(smTest_r,dfTest_r)\n",
        "        smTest_results_real.append(smTest_r)\n",
        "        dfTest_results_real.append(dfTest_r)\n",
        "        dfTestBal_results_real.append(dfTestBal_r)\n",
        "        K.clear_session()\n",
        "    smTest_results.append(smTest_results_real)\n",
        "    dfTest_results.append(dfTest_results_real)\n",
        "    dfTestBal_results.append(dfTestBal_results_real)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FE952-bIxID7",
        "outputId": "68e55df7-2a98-40f4-eadb-9f26586aa877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e7494fe5acc6>:119: RuntimeWarning: invalid value encountered in true_divide\n",
            "  cls_weights = np.max(stat,axis=0)/stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "nrx: 0 - real: 0 \n",
            "Epoch 1/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 3.0102 - categorical_accuracy: 0.1107\n",
            "Epoch 1: val_loss improved from inf to 2.28529, saving model to t_weights_0\n",
            "50/50 [==============================] - 23s 202ms/step - loss: 3.0063 - categorical_accuracy: 0.1112 - val_loss: 2.2853 - val_categorical_accuracy: 0.2200\n",
            "Epoch 2/100\n",
            "47/50 [===========================>..] - ETA: 0s - loss: 2.8632 - categorical_accuracy: 0.1543\n",
            "Epoch 2: val_loss improved from 2.28529 to 1.85880, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 2.8424 - categorical_accuracy: 0.1625 - val_loss: 1.8588 - val_categorical_accuracy: 0.3650\n",
            "Epoch 3/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.9328 - categorical_accuracy: 0.4108\n",
            "Epoch 3: val_loss improved from 1.85880 to 0.96199, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.9189 - categorical_accuracy: 0.4131 - val_loss: 0.9620 - val_categorical_accuracy: 0.6550\n",
            "Epoch 4/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.1348 - categorical_accuracy: 0.6530\n",
            "Epoch 4: val_loss improved from 0.96199 to 0.62263, saving model to t_weights_0\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1271 - categorical_accuracy: 0.6556 - val_loss: 0.6226 - val_categorical_accuracy: 0.7450\n",
            "Epoch 5/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7913 - categorical_accuracy: 0.7710\n",
            "Epoch 5: val_loss improved from 0.62263 to 0.45202, saving model to t_weights_0\n",
            "50/50 [==============================] - 7s 148ms/step - loss: 0.7886 - categorical_accuracy: 0.7738 - val_loss: 0.4520 - val_categorical_accuracy: 0.8150\n",
            "Epoch 6/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6775 - categorical_accuracy: 0.8125\n",
            "Epoch 6: val_loss improved from 0.45202 to 0.38987, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.6766 - categorical_accuracy: 0.8138 - val_loss: 0.3899 - val_categorical_accuracy: 0.8900\n",
            "Epoch 7/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5533 - categorical_accuracy: 0.8304\n",
            "Epoch 7: val_loss improved from 0.38987 to 0.34546, saving model to t_weights_0\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.5582 - categorical_accuracy: 0.8319 - val_loss: 0.3455 - val_categorical_accuracy: 0.8950\n",
            "Epoch 8/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.8661\n",
            "Epoch 8: val_loss improved from 0.34546 to 0.34202, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.4638 - categorical_accuracy: 0.8669 - val_loss: 0.3420 - val_categorical_accuracy: 0.8800\n",
            "Epoch 9/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4283 - categorical_accuracy: 0.8852\n",
            "Epoch 9: val_loss improved from 0.34202 to 0.27542, saving model to t_weights_0\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.4261 - categorical_accuracy: 0.8856 - val_loss: 0.2754 - val_categorical_accuracy: 0.9150\n",
            "Epoch 10/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3507 - categorical_accuracy: 0.9095\n",
            "Epoch 10: val_loss improved from 0.27542 to 0.24452, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.3510 - categorical_accuracy: 0.9106 - val_loss: 0.2445 - val_categorical_accuracy: 0.9300\n",
            "Epoch 11/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2811 - categorical_accuracy: 0.9311\n",
            "Epoch 11: val_loss did not improve from 0.24452\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.2798 - categorical_accuracy: 0.9312 - val_loss: 0.2490 - val_categorical_accuracy: 0.9050\n",
            "Epoch 12/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2621 - categorical_accuracy: 0.9284\n",
            "Epoch 12: val_loss improved from 0.24452 to 0.23808, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 0.2594 - categorical_accuracy: 0.9300 - val_loss: 0.2381 - val_categorical_accuracy: 0.9250\n",
            "Epoch 13/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2381 - categorical_accuracy: 0.9324\n",
            "Epoch 13: val_loss did not improve from 0.23808\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.2455 - categorical_accuracy: 0.9306 - val_loss: 0.2934 - val_categorical_accuracy: 0.9100\n",
            "Epoch 14/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2554 - categorical_accuracy: 0.9235\n",
            "Epoch 14: val_loss improved from 0.23808 to 0.21284, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 160ms/step - loss: 0.2515 - categorical_accuracy: 0.9250 - val_loss: 0.2128 - val_categorical_accuracy: 0.9250\n",
            "Epoch 15/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2124 - categorical_accuracy: 0.9413\n",
            "Epoch 15: val_loss did not improve from 0.21284\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 0.2140 - categorical_accuracy: 0.9413 - val_loss: 0.2563 - val_categorical_accuracy: 0.9200\n",
            "Epoch 16/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1938 - categorical_accuracy: 0.9466\n",
            "Epoch 16: val_loss did not improve from 0.21284\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 0.2003 - categorical_accuracy: 0.9456 - val_loss: 0.2255 - val_categorical_accuracy: 0.9250\n",
            "Epoch 17/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.9541\n",
            "Epoch 17: val_loss did not improve from 0.21284\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.1822 - categorical_accuracy: 0.9531 - val_loss: 0.2774 - val_categorical_accuracy: 0.9150\n",
            "Epoch 18/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1578 - categorical_accuracy: 0.9598\n",
            "Epoch 18: val_loss improved from 0.21284 to 0.20824, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1589 - categorical_accuracy: 0.9594 - val_loss: 0.2082 - val_categorical_accuracy: 0.9350\n",
            "Epoch 19/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1182 - categorical_accuracy: 0.9656\n",
            "Epoch 19: val_loss improved from 0.20824 to 0.19268, saving model to t_weights_0\n",
            "50/50 [==============================] - 8s 157ms/step - loss: 0.1204 - categorical_accuracy: 0.9644 - val_loss: 0.1927 - val_categorical_accuracy: 0.9450\n",
            "Epoch 20/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9573\n",
            "Epoch 20: val_loss did not improve from 0.19268\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.1474 - categorical_accuracy: 0.9575 - val_loss: 0.2682 - val_categorical_accuracy: 0.9300\n",
            "Epoch 21/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1411 - categorical_accuracy: 0.9617\n",
            "Epoch 21: val_loss did not improve from 0.19268\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.1385 - categorical_accuracy: 0.9625 - val_loss: 0.2838 - val_categorical_accuracy: 0.9350\n",
            "Epoch 22/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1393 - categorical_accuracy: 0.9611\n",
            "Epoch 22: val_loss did not improve from 0.19268\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 0.1379 - categorical_accuracy: 0.9613 - val_loss: 0.3234 - val_categorical_accuracy: 0.9250\n",
            "Epoch 23/100\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1212 - categorical_accuracy: 0.9675\n",
            "Epoch 23: val_loss did not improve from 0.19268\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.1192 - categorical_accuracy: 0.9681 - val_loss: 0.3336 - val_categorical_accuracy: 0.9350\n",
            "Epoch 24/100\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.9661\n",
            "Epoch 24: val_loss did not improve from 0.19268\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.1262 - categorical_accuracy: 0.9656 - val_loss: 0.2369 - val_categorical_accuracy: 0.9450\n",
            "313/313 [==============================] - 2s 4ms/step\n",
            "0.9350000023841858 0.1425\n",
            "\n",
            "\n",
            "nrx: 5 - real: 0 \n",
            "Epoch 1/100\n",
            "293/295 [============================>.] - ETA: 0s - loss: 2.6152 - categorical_accuracy: 0.1685\n",
            "Epoch 1: val_loss improved from inf to 1.75761, saving model to t_weights_0\n",
            "295/295 [==============================] - 25s 42ms/step - loss: 2.6123 - categorical_accuracy: 0.1695 - val_loss: 1.7576 - val_categorical_accuracy: 0.3263\n",
            "Epoch 2/100\n",
            "292/295 [============================>.] - ETA: 0s - loss: 1.7794 - categorical_accuracy: 0.4518\n",
            "Epoch 2: val_loss improved from 1.75761 to 0.85401, saving model to t_weights_0\n",
            "295/295 [==============================] - 11s 38ms/step - loss: 1.7729 - categorical_accuracy: 0.4543 - val_loss: 0.8540 - val_categorical_accuracy: 0.7424\n",
            "Epoch 3/100\n",
            "294/295 [============================>.] - ETA: 0s - loss: 0.9990 - categorical_accuracy: 0.7465\n",
            "Epoch 3: val_loss improved from 0.85401 to 0.41298, saving model to t_weights_0\n",
            "295/295 [==============================] - 12s 40ms/step - loss: 0.9995 - categorical_accuracy: 0.7466 - val_loss: 0.4130 - val_categorical_accuracy: 0.8856\n",
            "Epoch 4/100\n",
            "294/295 [============================>.] - ETA: 0s - loss: 0.6548 - categorical_accuracy: 0.8409\n",
            "Epoch 4: val_loss improved from 0.41298 to 0.37712, saving model to t_weights_0\n",
            "295/295 [==============================] - 12s 39ms/step - loss: 0.6546 - categorical_accuracy: 0.8410 - val_loss: 0.3771 - val_categorical_accuracy: 0.8805\n",
            "Epoch 5/100\n",
            "293/295 [============================>.] - ETA: 0s - loss: 0.5259 - categorical_accuracy: 0.8700\n",
            "Epoch 5: val_loss improved from 0.37712 to 0.31405, saving model to t_weights_0\n",
            "295/295 [==============================] - 11s 38ms/step - loss: 0.5277 - categorical_accuracy: 0.8699 - val_loss: 0.3141 - val_categorical_accuracy: 0.9008\n",
            "Epoch 6/100\n",
            "293/295 [============================>.] - ETA: 0s - loss: 0.4594 - categorical_accuracy: 0.8855\n",
            "Epoch 6: val_loss did not improve from 0.31405\n",
            "295/295 [==============================] - 4s 15ms/step - loss: 0.4598 - categorical_accuracy: 0.8855 - val_loss: 0.3161 - val_categorical_accuracy: 0.9051\n",
            "Epoch 7/100\n",
            "294/295 [============================>.] - ETA: 0s - loss: 0.4241 - categorical_accuracy: 0.8948\n",
            "Epoch 7: val_loss did not improve from 0.31405\n",
            "295/295 [==============================] - 5s 18ms/step - loss: 0.4238 - categorical_accuracy: 0.8948 - val_loss: 0.3491 - val_categorical_accuracy: 0.8958\n",
            "Epoch 8/100\n",
            "295/295 [==============================] - ETA: 0s - loss: 0.3821 - categorical_accuracy: 0.9013\n",
            "Epoch 8: val_loss improved from 0.31405 to 0.27818, saving model to t_weights_0\n",
            "295/295 [==============================] - 11s 38ms/step - loss: 0.3821 - categorical_accuracy: 0.9013 - val_loss: 0.2782 - val_categorical_accuracy: 0.9169\n",
            "Epoch 9/100\n",
            "292/295 [============================>.] - ETA: 0s - loss: 0.3533 - categorical_accuracy: 0.9052\n",
            "Epoch 9: val_loss improved from 0.27818 to 0.25771, saving model to t_weights_0\n",
            "295/295 [==============================] - 11s 38ms/step - loss: 0.3540 - categorical_accuracy: 0.9051 - val_loss: 0.2577 - val_categorical_accuracy: 0.9153\n",
            "Epoch 10/100\n",
            "293/295 [============================>.] - ETA: 0s - loss: 0.3358 - categorical_accuracy: 0.9086\n",
            "Epoch 10: val_loss did not improve from 0.25771\n",
            "295/295 [==============================] - 5s 18ms/step - loss: 0.3372 - categorical_accuracy: 0.9083 - val_loss: 0.2762 - val_categorical_accuracy: 0.9186\n",
            "Epoch 11/100\n",
            "295/295 [==============================] - ETA: 0s - loss: 0.3169 - categorical_accuracy: 0.9103\n",
            "Epoch 11: val_loss did not improve from 0.25771\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.3169 - categorical_accuracy: 0.9103 - val_loss: 0.2706 - val_categorical_accuracy: 0.9161\n",
            "Epoch 12/100\n",
            "292/295 [============================>.] - ETA: 0s - loss: 0.3043 - categorical_accuracy: 0.9164\n",
            "Epoch 12: val_loss did not improve from 0.25771\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.3045 - categorical_accuracy: 0.9163 - val_loss: 0.2640 - val_categorical_accuracy: 0.9178\n",
            "Epoch 13/100\n",
            "292/295 [============================>.] - ETA: 0s - loss: 0.3019 - categorical_accuracy: 0.9166\n",
            "Epoch 13: val_loss did not improve from 0.25771\n",
            "295/295 [==============================] - 5s 17ms/step - loss: 0.3015 - categorical_accuracy: 0.9165 - val_loss: 0.2660 - val_categorical_accuracy: 0.9254\n",
            "Epoch 14/100\n",
            "293/295 [============================>.] - ETA: 0s - loss: 0.2682 - categorical_accuracy: 0.9263\n",
            "Epoch 14: val_loss did not improve from 0.25771\n",
            "295/295 [==============================] - 4s 15ms/step - loss: 0.2686 - categorical_accuracy: 0.9262 - val_loss: 0.2952 - val_categorical_accuracy: 0.9186\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "0.9093220233917236 0.3057\n",
            "\n",
            "\n",
            "nrx: 10 - real: 0 \n",
            "Epoch 1/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 2.2344 - categorical_accuracy: 0.2598\n",
            "Epoch 1: val_loss improved from inf to 1.28053, saving model to t_weights_0\n",
            "545/545 [==============================] - 28s 30ms/step - loss: 2.2344 - categorical_accuracy: 0.2598 - val_loss: 1.2805 - val_categorical_accuracy: 0.5491\n",
            "Epoch 2/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 1.1640 - categorical_accuracy: 0.6565\n",
            "Epoch 2: val_loss improved from 1.28053 to 0.70922, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 28ms/step - loss: 1.1640 - categorical_accuracy: 0.6565 - val_loss: 0.7092 - val_categorical_accuracy: 0.8069\n",
            "Epoch 3/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.7087 - categorical_accuracy: 0.8139\n",
            "Epoch 3: val_loss improved from 0.70922 to 0.46477, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.7084 - categorical_accuracy: 0.8139 - val_loss: 0.4648 - val_categorical_accuracy: 0.8633\n",
            "Epoch 4/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.8715\n",
            "Epoch 4: val_loss improved from 0.46477 to 0.31919, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.5100 - categorical_accuracy: 0.8717 - val_loss: 0.3192 - val_categorical_accuracy: 0.9110\n",
            "Epoch 5/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8909\n",
            "Epoch 5: val_loss improved from 0.31919 to 0.30317, saving model to t_weights_0\n",
            "545/545 [==============================] - 14s 26ms/step - loss: 0.4195 - categorical_accuracy: 0.8909 - val_loss: 0.3032 - val_categorical_accuracy: 0.9101\n",
            "Epoch 6/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.3649 - categorical_accuracy: 0.9061\n",
            "Epoch 6: val_loss did not improve from 0.30317\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.3662 - categorical_accuracy: 0.9058 - val_loss: 0.3170 - val_categorical_accuracy: 0.9092\n",
            "Epoch 7/100\n",
            "544/545 [============================>.] - ETA: 0s - loss: 0.3180 - categorical_accuracy: 0.9166\n",
            "Epoch 7: val_loss improved from 0.30317 to 0.26287, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 28ms/step - loss: 0.3181 - categorical_accuracy: 0.9166 - val_loss: 0.2629 - val_categorical_accuracy: 0.9252\n",
            "Epoch 8/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.3085 - categorical_accuracy: 0.9185\n",
            "Epoch 8: val_loss did not improve from 0.26287\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.3085 - categorical_accuracy: 0.9185 - val_loss: 0.3229 - val_categorical_accuracy: 0.9046\n",
            "Epoch 9/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.2724 - categorical_accuracy: 0.9274\n",
            "Epoch 9: val_loss did not improve from 0.26287\n",
            "545/545 [==============================] - 8s 15ms/step - loss: 0.2729 - categorical_accuracy: 0.9274 - val_loss: 0.2772 - val_categorical_accuracy: 0.9211\n",
            "Epoch 10/100\n",
            "544/545 [============================>.] - ETA: 0s - loss: 0.2614 - categorical_accuracy: 0.9297\n",
            "Epoch 10: val_loss improved from 0.26287 to 0.24665, saving model to t_weights_0\n",
            "545/545 [==============================] - 16s 29ms/step - loss: 0.2613 - categorical_accuracy: 0.9296 - val_loss: 0.2467 - val_categorical_accuracy: 0.9275\n",
            "Epoch 11/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.2542 - categorical_accuracy: 0.9312\n",
            "Epoch 11: val_loss did not improve from 0.24665\n",
            "545/545 [==============================] - 8s 15ms/step - loss: 0.2542 - categorical_accuracy: 0.9312 - val_loss: 0.2580 - val_categorical_accuracy: 0.9183\n",
            "Epoch 12/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9335\n",
            "Epoch 12: val_loss did not improve from 0.24665\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.2380 - categorical_accuracy: 0.9337 - val_loss: 0.2521 - val_categorical_accuracy: 0.9216\n",
            "Epoch 13/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.2246 - categorical_accuracy: 0.9388\n",
            "Epoch 13: val_loss did not improve from 0.24665\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.2244 - categorical_accuracy: 0.9388 - val_loss: 0.2654 - val_categorical_accuracy: 0.9234\n",
            "Epoch 14/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.2095 - categorical_accuracy: 0.9403\n",
            "Epoch 14: val_loss did not improve from 0.24665\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.2095 - categorical_accuracy: 0.9403 - val_loss: 0.2704 - val_categorical_accuracy: 0.9179\n",
            "Epoch 15/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.2155 - categorical_accuracy: 0.9374\n",
            "Epoch 15: val_loss improved from 0.24665 to 0.23505, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 28ms/step - loss: 0.2155 - categorical_accuracy: 0.9374 - val_loss: 0.2350 - val_categorical_accuracy: 0.9298\n",
            "Epoch 16/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.2032 - categorical_accuracy: 0.9419\n",
            "Epoch 16: val_loss improved from 0.23505 to 0.23286, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.2033 - categorical_accuracy: 0.9419 - val_loss: 0.2329 - val_categorical_accuracy: 0.9289\n",
            "Epoch 17/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.1943 - categorical_accuracy: 0.9450\n",
            "Epoch 17: val_loss improved from 0.23286 to 0.22558, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 28ms/step - loss: 0.1944 - categorical_accuracy: 0.9450 - val_loss: 0.2256 - val_categorical_accuracy: 0.9271\n",
            "Epoch 18/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.1916 - categorical_accuracy: 0.9457\n",
            "Epoch 18: val_loss did not improve from 0.22558\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1916 - categorical_accuracy: 0.9457 - val_loss: 0.2547 - val_categorical_accuracy: 0.9266\n",
            "Epoch 19/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.1791 - categorical_accuracy: 0.9479\n",
            "Epoch 19: val_loss improved from 0.22558 to 0.22551, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.1789 - categorical_accuracy: 0.9479 - val_loss: 0.2255 - val_categorical_accuracy: 0.9289\n",
            "Epoch 20/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1742 - categorical_accuracy: 0.9482\n",
            "Epoch 20: val_loss did not improve from 0.22551\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1743 - categorical_accuracy: 0.9482 - val_loss: 0.2541 - val_categorical_accuracy: 0.9335\n",
            "Epoch 21/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.1799 - categorical_accuracy: 0.9474\n",
            "Epoch 21: val_loss did not improve from 0.22551\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.1791 - categorical_accuracy: 0.9476 - val_loss: 0.2523 - val_categorical_accuracy: 0.9261\n",
            "Epoch 22/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.9495\n",
            "Epoch 22: val_loss did not improve from 0.22551\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1677 - categorical_accuracy: 0.9494 - val_loss: 0.2402 - val_categorical_accuracy: 0.9330\n",
            "Epoch 23/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.1625 - categorical_accuracy: 0.9521\n",
            "Epoch 23: val_loss improved from 0.22551 to 0.21892, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.1625 - categorical_accuracy: 0.9521 - val_loss: 0.2189 - val_categorical_accuracy: 0.9335\n",
            "Epoch 24/100\n",
            "542/545 [============================>.] - ETA: 0s - loss: 0.1685 - categorical_accuracy: 0.9509\n",
            "Epoch 24: val_loss did not improve from 0.21892\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1687 - categorical_accuracy: 0.9508 - val_loss: 0.2703 - val_categorical_accuracy: 0.9220\n",
            "Epoch 25/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1650 - categorical_accuracy: 0.9511\n",
            "Epoch 25: val_loss did not improve from 0.21892\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.1647 - categorical_accuracy: 0.9512 - val_loss: 0.2232 - val_categorical_accuracy: 0.9326\n",
            "Epoch 26/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.1482 - categorical_accuracy: 0.9547\n",
            "Epoch 26: val_loss did not improve from 0.21892\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1482 - categorical_accuracy: 0.9547 - val_loss: 0.2499 - val_categorical_accuracy: 0.9317\n",
            "Epoch 27/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1448 - categorical_accuracy: 0.9557\n",
            "Epoch 27: val_loss improved from 0.21892 to 0.20877, saving model to t_weights_0\n",
            "545/545 [==============================] - 15s 27ms/step - loss: 0.1445 - categorical_accuracy: 0.9557 - val_loss: 0.2088 - val_categorical_accuracy: 0.9372\n",
            "Epoch 28/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1533 - categorical_accuracy: 0.9529\n",
            "Epoch 28: val_loss did not improve from 0.20877\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1534 - categorical_accuracy: 0.9530 - val_loss: 0.2275 - val_categorical_accuracy: 0.9344\n",
            "Epoch 29/100\n",
            "543/545 [============================>.] - ETA: 0s - loss: 0.1570 - categorical_accuracy: 0.9522\n",
            "Epoch 29: val_loss did not improve from 0.20877\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.1569 - categorical_accuracy: 0.9522 - val_loss: 0.2450 - val_categorical_accuracy: 0.9399\n",
            "Epoch 30/100\n",
            "544/545 [============================>.] - ETA: 0s - loss: 0.1465 - categorical_accuracy: 0.9543\n",
            "Epoch 30: val_loss did not improve from 0.20877\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1463 - categorical_accuracy: 0.9544 - val_loss: 0.2383 - val_categorical_accuracy: 0.9367\n",
            "Epoch 31/100\n",
            "544/545 [============================>.] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9581\n",
            "Epoch 31: val_loss did not improve from 0.20877\n",
            "545/545 [==============================] - 9s 16ms/step - loss: 0.1365 - categorical_accuracy: 0.9580 - val_loss: 0.2602 - val_categorical_accuracy: 0.9312\n",
            "Epoch 32/100\n",
            "545/545 [==============================] - ETA: 0s - loss: 0.1516 - categorical_accuracy: 0.9546\n",
            "Epoch 32: val_loss did not improve from 0.20877\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.1516 - categorical_accuracy: 0.9546 - val_loss: 0.2317 - val_categorical_accuracy: 0.9312\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "0.9408257007598877 0.4817\n",
            "\n",
            "\n",
            "nrx: 15 - real: 0 \n",
            "Epoch 1/100\n",
            "783/785 [============================>.] - ETA: 0s - loss: 2.1024 - categorical_accuracy: 0.3121\n",
            "Epoch 1: val_loss improved from inf to 1.23029, saving model to t_weights_0\n",
            "785/785 [==============================] - 31s 25ms/step - loss: 2.1009 - categorical_accuracy: 0.3126 - val_loss: 1.2303 - val_categorical_accuracy: 0.5557\n",
            "Epoch 2/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 1.2108 - categorical_accuracy: 0.6524\n",
            "Epoch 2: val_loss improved from 1.23029 to 0.63141, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 25ms/step - loss: 1.2113 - categorical_accuracy: 0.6525 - val_loss: 0.6314 - val_categorical_accuracy: 0.8083\n",
            "Epoch 3/100\n",
            "785/785 [==============================] - ETA: 0s - loss: 0.7214 - categorical_accuracy: 0.8195\n",
            "Epoch 3: val_loss improved from 0.63141 to 0.40891, saving model to t_weights_0\n",
            "785/785 [==============================] - 20s 25ms/step - loss: 0.7214 - categorical_accuracy: 0.8195 - val_loss: 0.4089 - val_categorical_accuracy: 0.8844\n",
            "Epoch 4/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.5290 - categorical_accuracy: 0.8707\n",
            "Epoch 4: val_loss improved from 0.40891 to 0.35871, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 24ms/step - loss: 0.5286 - categorical_accuracy: 0.8708 - val_loss: 0.3587 - val_categorical_accuracy: 0.8987\n",
            "Epoch 5/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.4350 - categorical_accuracy: 0.8927\n",
            "Epoch 5: val_loss improved from 0.35871 to 0.31745, saving model to t_weights_0\n",
            "785/785 [==============================] - 20s 25ms/step - loss: 0.4354 - categorical_accuracy: 0.8925 - val_loss: 0.3175 - val_categorical_accuracy: 0.9115\n",
            "Epoch 6/100\n",
            "783/785 [============================>.] - ETA: 0s - loss: 0.3873 - categorical_accuracy: 0.9005\n",
            "Epoch 6: val_loss improved from 0.31745 to 0.30018, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 24ms/step - loss: 0.3871 - categorical_accuracy: 0.9006 - val_loss: 0.3002 - val_categorical_accuracy: 0.9150\n",
            "Epoch 7/100\n",
            "782/785 [============================>.] - ETA: 0s - loss: 0.3494 - categorical_accuracy: 0.9083\n",
            "Epoch 7: val_loss improved from 0.30018 to 0.28859, saving model to t_weights_0\n",
            "785/785 [==============================] - 20s 25ms/step - loss: 0.3491 - categorical_accuracy: 0.9084 - val_loss: 0.2886 - val_categorical_accuracy: 0.9140\n",
            "Epoch 8/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.3209 - categorical_accuracy: 0.9146\n",
            "Epoch 8: val_loss improved from 0.28859 to 0.24673, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 24ms/step - loss: 0.3206 - categorical_accuracy: 0.9147 - val_loss: 0.2467 - val_categorical_accuracy: 0.9268\n",
            "Epoch 9/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.2985 - categorical_accuracy: 0.9185\n",
            "Epoch 9: val_loss did not improve from 0.24673\n",
            "785/785 [==============================] - 12s 16ms/step - loss: 0.2988 - categorical_accuracy: 0.9184 - val_loss: 0.2722 - val_categorical_accuracy: 0.9207\n",
            "Epoch 10/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.2859 - categorical_accuracy: 0.9218\n",
            "Epoch 10: val_loss did not improve from 0.24673\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.2863 - categorical_accuracy: 0.9217 - val_loss: 0.2673 - val_categorical_accuracy: 0.9213\n",
            "Epoch 11/100\n",
            "783/785 [============================>.] - ETA: 0s - loss: 0.2702 - categorical_accuracy: 0.9256\n",
            "Epoch 11: val_loss improved from 0.24673 to 0.24051, saving model to t_weights_0\n",
            "785/785 [==============================] - 18s 23ms/step - loss: 0.2699 - categorical_accuracy: 0.9258 - val_loss: 0.2405 - val_categorical_accuracy: 0.9283\n",
            "Epoch 12/100\n",
            "782/785 [============================>.] - ETA: 0s - loss: 0.2536 - categorical_accuracy: 0.9293\n",
            "Epoch 12: val_loss did not improve from 0.24051\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.2538 - categorical_accuracy: 0.9292 - val_loss: 0.2569 - val_categorical_accuracy: 0.9277\n",
            "Epoch 13/100\n",
            "785/785 [==============================] - ETA: 0s - loss: 0.2430 - categorical_accuracy: 0.9309\n",
            "Epoch 13: val_loss improved from 0.24051 to 0.24004, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 24ms/step - loss: 0.2430 - categorical_accuracy: 0.9309 - val_loss: 0.2400 - val_categorical_accuracy: 0.9261\n",
            "Epoch 14/100\n",
            "785/785 [==============================] - ETA: 0s - loss: 0.2431 - categorical_accuracy: 0.9310\n",
            "Epoch 14: val_loss did not improve from 0.24004\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.2431 - categorical_accuracy: 0.9310 - val_loss: 0.2462 - val_categorical_accuracy: 0.9280\n",
            "Epoch 15/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.2328 - categorical_accuracy: 0.9342\n",
            "Epoch 15: val_loss did not improve from 0.24004\n",
            "785/785 [==============================] - 12s 16ms/step - loss: 0.2327 - categorical_accuracy: 0.9343 - val_loss: 0.2919 - val_categorical_accuracy: 0.9178\n",
            "Epoch 16/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.2144 - categorical_accuracy: 0.9379\n",
            "Epoch 16: val_loss did not improve from 0.24004\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.2143 - categorical_accuracy: 0.9379 - val_loss: 0.2819 - val_categorical_accuracy: 0.9232\n",
            "Epoch 17/100\n",
            "782/785 [============================>.] - ETA: 0s - loss: 0.2116 - categorical_accuracy: 0.9398\n",
            "Epoch 17: val_loss improved from 0.24004 to 0.23396, saving model to t_weights_0\n",
            "785/785 [==============================] - 19s 24ms/step - loss: 0.2119 - categorical_accuracy: 0.9397 - val_loss: 0.2340 - val_categorical_accuracy: 0.9334\n",
            "Epoch 18/100\n",
            "785/785 [==============================] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9410\n",
            "Epoch 18: val_loss did not improve from 0.23396\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.1997 - categorical_accuracy: 0.9410 - val_loss: 0.2392 - val_categorical_accuracy: 0.9331\n",
            "Epoch 19/100\n",
            "783/785 [============================>.] - ETA: 0s - loss: 0.1976 - categorical_accuracy: 0.9414\n",
            "Epoch 19: val_loss did not improve from 0.23396\n",
            "785/785 [==============================] - 12s 15ms/step - loss: 0.1975 - categorical_accuracy: 0.9414 - val_loss: 0.2391 - val_categorical_accuracy: 0.9306\n",
            "Epoch 20/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.2005 - categorical_accuracy: 0.9410\n",
            "Epoch 20: val_loss did not improve from 0.23396\n",
            "785/785 [==============================] - 12s 16ms/step - loss: 0.2003 - categorical_accuracy: 0.9410 - val_loss: 0.2409 - val_categorical_accuracy: 0.9312\n",
            "Epoch 21/100\n",
            "784/785 [============================>.] - ETA: 0s - loss: 0.1951 - categorical_accuracy: 0.9425\n",
            "Epoch 21: val_loss did not improve from 0.23396\n",
            "785/785 [==============================] - 12s 16ms/step - loss: 0.1951 - categorical_accuracy: 0.9425 - val_loss: 0.2399 - val_categorical_accuracy: 0.9354\n",
            "Epoch 22/100\n",
            "782/785 [============================>.] - ETA: 0s - loss: 0.1812 - categorical_accuracy: 0.9461\n",
            "Epoch 22: val_loss did not improve from 0.23396\n",
            "785/785 [==============================] - 12s 16ms/step - loss: 0.1815 - categorical_accuracy: 0.9459 - val_loss: 0.2622 - val_categorical_accuracy: 0.9261\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "0.9299362897872925 0.5232\n",
            "\n",
            "\n",
            "nrx: 20 - real: 0 \n",
            "Epoch 1/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 1.9647 - categorical_accuracy: 0.3485\n",
            "Epoch 1: val_loss improved from inf to 1.00887, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 37s 24ms/step - loss: 1.9642 - categorical_accuracy: 0.3487 - val_loss: 1.0089 - val_categorical_accuracy: 0.6774\n",
            "Epoch 2/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.9832 - categorical_accuracy: 0.7253\n",
            "Epoch 2: val_loss improved from 1.00887 to 0.47318, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 22ms/step - loss: 0.9825 - categorical_accuracy: 0.7255 - val_loss: 0.4732 - val_categorical_accuracy: 0.8726\n",
            "Epoch 3/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.6094 - categorical_accuracy: 0.8446\n",
            "Epoch 3: val_loss improved from 0.47318 to 0.40469, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 22s 21ms/step - loss: 0.6097 - categorical_accuracy: 0.8444 - val_loss: 0.4047 - val_categorical_accuracy: 0.8857\n",
            "Epoch 4/100\n",
            "1028/1030 [============================>.] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.8809\n",
            "Epoch 4: val_loss improved from 0.40469 to 0.33740, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 22ms/step - loss: 0.4631 - categorical_accuracy: 0.8810 - val_loss: 0.3374 - val_categorical_accuracy: 0.9080\n",
            "Epoch 5/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.3979 - categorical_accuracy: 0.8960\n",
            "Epoch 5: val_loss improved from 0.33740 to 0.32727, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 22ms/step - loss: 0.3984 - categorical_accuracy: 0.8961 - val_loss: 0.3273 - val_categorical_accuracy: 0.9032\n",
            "Epoch 6/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.3577 - categorical_accuracy: 0.9050\n",
            "Epoch 6: val_loss improved from 0.32727 to 0.26801, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 22s 21ms/step - loss: 0.3577 - categorical_accuracy: 0.9051 - val_loss: 0.2680 - val_categorical_accuracy: 0.9214\n",
            "Epoch 7/100\n",
            "1030/1030 [==============================] - ETA: 0s - loss: 0.3244 - categorical_accuracy: 0.9132\n",
            "Epoch 7: val_loss improved from 0.26801 to 0.25135, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 24s 23ms/step - loss: 0.3244 - categorical_accuracy: 0.9132 - val_loss: 0.2514 - val_categorical_accuracy: 0.9214\n",
            "Epoch 8/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.3172 - categorical_accuracy: 0.9143\n",
            "Epoch 8: val_loss did not improve from 0.25135\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.3176 - categorical_accuracy: 0.9142 - val_loss: 0.4316 - val_categorical_accuracy: 0.8595\n",
            "Epoch 9/100\n",
            "1030/1030 [==============================] - ETA: 0s - loss: 0.2861 - categorical_accuracy: 0.9209\n",
            "Epoch 9: val_loss did not improve from 0.25135\n",
            "1030/1030 [==============================] - 17s 17ms/step - loss: 0.2861 - categorical_accuracy: 0.9209 - val_loss: 0.2617 - val_categorical_accuracy: 0.9223\n",
            "Epoch 10/100\n",
            "1030/1030 [==============================] - ETA: 0s - loss: 0.2783 - categorical_accuracy: 0.9226\n",
            "Epoch 10: val_loss improved from 0.25135 to 0.24161, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 22s 21ms/step - loss: 0.2783 - categorical_accuracy: 0.9226 - val_loss: 0.2416 - val_categorical_accuracy: 0.9250\n",
            "Epoch 11/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.2621 - categorical_accuracy: 0.9248\n",
            "Epoch 11: val_loss did not improve from 0.24161\n",
            "1030/1030 [==============================] - 16s 16ms/step - loss: 0.2619 - categorical_accuracy: 0.9249 - val_loss: 0.2761 - val_categorical_accuracy: 0.9155\n",
            "Epoch 12/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.2567 - categorical_accuracy: 0.9275\n",
            "Epoch 12: val_loss improved from 0.24161 to 0.23693, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 24s 23ms/step - loss: 0.2568 - categorical_accuracy: 0.9274 - val_loss: 0.2369 - val_categorical_accuracy: 0.9260\n",
            "Epoch 13/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.2357 - categorical_accuracy: 0.9324\n",
            "Epoch 13: val_loss improved from 0.23693 to 0.23571, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 25s 24ms/step - loss: 0.2356 - categorical_accuracy: 0.9324 - val_loss: 0.2357 - val_categorical_accuracy: 0.9248\n",
            "Epoch 14/100\n",
            "1028/1030 [============================>.] - ETA: 0s - loss: 0.2386 - categorical_accuracy: 0.9314\n",
            "Epoch 14: val_loss improved from 0.23571 to 0.21666, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 22ms/step - loss: 0.2388 - categorical_accuracy: 0.9314 - val_loss: 0.2167 - val_categorical_accuracy: 0.9352\n",
            "Epoch 15/100\n",
            "1030/1030 [==============================] - ETA: 0s - loss: 0.2324 - categorical_accuracy: 0.9328\n",
            "Epoch 15: val_loss did not improve from 0.21666\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.2324 - categorical_accuracy: 0.9328 - val_loss: 0.2214 - val_categorical_accuracy: 0.9289\n",
            "Epoch 16/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.2224 - categorical_accuracy: 0.9348\n",
            "Epoch 16: val_loss improved from 0.21666 to 0.20039, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 22ms/step - loss: 0.2222 - categorical_accuracy: 0.9349 - val_loss: 0.2004 - val_categorical_accuracy: 0.9357\n",
            "Epoch 17/100\n",
            "1028/1030 [============================>.] - ETA: 0s - loss: 0.2149 - categorical_accuracy: 0.9395\n",
            "Epoch 17: val_loss did not improve from 0.20039\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.2147 - categorical_accuracy: 0.9395 - val_loss: 0.2140 - val_categorical_accuracy: 0.9364\n",
            "Epoch 18/100\n",
            "1030/1030 [==============================] - ETA: 0s - loss: 0.2078 - categorical_accuracy: 0.9386\n",
            "Epoch 18: val_loss did not improve from 0.20039\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.2078 - categorical_accuracy: 0.9386 - val_loss: 0.2131 - val_categorical_accuracy: 0.9301\n",
            "Epoch 19/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.2039 - categorical_accuracy: 0.9411\n",
            "Epoch 19: val_loss improved from 0.20039 to 0.19896, saving model to t_weights_0\n",
            "1030/1030 [==============================] - 23s 23ms/step - loss: 0.2039 - categorical_accuracy: 0.9411 - val_loss: 0.1990 - val_categorical_accuracy: 0.9422\n",
            "Epoch 20/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.1990 - categorical_accuracy: 0.9400\n",
            "Epoch 20: val_loss did not improve from 0.19896\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.1989 - categorical_accuracy: 0.9400 - val_loss: 0.2309 - val_categorical_accuracy: 0.9303\n",
            "Epoch 21/100\n",
            "1028/1030 [============================>.] - ETA: 0s - loss: 0.1919 - categorical_accuracy: 0.9422\n",
            "Epoch 21: val_loss did not improve from 0.19896\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.1919 - categorical_accuracy: 0.9422 - val_loss: 0.2558 - val_categorical_accuracy: 0.9260\n",
            "Epoch 22/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.1974 - categorical_accuracy: 0.9408\n",
            "Epoch 22: val_loss did not improve from 0.19896\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.1973 - categorical_accuracy: 0.9409 - val_loss: 0.2464 - val_categorical_accuracy: 0.9228\n",
            "Epoch 23/100\n",
            "1027/1030 [============================>.] - ETA: 0s - loss: 0.1916 - categorical_accuracy: 0.9430\n",
            "Epoch 23: val_loss did not improve from 0.19896\n",
            "1030/1030 [==============================] - 16s 15ms/step - loss: 0.1919 - categorical_accuracy: 0.9429 - val_loss: 0.2083 - val_categorical_accuracy: 0.9352\n",
            "Epoch 24/100\n",
            "1029/1030 [============================>.] - ETA: 0s - loss: 0.1849 - categorical_accuracy: 0.9459\n",
            "Epoch 24: val_loss did not improve from 0.19896\n",
            "1030/1030 [==============================] - 17s 17ms/step - loss: 0.1849 - categorical_accuracy: 0.9459 - val_loss: 0.2180 - val_categorical_accuracy: 0.9357\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "0.9337378740310669 0.5945\n",
            "\n",
            "\n",
            "nrx: 25 - real: 0 \n",
            "Epoch 1/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 1.8489 - categorical_accuracy: 0.3597\n",
            "Epoch 1: val_loss improved from inf to 1.12652, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 40s 22ms/step - loss: 1.8489 - categorical_accuracy: 0.3597 - val_loss: 1.1265 - val_categorical_accuracy: 0.6285\n",
            "Epoch 2/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.9304 - categorical_accuracy: 0.7242\n",
            "Epoch 2: val_loss improved from 1.12652 to 0.56980, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.9304 - categorical_accuracy: 0.7242 - val_loss: 0.5698 - val_categorical_accuracy: 0.8185\n",
            "Epoch 3/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.5620 - categorical_accuracy: 0.8482\n",
            "Epoch 3: val_loss improved from 0.56980 to 0.42868, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.5620 - categorical_accuracy: 0.8482 - val_loss: 0.4287 - val_categorical_accuracy: 0.8672\n",
            "Epoch 4/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.4351 - categorical_accuracy: 0.8806\n",
            "Epoch 4: val_loss improved from 0.42868 to 0.34219, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.4349 - categorical_accuracy: 0.8807 - val_loss: 0.3422 - val_categorical_accuracy: 0.8956\n",
            "Epoch 5/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.3717 - categorical_accuracy: 0.8959\n",
            "Epoch 5: val_loss improved from 0.34219 to 0.29503, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 21ms/step - loss: 0.3715 - categorical_accuracy: 0.8959 - val_loss: 0.2950 - val_categorical_accuracy: 0.9156\n",
            "Epoch 6/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.3344 - categorical_accuracy: 0.9061\n",
            "Epoch 6: val_loss did not improve from 0.29503\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.3345 - categorical_accuracy: 0.9060 - val_loss: 0.3241 - val_categorical_accuracy: 0.9001\n",
            "Epoch 7/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.3119 - categorical_accuracy: 0.9122\n",
            "Epoch 7: val_loss improved from 0.29503 to 0.27250, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.3119 - categorical_accuracy: 0.9122 - val_loss: 0.2725 - val_categorical_accuracy: 0.9132\n",
            "Epoch 8/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.2862 - categorical_accuracy: 0.9187\n",
            "Epoch 8: val_loss did not improve from 0.27250\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.2862 - categorical_accuracy: 0.9187 - val_loss: 0.2730 - val_categorical_accuracy: 0.9184\n",
            "Epoch 9/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.2693 - categorical_accuracy: 0.9210\n",
            "Epoch 9: val_loss did not improve from 0.27250\n",
            "1260/1260 [==============================] - 21s 16ms/step - loss: 0.2694 - categorical_accuracy: 0.9210 - val_loss: 0.2767 - val_categorical_accuracy: 0.9188\n",
            "Epoch 10/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.2605 - categorical_accuracy: 0.9242\n",
            "Epoch 10: val_loss improved from 0.27250 to 0.24925, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.2605 - categorical_accuracy: 0.9242 - val_loss: 0.2492 - val_categorical_accuracy: 0.9242\n",
            "Epoch 11/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.2483 - categorical_accuracy: 0.9283\n",
            "Epoch 11: val_loss improved from 0.24925 to 0.24862, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.2482 - categorical_accuracy: 0.9283 - val_loss: 0.2486 - val_categorical_accuracy: 0.9214\n",
            "Epoch 12/100\n",
            "1257/1260 [============================>.] - ETA: 0s - loss: 0.2346 - categorical_accuracy: 0.9302\n",
            "Epoch 12: val_loss did not improve from 0.24862\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.2348 - categorical_accuracy: 0.9302 - val_loss: 0.2539 - val_categorical_accuracy: 0.9178\n",
            "Epoch 13/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.2292 - categorical_accuracy: 0.9321\n",
            "Epoch 13: val_loss improved from 0.24862 to 0.23179, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.2293 - categorical_accuracy: 0.9320 - val_loss: 0.2318 - val_categorical_accuracy: 0.9315\n",
            "Epoch 14/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.2186 - categorical_accuracy: 0.9354\n",
            "Epoch 14: val_loss did not improve from 0.23179\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.2186 - categorical_accuracy: 0.9354 - val_loss: 0.2328 - val_categorical_accuracy: 0.9293\n",
            "Epoch 15/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.2121 - categorical_accuracy: 0.9367\n",
            "Epoch 15: val_loss did not improve from 0.23179\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.2121 - categorical_accuracy: 0.9367 - val_loss: 0.2324 - val_categorical_accuracy: 0.9293\n",
            "Epoch 16/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.2108 - categorical_accuracy: 0.9366\n",
            "Epoch 16: val_loss did not improve from 0.23179\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.2108 - categorical_accuracy: 0.9366 - val_loss: 0.2461 - val_categorical_accuracy: 0.9295\n",
            "Epoch 17/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.2016 - categorical_accuracy: 0.9392\n",
            "Epoch 17: val_loss did not improve from 0.23179\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.2016 - categorical_accuracy: 0.9392 - val_loss: 0.2738 - val_categorical_accuracy: 0.9140\n",
            "Epoch 18/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.2013 - categorical_accuracy: 0.9396\n",
            "Epoch 18: val_loss improved from 0.23179 to 0.21651, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 21ms/step - loss: 0.2013 - categorical_accuracy: 0.9395 - val_loss: 0.2165 - val_categorical_accuracy: 0.9353\n",
            "Epoch 19/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1888 - categorical_accuracy: 0.9423\n",
            "Epoch 19: val_loss did not improve from 0.21651\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1888 - categorical_accuracy: 0.9424 - val_loss: 0.2466 - val_categorical_accuracy: 0.9273\n",
            "Epoch 20/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.1928 - categorical_accuracy: 0.9419\n",
            "Epoch 20: val_loss improved from 0.21651 to 0.21629, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.1928 - categorical_accuracy: 0.9419 - val_loss: 0.2163 - val_categorical_accuracy: 0.9329\n",
            "Epoch 21/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1860 - categorical_accuracy: 0.9432\n",
            "Epoch 21: val_loss did not improve from 0.21629\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.1860 - categorical_accuracy: 0.9432 - val_loss: 0.2368 - val_categorical_accuracy: 0.9339\n",
            "Epoch 22/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.1859 - categorical_accuracy: 0.9446\n",
            "Epoch 22: val_loss improved from 0.21629 to 0.21579, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.1859 - categorical_accuracy: 0.9446 - val_loss: 0.2158 - val_categorical_accuracy: 0.9365\n",
            "Epoch 23/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.1798 - categorical_accuracy: 0.9467\n",
            "Epoch 23: val_loss did not improve from 0.21579\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1798 - categorical_accuracy: 0.9467 - val_loss: 0.2362 - val_categorical_accuracy: 0.9252\n",
            "Epoch 24/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1798 - categorical_accuracy: 0.9457\n",
            "Epoch 24: val_loss improved from 0.21579 to 0.21448, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.1798 - categorical_accuracy: 0.9458 - val_loss: 0.2145 - val_categorical_accuracy: 0.9369\n",
            "Epoch 25/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1725 - categorical_accuracy: 0.9469\n",
            "Epoch 25: val_loss improved from 0.21448 to 0.21023, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 22ms/step - loss: 0.1726 - categorical_accuracy: 0.9469 - val_loss: 0.2102 - val_categorical_accuracy: 0.9347\n",
            "Epoch 26/100\n",
            "1257/1260 [============================>.] - ETA: 0s - loss: 0.1716 - categorical_accuracy: 0.9475\n",
            "Epoch 26: val_loss improved from 0.21023 to 0.20529, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 28s 22ms/step - loss: 0.1716 - categorical_accuracy: 0.9476 - val_loss: 0.2053 - val_categorical_accuracy: 0.9396\n",
            "Epoch 27/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.1708 - categorical_accuracy: 0.9480\n",
            "Epoch 27: val_loss did not improve from 0.20529\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.1708 - categorical_accuracy: 0.9480 - val_loss: 0.2079 - val_categorical_accuracy: 0.9394\n",
            "Epoch 28/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1664 - categorical_accuracy: 0.9500\n",
            "Epoch 28: val_loss did not improve from 0.20529\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1664 - categorical_accuracy: 0.9500 - val_loss: 0.2238 - val_categorical_accuracy: 0.9329\n",
            "Epoch 29/100\n",
            "1259/1260 [============================>.] - ETA: 0s - loss: 0.1636 - categorical_accuracy: 0.9499\n",
            "Epoch 29: val_loss did not improve from 0.20529\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.1637 - categorical_accuracy: 0.9499 - val_loss: 0.2189 - val_categorical_accuracy: 0.9335\n",
            "Epoch 30/100\n",
            "1257/1260 [============================>.] - ETA: 0s - loss: 0.1605 - categorical_accuracy: 0.9510\n",
            "Epoch 30: val_loss improved from 0.20529 to 0.19526, saving model to t_weights_0\n",
            "1260/1260 [==============================] - 27s 21ms/step - loss: 0.1605 - categorical_accuracy: 0.9510 - val_loss: 0.1953 - val_categorical_accuracy: 0.9402\n",
            "Epoch 31/100\n",
            "1257/1260 [============================>.] - ETA: 0s - loss: 0.1627 - categorical_accuracy: 0.9507\n",
            "Epoch 31: val_loss did not improve from 0.19526\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1626 - categorical_accuracy: 0.9507 - val_loss: 0.2142 - val_categorical_accuracy: 0.9373\n",
            "Epoch 32/100\n",
            "1257/1260 [============================>.] - ETA: 0s - loss: 0.1546 - categorical_accuracy: 0.9529\n",
            "Epoch 32: val_loss did not improve from 0.19526\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.1545 - categorical_accuracy: 0.9530 - val_loss: 0.2126 - val_categorical_accuracy: 0.9357\n",
            "Epoch 33/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.9512\n",
            "Epoch 33: val_loss did not improve from 0.19526\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1612 - categorical_accuracy: 0.9512 - val_loss: 0.2210 - val_categorical_accuracy: 0.9365\n",
            "Epoch 34/100\n",
            "1258/1260 [============================>.] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.9531\n",
            "Epoch 34: val_loss did not improve from 0.19526\n",
            "1260/1260 [==============================] - 20s 16ms/step - loss: 0.1516 - categorical_accuracy: 0.9531 - val_loss: 0.2087 - val_categorical_accuracy: 0.9347\n",
            "Epoch 35/100\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 0.1515 - categorical_accuracy: 0.9531\n",
            "Epoch 35: val_loss did not improve from 0.19526\n",
            "1260/1260 [==============================] - 21s 17ms/step - loss: 0.1515 - categorical_accuracy: 0.9531 - val_loss: 0.2192 - val_categorical_accuracy: 0.9337\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "0.9374627470970154 0.6614\n",
            "\n",
            "\n",
            "nrx: 0 - real: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e7494fe5acc6>:119: RuntimeWarning: invalid value encountered in true_divide\n",
            "  cls_weights = np.max(stat,axis=0)/stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d89af7d45200>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                 keras.callbacks.EarlyStopping(monitor='val_loss',  patience=patience)]\n\u001b[1;32m     58\u001b[0m               \u001b[0;31m#history = classifier.fit(sig_train,txid_train,class_weight=cls_weights,validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m               history = classifier.fit(sig_train,txid_train,sample_weight=spl_weights,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                       validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs, verbose=1)\n\u001b[1;32m     61\u001b[0m               \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_variable_creation_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         ._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    765\u001b[0m             *args, **kwds))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[1;32m   1267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \"\"\"\n\u001b[1;32m    542\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_current_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1251\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2639\u001b[0;31m       return self._replica_ctx_update(\n\u001b[0m\u001b[1;32m   2640\u001b[0m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[1;32m   2641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2518\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3109\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3115\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3116\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3117\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3118\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3119\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2516\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2635\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3709\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3712\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3714\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3716\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3717\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m--> 142\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m    143\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mtf___update_step_xla\u001b[0;34m(self, gradient, variable, key)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;34mf\"`tf.keras.optimizers.legacy.{self.__class__.__name__}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             )\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_velocities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_2_power\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_1_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11353\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11354\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11355\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m  11356\u001b[0m         \"Sub\", x=x, y=y, name=name)\n\u001b[1;32m  11357\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0m\u001b[1;32m    778\u001b[0m                              \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_type_attr_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                              input_types)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       \u001b[0;31m# Handle the case where the name is a keyword or built-in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smTest_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkCqlGsaQLKR",
        "outputId": "3f1de751-f727-4c9d-93d5-0ce24753dded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.8999999761581421,\n",
              "  0.8983050584793091,\n",
              "  0.9201834797859192,\n",
              "  0.9156050682067871,\n",
              "  0.9135922193527222,\n",
              "  0.9102640748023987]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.dpi'] = 100\n",
        "plt.errorbar(np.array(nrx_list)+1,np.mean(smTest_results,0),np.std(smTest_results,0),capsize=4)\n",
        "plt.errorbar(np.array(nrx_list)+1,np.mean(dfTest_results,0),np.std(dfTest_results,0),capsize=4)\n",
        "plt.legend(['Same Rx(s)','Diff. Rx'])\n",
        "plt.xlabel('N Train Rx')\n",
        "plt.ylabel('Class. Accuracy')\n",
        "#plt.xticks(range(0,len(nrx_list),2))\n",
        "plt.grid()\n",
        "print(np.mean(dfTest_results,0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "9nuftguw1wE5",
        "outputId": "d76c7418-887f-44cc-94c8-259833369dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1425, 0.3057, 0.4817, 0.5232, 0.5945, 0.6614]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABglklEQVR4nO3deVxU9f7H8dfMMGwirmwiiruZW2ouWbapmGlpm9csTc1uJvda1C1tcWmRbDFv5c0Wte1aZpvdNMsoK3+almbaIrnjAogbKAgMM+f3x+gAAsoozMDwfj4e82DOOp/5Mjpvzvd7zjEZhmEgIiIi4iPM3i5AREREpCIp3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpft4uwNMcDgf79++ndu3amEwmb5cjIiIi5WAYBseOHaNRo0aYzWc+NlPjws3+/fuJiYnxdhkiIiJyDvbs2UPjxo3PuE6NCze1a9cGnI0TGhoKgM1m46uvvqJ///5YrVZvlufT1M6eoXb2DLWz56itPaOqt3NWVhYxMTGu7/EzqXHh5lRXVGhoaLFwExwcTGhoaJX8hfoKtbNnqJ09Q+3sOWprz6gu7VyeISUaUCwiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKQo3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKTXuxpkiUj4n8u1knrARHGChlr8fFvPZb1YnIlIVKNyI1GD5BQ72HMnh+78y2LjnKBnH8lyPoydsxdb1t5gJsJoJ8DNTN8hKg5AAQgL8qHXyERJgOfnztHn+fsXmhwT4EWg1l+vOviIi50LhRsTHORwG+zNPsPNgdrHHroPZ7DlyArvDKNd+8u0O8u0OjgEHj+ezLSP7nGsymygzCJUWmIqHo5Pziqzr76cedqk5HA4Dm8OB3WFQ4DAosBsUOBwU2A3sDgOb3XHy58npU+ueWu/kc7vDUbiO3UG+rYCNaSYO/piCgYkCR2n7K9ymwGFw8HguR7Jt2A0Dh8M4+RMiQgO4vnN0idpbR4TQrlGdSm8jhZtz9Mf+TP5KP+6aPpqTz/s/7aFesD/1a/lTL9hKvVr+1A/2JzTIygVRtT3yC5WayTAMMo7nsTMjm+0HskjabebzhRvZfTiHXYdyyC9wlLltkNVCVJ1AQoOshNUOICwkgLDaAYTXDiDY30KBwyDP5iC3wE6ezUFegZ0GIf40CAkgO6+A43l2svMKTj4v/Ol8bi82PzvfDoDDgGO5BRzLLaiQ9+9vMVOr3EeOzhCYToYmdcFVT4ZR+KVb4DCw251f7EW//E//wi463/ml7ygWGApDQdF1i67j3MZe6vZF1y09jBQ4zlRb8f2dCipG+f4eOUcW2LnlvPfyRyp8m5xRYn6PZvVZ9Pde573/s1G4OUfT//cHa3ceLvf6/hYznWPq0qhuINH1goiuG0yjuoE0rhdEo7pBBPvrVyFnl5ljY+ehbHYePM7Ogzknj8IcZ9fBHI7nFQ0KZth/wDVltZhoUj+YZg1DaNbw1M9aNGtYi4jQAI91ETkcBjk2e4kgVCIEFQlNx/NLzju1bt7J0JZvd5Cf4+BIju0sFZRPkNVy5iDk70eQ1UTKfhNZP+0lNNi/WLebcxsLIQF+BFktVaYLzjDK8+Xq/Mu85Jd4yb/4SwsGpf2FbyvzqIID28kQUnT/rnVO1VPg4GiWhVnJq7AbZdR2so6aymwCP7MZP4sJi9mE1WLGYjbhZzbhZzE5l5mLL7Oetq4ZOJiRTuNGUfj7WbCYzSXWObU/i9mM1WziUHYeR7JtmM0mLCYTZjNYTCZqB1pp1yi0RJ2tI0I80h76Rj1HUwe3K3bkJvOEjT9TsziSk8/h7HyO5Ng4kp3P0RM27A6DfLuDdbvKDkP1gq0nQ48z7ETXDXIFn+i6QdSv5V9l/oOUypWTX8CugznsOpRdoivpcHZ+mduZTNC4XhBN6wdjOp7B5V0uoGVEKM0bhtCobiB+Fu933ZjNJkJOBoCICthfgd1Bdp7dFYBKDUelzMvOLzrf7np+6svxhM3OCZudg8fPUgAWluz+48zv2YTr6NGpwFM8MFkIslqwOyj2ZV9qIHCc1i1gd5Td9WA/7S//k0cFqi8TnMiptL0HWS00D6vlCgB+FvPJL/KTP08LCae+4AvnF13X7JpXGAhO29+pbcxmLBYTVvPJ8FBkfon9ngoaJ7dxrWc2Ya6Ao402m41ly5YxcGAnrFZrBbSq9yjcnKN2jeqUq5vJ7jDIOJbHvqMnnI8jJ9hf5Pm+oyc4nlfgDEM5Nn7bl1XqfgKt5uKhp05QsTAUVadqfHlJ+ZwayLszI5tdh7LZcTDb9Tw1M/eM24bXDnAddSn6iKkfTKDVUvgfVK+m1f4/qLPxs5ipE2ymTvD5v0/DMMgrcBQPPPllhKO8ArJO5PPXzhTqNowgJ99RIjBl5xdgGCe74PIKOJZXMV1wlcF62pd28S/gM//F71xW8i/8U9OF+y3cZ7GjAGf54vezmMBwsH7dWnpf0ovAAP+S4eBULUXCwNb0LHZk5GA2Ua4/DD01FkQ8Q+GmklnMJiLrBBJZJ5CuTeuVuk7mCVvx0HNa+Mk4lkeuzcGOjGx2lDGI02yCyFBnl9epEHTqeeOTz9X15Vl2h8H+oydcR2B2nAwvOw9ms/csA3nrBFlp1rAWzU8Gl9giP0MC9HusDCaTiUCrhUCrhQblOHLuDJG7GDjwolJDpMNhcKJYF5ydBz/8lT/TjpW7pib1g7nzsmaFf60XDRyWUwHC2T1gKREOin/Zl7VOdRhfZLPZyEyGrk3rlTuwX9SkPhc1qV/JlUlVpf8lq4A6QVbqBJXePwmQV2An9WhuidBzKgylHs0l3+5gf2Yu+zNzgSOl7qdusNUZek4e7WlctBusXhAN1PXltqIDeU8/AlOegbzNGtaiWVgtmjUoDC/NG9aiXi1/D74LqQxms8nV/RR+ct7zt3Qq1p19NjqaIHJuFG6qgQA/C7Env/hK43AYHDyex94yur32HT3BsdwCjubYOJpj4/f9pXd9BfiZXUd8io79OTUdWScQaw3t+io2kDcjm52HcsoYyFtc0YG8zcNqEXsyxDQPq0V4bc8N5JWqobzd2SJyfhRufIDZbCI8NJDw0EC6NCm96ysr1+YMPUdKdnvtP3qCA8fyyCtwsOOg8+hDqa9jgojQwDK7vaLrBlGrGneZnD6Qt2g3UnkG8jZrGEKzBsEnj8aE0KxBrSozkFdEpCapvt9E4pbQQCuhkVbaRpbd9ZWWmVsi/OzPPHU0yNn1lZqZS2pmLut3l971VSfIWuxoT9EQFBHiV8nXZzi7ogN5dx7Mdh6NOfk8LevMA3kjQgOIbeA86tKsYS3X85j6wQT4WTz0DkRE5GwUbgRwdn01bVCLpg3O0PWVnVd8vI8rCOWy70gOWbkFZJ6wkXnCxh+ppXd9+ZkszN66isb1gouN9zkVhCLrBJ731WZPDeTdefDkOJiT4WXXoWz2HM7hTGfD1g22Fp6B1MA5Hia2gQbyiohUJ/rfWsrFbDYRXjuQ8NqBXFRG19exXBv7j+ay72jOyeBzchD0kRz2H80l/VguBYaJXYecV80tjckEEbUDT17sMPhk6Cl+4cPagdZiA3lPPwKz+/CZB/IG+1ucY1/CnIN3Tz1v1kADeUVEfIHCjVSY2oFW2kRaaRNZu9Tl2SfyeP+z5bS5qCdpx0o//T2/wEFaVi5pWblsSDla6n6CrBYcJ69JUhZ/i5kmp8a/nPbQQF4REd/m9XAzZ84cnn32WdLS0ujUqRMvvfQS3bt3L3Vdm81GYmIib731Fvv27aNNmzbMnDmTAQMGeLhqORf+fmYaBjrvLVLatSoMw+Dg8fxi3V5vrNpBelZesfVO2OxlvkabiBDeGHUxjeoGVYvrd4iISMXzarhZtGgRCQkJzJ07lx49ejB79mzi4uJITk4mPDy8xPqPPvoo7777Lq+//jpt27blyy+/ZOjQoaxevZqLLrrIC+9AKpLJZHLeuLF2AJ1j6gLQu2WDYtcFybXZOZKTj8lkomEt/xJnIrWOCCGmfrAnyxYRkSrGq+Fm1qxZjBs3jtGjRwMwd+5cli5dyvz585k0aVKJ9d955x0eeeQRBg4cCMD48eP5+uuvef7553n33Xc9Wrt4hq4LIiIi7vJauMnPz2f9+vVMnjzZNc9sNtO3b1/WrFlT6jZ5eXkEBgYWmxcUFMSqVavKfJ28vDzy8gq7NbKynGfx2Gw2bDab63nRn1I51M6eoXb2DLWz56itPaOqt7M7dXkt3Bw8eBC73U5ERPF7A0dERLBly5ZSt4mLi2PWrFn06dOHFi1akJSUxMcff4zdXvYYjMTERKZPn15i/ldffUVwcPHuixUrVpzDOxF3qZ09Q+3sGWpnz1Fbe0ZVbeecnPLfFd7rA4rd8e9//5tx48bRtm1bTCYTLVq0YPTo0cyfP7/MbSZPnkxCQoJrOisri5iYGPr3709oqPOCdjabjRUrVtCvXz+fv4uyN6mdPUPt7BlqZ89RW3tGVW/nUz0v5eG1cNOwYUMsFgvp6enF5qenpxMZGVnqNmFhYXz66afk5uZy6NAhGjVqxKRJk2jevHmZrxMQEEBAQECJ+VartcQvr7R5UvHUzp6hdvYMtbPnqK09o6q2szs1ee2mN/7+/nTt2pWkpCTXPIfDQVJSEr169TrjtoGBgURHR1NQUMBHH33E9ddfX9nlioiISDXh1W6phIQERo0aRbdu3ejevTuzZ88mOzvbdfbUyJEjiY6OJjExEYC1a9eyb98+OnfuzL59+5g2bRoOh4MHH3zQm29DREREqhCvhpthw4aRkZHBlClTSEtLo3Pnzixfvtw1yDglJQWzufDgUm5uLo8++ig7duwgJCSEgQMH8s4771C3bl0vvQMRERGparw+oDg+Pp74+PhSl61cubLY9OWXX84ff/zhgapERESkuvLamBsRERGRyqBwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhP8Xq4mTNnDrGxsQQGBtKjRw/WrVt3xvVnz55NmzZtCAoKIiYmhvvuu4/c3FwPVSsiIiJVnVfDzaJFi0hISGDq1Kls2LCBTp06ERcXx4EDB0pdf+HChUyaNImpU6fy559/Mm/ePBYtWsTDDz/s4cpFRESkqvLz5ovPmjWLcePGMXr0aADmzp3L0qVLmT9/PpMmTSqx/urVq+nduze33norALGxsQwfPpy1a9eW+Rp5eXnk5eW5prOysgCw2WzYbDbX86I/pXKonT1D7ewZamfPUVt7RlVvZ3fqMhmGYVRiLWXKz88nODiYDz/8kCFDhrjmjxo1iqNHj7JkyZIS2yxcuJB77rmHr776iu7du7Njxw6uvfZabr/99jKP3kybNo3p06eXuq/g4OAKez8iIiJSeXJycrj11lvJzMwkNDT0jOt67cjNwYMHsdvtREREFJsfERHBli1bSt3m1ltv5eDBg1x66aUYhkFBQQF33333GbulJk+eTEJCgms6KyuLmJgY+vfv72ocm83GihUr6NevH1artQLenZRG7ewZamfPUDt7jtraM6p6O5/qeSkPr3ZLuWvlypXMmDGD//znP/To0YNt27YxceJEnnjiCR577LFStwkICCAgIKDEfKvVWuKXV9o8qXhqZ89QO3uG2tlz1NaeUVXb2Z2avBZuGjZsiMViIT09vdj89PR0IiMjS93mscce4/bbb+fOO+8EoEOHDmRnZ3PXXXfxyCOPYDZ7/eQvERER8TKvpQF/f3+6du1KUlKSa57D4SApKYlevXqVuk1OTk6JAGOxWADw0tAhERERqWK82i2VkJDAqFGj6NatG927d2f27NlkZ2e7zp4aOXIk0dHRJCYmAjB48GBmzZrFRRdd5OqWeuyxxxg8eLAr5IiIiEjN5tVwM2zYMDIyMpgyZQppaWl07tyZ5cuXuwYZp6SkFDtS8+ijj2IymXj00UfZt28fYWFhDB48mKeeespbb0FERESqGK8PKI6Pjyc+Pr7UZStXriw27efnx9SpU5k6daoHKhMREZHqSCNwRURExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpCjciIiLiUxRuRERExKco3IiIiIhPUbgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpVSLczJkzh9jYWAIDA+nRowfr1q0rc90rrrgCk8lU4nHttdd6sGIRERGpqrwebhYtWkRCQgJTp05lw4YNdOrUibi4OA4cOFDq+h9//DGpqamux2+//YbFYuHmm2/2cOUiIiJSFfl5u4BZs2Yxbtw4Ro8eDcDcuXNZunQp8+fPZ9KkSSXWr1+/frHp999/n+Dg4DLDTV5eHnl5ea7prKwsAGw2GzabzfW86E+pHGpnz1A7e4ba2XPU1p5R1dvZnbpMhmEYlVjLGeXn5xMcHMyHH37IkCFDXPNHjRrF0aNHWbJkyVn30aFDB3r16sVrr71W6vJp06Yxffr0EvMXLlxIcHDwOdcuIiIinpOTk8Ott95KZmYmoaGhZ1zXq0duDh48iN1uJyIiotj8iIgItmzZctbt161bx2+//ca8efPKXGfy5MkkJCS4prOysoiJiaF///6uxrHZbKxYsYJ+/fphtVrP8d3I2aidPUPt7BlqZ89RW3tGVW/nUz0v5eH1bqnzMW/ePDp06ED37t3LXCcgIICAgIAS861Wa4lfXmnzpOKpnT1D7ewZamfPUVt7RlVtZ3dq8uqA4oYNG2KxWEhPTy82Pz09ncjIyDNum52dzfvvv8/YsWMrs0QRERGpZrwabvz9/enatStJSUmueQ6Hg6SkJHr16nXGbRcvXkxeXh633XZbZZcpIiIi1YjXu6USEhIYNWoU3bp1o3v37syePZvs7GzX2VMjR44kOjqaxMTEYtvNmzePIUOG0KBBA2+ULSIiIlWU18PNsGHDyMjIYMqUKaSlpdG5c2eWL1/uGmSckpKC2Vz8AFNycjKrVq3iq6++8kbJIiIiUoV5PdwAxMfHEx8fX+qylStXlpjXpk0bvHgGu4iIiFRhXr9CsYiIiEhFUrgRERERn6JwIyIiIj5F4UZERER8isKNiIiI+BSFGxEREfEpboebHTt2VEYdIiIiIhXC7XDTsmVLrrzySt59911yc3MroyYRERGpbgwD0n6DlTNh/VteLcXti/ht2LCBBQsWkJCQQHx8PMOGDWPs2LFnvDO3iIiI+KB9G2DLUkjdCPt/gZxDzvl1GoM1qOT6YW0hqmOll+V2uOncuTP//ve/ef755/nss8948803ufTSS2ndujVjxozh9ttvJywsrDJqFREREW/Lz4Ed3zpDzaZF4CgouU7mXvh4XMn5TXvD6GWVXuI5337Bz8+PG264gWuvvZb//Oc/TJ48mQceeICHH36YW265hZkzZxIVFVWRtYqIiIg35ByGv5Y7A822JCg4UbjMvxZEdoRGF0F4O/ALKHs/YW0rv1bOI9z8/PPPzJ8/n/fff59atWrxwAMPMHbsWPbu3cv06dO5/vrrWbduXUXWKiIiIp5yZDckL3MGmt3/B4ajcFmdJtD2WuejSS+wVIlbVbq4Xc2sWbNYsGABycnJDBw4kLfffpuBAwe67tzdrFkz3nzzTWJjYyu6VhEREakshkFozm7M3890HqVJ31x8eWQHaHMy0ER2AJPJO3WWg9vh5pVXXmHMmDHccccdZXY7hYeHM2/evPMuTkRERCqRvQBS1sCWpfht+ZwrM/dA8sllJrNzjEzba6HNQKjX1KulusPtcLN169azruPv78+oUaPOqSARERGpRPk5sP0bZ3fTX1/AiSMAmIACkz/mVn0xtxsMreKgVgPv1nqO3A43CxYsICQkhJtvvrnY/MWLF5OTk6NQIyIiUtVkHyocELz9m+IDgoPqQ5trKGgZx/KtecQNGorZavVerRXA7XCTmJjIq6++WmJ+eHg4d911l8KNiIhIVXBklzPMbFnq7HoqOiC4bhNoO8jZ5RTTEyx+GDYb9u2Vf5q2J7gdblJSUmjWrFmJ+U2bNiUlJaVCihIRERE3GQakbSoMNOm/FV8e2bEw0ERcWKUHBJ8vt8NNeHg4mzZtKnE21K+//kqDBtWzb05ERKRashdAyurCQJO5p3CZyQJNLzkZaAY6j9bUEG6Hm+HDh/PPf/6T2rVr06dPHwC+++47Jk6cyN/+9rcKL1BERESKyM8uMiB4uWtAMAB+QdDyamegaR0HwfW9V6cXuR1unnjiCXbt2sXVV1+Nn59zc4fDwciRI5kxY0aFFygiIlLjZR+E5C+cgWbHt1BQ5MbVQfWdp2q3vRaaXwH+wV4rs6pwO9z4+/uzaNEinnjiCX799VeCgoLo0KEDTZtWn/PfRUREqrzDOwu7m/b8eNqA4KZFBgT3qHJXCPa2c26N1q1b07p164qsRUREpOYyDEj9tTDQHPi9+PKoToWBJrydTw8IPl/nFG727t3LZ599RkpKCvn5+cWWzZo1q0IKExER8Xl2G+wuMiA4a2/hMpMFYns7A02ba2rUgODz5Xa4SUpK4rrrrqN58+Zs2bKF9u3bs2vXLgzDoEuXLpVRo4iIiO/IOw7bk04OCP4Sco8WLrMGFw4IbtW/xg4IPl9uh5vJkyfzwAMPMH36dGrXrs1HH31EeHg4I0aMYMCAAZVRo4iISPV2PMN5q4MtS2H7t2DPK1wW3BDaDHAGmuZXgDXIa2X6CrfDzZ9//sl7773n3NjPjxMnThASEsLjjz/O9ddfz/jx4yu8SBERkWrn0HZIXnbyCsE/AkbhsnqxJ8fPDIKY7mC2eKtKn+R2uKlVq5ZrnE1UVBTbt2/nwgsvBODgwYMVW52IiEh1YRiQurHIgOA/ii+P6lxkQPAFGhBcidwONz179mTVqlVccMEFDBw4kPvvv5/Nmzfz8ccf07Nnz8qoUUREpGqy22DXKmeYSV4GWfsKl5ksEHtpkQHBMd6rs4ZxO9zMmjWL48ePAzB9+nSOHz/OokWLaNWqlc6UEhER35d3HLZ97Qw0W7+E3MzCZdZaRQYE99OAYC9xK9zY7Xb27t1Lx44dAWcX1dy5cyulMBERkSrj+IEiVwheWcqA4GtODgi+XAOCqwCzOytbLBb69+/PkSNHzr5yOc2ZM4fY2FgCAwPp0aMH69atO+P6R48eZcKECURFRREQEEDr1q1Ztsw3btEuIiJVyKHt8H8vwrw4eK41/O+fziM19jyo1wwu+QeM+RIe+Auuf9l5xpOCTZXgdrdU+/bt2bFjB82aNTvvF1+0aBEJCQnMnTuXHj16MHv2bOLi4khOTiY8PLzE+vn5+fTr14/w8HA+/PBDoqOj2b17N3Xr1j3vWkREpIYzDNi/oXBAcMaW4ssbXeQcDNx2EIS11YDgKsztcPPkk0/ywAMP8MQTT9C1a1dq1apVbHloaGi59zVr1izGjRvH6NGjAZg7dy5Lly5l/vz5TJo0qcT68+fP5/Dhw6xevRqr1QpAbGzsGV8jLy+PvLzCw4dZWVkA2Gw2bDab63nRn1I51M6eoXb2DLWz51RqW9vzMe1ejemvZZj/+gLTsVTXIsPsh9G0N0brgThaD4DQ6MLtCgoqvhYvq+qfaXfqMhmGYZx9tUJmc2FPlqlIajUMA5PJhN1uL9d+8vPzCQ4O5sMPP2TIkCGu+aNGjeLo0aMsWbKkxDYDBw6kfv36BAcHs2TJEsLCwrj11lt56KGHsFhKv0bAtGnTmD59eon5CxcuJDhYd04VEalp/OwnCM/aTGTmeiKzfsVqz3EtKzAHkB7akbQ6XUkP7YTNr9YZ9iSelJOTw6233kpmZuZZD6S4feTm22+/PefCijp48CB2u52IiIhi8yMiItiyZUup2+zYsYNvvvmGESNGsGzZMrZt28Y999yDzWZj6tSppW4zefJkEhISXNNZWVnExMTQv39/V+PYbDZWrFhBv379XEeEpOKpnT1D7ewZamfPqZC2zj7oPDqTvAzTru8x2Qvvi2jUCsNoNQBHm4EYsZcR7hdIyYERvq+qf6ZP9byUh9vh5vLLL3d3kwrjcDgIDw/ntddew2Kx0LVrV/bt28ezzz5bZrgJCAggICCgxHyr1Vril1faPKl4amfPUDt7htrZc9xq69RNsGcd7P8F9v0MGckUu0JwrXDnGJpGnTHVb44pvB3mqI6VUnd1U1U/0+7U5Ha4+f7778+4vE+fPuXaT8OGDbFYLKSnpxebn56eTmRkZKnbREVFYbVai3VBXXDBBaSlpZGfn4+/v3+5XltERHzU8Qz48zNIml78+jOnyz7gPPNp65fO6aa9YbTOvPUVboebK664osS8omNvyjvmxt/fn65du5KUlOQac+NwOEhKSiI+Pr7UbXr37s3ChQtxOByusT9//fUXUVFRCjYiIjXVqUDzx6fOqwUbjsJldZtCdFdo3A1qhZW9j7C2lV6meI7b4eb0a9zYbDZ++eUXHnvsMZ566im39pWQkMCoUaPo1q0b3bt3Z/bs2WRnZ7vOnho5ciTR0dEkJiYCMH78eF5++WUmTpzIP/7xD7Zu3cqMGTP45z//6e7bEBGR6uz4AWeg+f1T2P1/xQNNo4ug3RBodz3UP//Llkj143a4qVOnTol5/fr1w9/fn4SEBNavX1/ufQ0bNoyMjAymTJlCWloanTt3Zvny5a5BxikpKcXOzoqJieHLL7/kvvvuo2PHjkRHRzNx4kQeeughd9+GiIhUN8cPwLYvFGjkrNwON2WJiIggOTnZ7e3i4+PL7IZauXJliXm9evXixx9/dPt1RESkGjp+APNvn3DJ1gX4bUwuGWguHOoMNPVivVaiVD1uh5tNmzYVmzYMg9TUVJ5++mk6d+5cUXWJiEhNdSz95BiaJbD7/7AYDlyjZRp1gQuHKNDIGbkdbjp37ozJZOL0a//17NmT+fPnV1hhIiJSg5wKNKe6nIqctu2Iuog/TG1oM/RBrGEtvFaiVB9uh5udO3cWmzabzYSFhREYGFhhRYmISA1whkBDdFfXGBp7SCO2L1tGm7pNvFSoVDduh5umTZtWRh0iIlITnC3QnBpDUzTIVNF7HUnV5Xa4+ec//0nLli1LnH798ssvs23bNmbPnl1RtYmIiC84lgZ/nLwOze7VFA803QrH0OjIjFQQt8PNRx99xGeffVZi/iWXXMLTTz+tcCMiIgo04lVuh5tDhw6Veq2b0NBQDh48WCFFiYhINXQq0Pz+CaSsoVigaXxx4XVo6sZ4q0KpIdwONy1btmT58uUlrk3zxRdf0Lx58worTEREqoGs1MIxNAo0UkW4HW4SEhKIj48nIyODq666CoCkpCSef/55dUmJiNQErkDzCaT8SPFA093Z5XTBdQo04jVuh5sxY8aQl5fHU089xRNPPAFAbGwsr7zyCiNHjqzwAkVEpArI2l84hqasQNPueqjT2EsFihQ6p9svjB8/nvHjx5ORkUFQUBAhISEVXZeIiHjbWQPNUGh3nQKNVDnndBG/goICWrVqRVhY4e3jt27ditVqJTY2tiLrExERT8ra77ztwe+fwp7T7uMX0+PkGBoFGqna3A43d9xxB2PGjKFVq1bF5q9du5Y33nij1JtdiohIFXa2QHPhUOcYmjrRXilPxF1uh5tffvmF3r17l5jfs2fPMu/uLSIiVUzmvsJBwXvWFl8W07NwULACjVRDbocbk8nEsWPHSszPzMzEbrdXSFEiIlIJMvc5j9D88WkZgebkGJrQRl4pT6SiuB1u+vTpQ2JiIu+99x4WiwUAu91OYmIil156aYUXKCIi5+FMgaZJr8IxNAo04kPcDjczZ86kT58+tGnThssuuwyAH374gaysLL755psKL1BERNyUubdwDM3edUUWmKBJTwUa8Xluh5t27dqxadMmXn75ZX799VeCgoIYOXIk8fHx1K9fvzJqFBGRszljoOlVOIYmNMpLBYp4zjld56ZRo0bMmDGj2LyjR4/y8ssva1CxiIinHN1T2OW096ciCxRopGY7p3BTVFJSEvPmzeOTTz4hODhY4UZEpDKdKdA0vcTZ5XTBYAUaqdHOKdzs2bOHBQsWsGDBAlJSUhg2bBiffPIJV199dUXXJyIipwLN75/Avp+LLCgSaNpdB7UjvVWhSJVS7nBjs9n49NNPeeONN/jhhx8YMGAAzz77LMOHD+fRRx+lXbt2lVmniEjNcjSlcAxNaYHmwqHOIzQKNCIllDvcREdH07ZtW2677Tbef/996tWrB8Dw4cMrrTgRkRrljIGm98kxNAo0ImdT7nBTUFCAyWTCZDK5rm8jIiLnwZYLB/6AXaucY2j2rS+ysGiguQ5qR3ipSJHqp9zhZv/+/Xz00UfMmzePiRMncs0113DbbbdhMpkqsz4REd+Qdwx+XwK7fnAeoclMgaxUMIpe2d0EDVtDdFeI7uK8r1NUR6+VLFJdlTvcBAYGMmLECEaMGMH27dtZsGAB//znPykoKOCpp57ijjvu4KqrrtJRHRGRnMOQ+qvzkbbJ+fPQdsA4y4YGHEx2Pn5d6DxyM3qZJyoW8SnndLZUixYtePLJJ3n88cf58ssvmTdvHoMGDaJ27docPHiwomsUEamaDAOOpULGH8WDTOae0tevFQ61o6Buk8JHUD0o6wh4WNvKq13Eh53XdW7MZjPXXHMN11xzDRkZGbzzzjsVVZeISNViGHBkJ6Q6A4xl/6/EpfyEdWNW6evXbw6RHSGqk7NrKbIThIR5tmaRGuq8L+J3SlhYGAkJCRW1OxER77EXwKGtriDjPCKzCfIyXauYgUDAMJkxhbUtEmQ6QWR7CKzjtfJFaroKCzciItVSQZ7zjKVTQSb1V0j/HQpOlFzX4g8RF0JkR+zh7fm/HcfpNWQs1mAFGZGqROFGRGqOvOOQ/tvJEHMyzGT8CY6Ckutaa53sTipyRCasDVisADhsNo6kLwNrsIffhIicTZUIN3PmzOHZZ58lLS2NTp068dJLL9G9e/dS133zzTcZPXp0sXkBAQHk5uZ6olQRqS5yDhcO8D0VZA5to9QzloLqnexOOhVkOjvHzJjNnq5aRCqA18PNokWLSEhIYO7cufTo0YPZs2cTFxdHcnIy4eHhpW4TGhpKcnKya1rX2hGp4Y6lFXYpnQozmSmlr1s7qsjYmJNhpk7jss9YEpFqp8LCzZIlS8jMzGTkyJFubTdr1izGjRvnOhozd+5cli5dyvz585k0aVKp25hMJiIjy3f58by8PPLy8lzTWVnOMxtsNhs2m831vOhPqRxqZ8/w6XY2DDi6G1P6Zkypm5w/0zZhyj5Q+up1YzEiO558dMCI6AAhpfzRVFBKt9RZ+HQ7VzFqa8+o6u3sTl0mwzDOdlWpcmnbti1bt27FbreffeWT8vPzCQ4O5sMPP2TIkCGu+aNGjeLo0aMsWbKkxDZvvvkmd955J9HR0TgcDrp06cKMGTO48MILS32NadOmMX369BLzFy5cSHCw+spFqizDQe3cVOqc2E2dnF3Onyd242/PKbkqJo4FNiIzqClHg2PJDGpKZlATCvxqeaFwEakMOTk53HrrrWRmZhIaGnrGdSss3JyL/fv3Ex0dzerVq+nVq5dr/oMPPsh3333H2rVrS2yzZs0atm7dSseOHcnMzOS5557j+++/5/fff6dx48Yl1i/tyE1MTAwHDx50NY7NZmPFihX069cPq9VaCe9UQO3sKdWynQvyIGNL4ZGYtE2YDvyByVZKkLH4Y4RdAJEdCo/KhLfz+MDeatnO1ZTa2jOqejtnZWXRsGHDcoUbr4+5cVevXr2KBaFLLrmECy64gFdffZUnnniixPoBAQEEBASUmG+1Wkv88kqbJxVP7ewZVbad87Mh7beTg303OsfIHNgCjlIOOVtrQWQH51lLJ8fImMLaYvLz93jZZamy7eyD1NaeUVXb2Z2a3A43y5cvJyQkhEsvvRRwnun0+uuv065dO+bMmUO9evXKva+GDRtisVhIT08vNj89Pb3cY2qsVisXXXQR27ZtK/+bEBHPOHHktAvh/QoHt1LqGUuBdQuv5hvV2TnYt0ELMOt+dSLiHrfDzb/+9S9mzpwJwObNm7n//vtJSEjg22+/JSEhgQULFpR7X/7+/nTt2pWkpCTXmBuHw0FSUhLx8fHl2ofdbmfz5s0MHDjQ3bciIhXpWFqRIHPyrKWjZZyxFBJZJMicPHOpTozOWBKRCuF2uNm5cyft2rUD4KOPPmLQoEHMmDGDDRs2nFPASEhIYNSoUXTr1o3u3bsze/ZssrOzXWdPjRw5kujoaBITEwF4/PHH6dmzJy1btuTo0aM8++yz7N69mzvvvNPt1xaRc3DyjKUSR2SOp5e+ft2mJY/I1I7waMkiUrO4HW78/f3JyXEO8vv6669dp37Xr1/fdZq1O4YNG0ZGRgZTpkwhLS2Nzp07s3z5ciIinP/5paSkYC5yIa0jR44wbtw40tLSqFevHl27dmX16tWuwCUiFchhd174LrXI+Ji0TZCbWXJdkxkatCp+RCayg/MCeSIiHuR2uLn00ktJSEigd+/erFu3jkWLFgHw119/lXq2UnnEx8eX2Q21cuXKYtMvvPACL7zwwjm9joiUIXUTZGwpnLbbYNMHkLIa7Pkl1zf7QXi7wi6lqE7Oey7569RrEfE+t8PNyy+/zD333MOHH37IK6+8QnR0NABffPEFAwYMqPACRcQDlk+C3f9X/vUbXwxjlldePSIi58HtcNOkSRM+//zzEvN1NEWkGhvwtPPIzZFdsGYO5B51Xjem21iIbO/scioqrK03qhQRKRe3w82GDRuwWq106NABcN52YcGCBbRr145p06bh7191rj8hIuUU1REO/gU/PA8FudCwNQx/33kqtohINeP2LW///ve/89dffwGwY8cO/va3vxEcHMzixYt58MEHK7xAEalkDgckPQ4fjXUGm1b94c6vFWxEpNpyO9z89ddfdO7cGYDFixfTp08fFi5cyJtvvslHH31U0fWJSGXKOwaLRjiP2AD0nug8YhNYx7t1iYicB7e7pQzDwOFwAM5TwQcNGgTgul+TiFQTh3fCe8Mh40+wBMB1L0GnYd6uSkTkvLkdbrp168aTTz5J3759+e6773jllVcA58X9Tl2bRkSquJ3fwwcjnbdHCImEvy2Exl29XZWISIVwu1tq9uzZbNiwgfj4eB555BFatmwJwIcffsgll1xS4QWKSAVb9zq8PcQZbBp1gbu+VbAREZ/i9pGbjh07snnz5hLzn332WSwW3eBOpMqy2+CLB+Hn+c7pDjc7u6KsQd6tS0SkgrkdbsoSGBhYUbsSkYqWfcjZDbV7FWCCvlOh9726UaWI+CS3w43dbueFF17ggw8+ICUlhfz84pdmP3z4cIUVJyIVIO03eH+48w7d/rXhxjegja4mLiK+y+0xN9OnT2fWrFkMGzaMzMxMEhISuOGGGzCbzUybNq0SShSRc/bn5zCvvzPY1GvmvH6Ngo2I+Di3w81///tfXn/9de6//378/PwYPnw4b7zxBlOmTOHHH3+sjBpFxF2GgXnV885r2NiyodnlMO4bCNdtE0TE97kdbtLS0ly3XggJCSEzMxOAQYMGsXTp0oqtTkTcZ8uh2645WL5LdE53/zvc9hEE1/duXSIiHuJ2uGncuDGpqakAtGjRgq+++gqAn376iYCAgIqtTkTck7kXv7euJfroOgyzFQb/GwY+AxartysTEfEYt8PN0KFDSUpKAuAf//gHjz32GK1atWLkyJGMGTOmwgsUkXJKWQuvXYkpfTN5frWxj/gYut7h7apERDzO7bOlnn76adfzYcOG0aRJE9asWUOrVq0YPHhwhRYnIuX0y7vw+X1gz8cIv5DvwsZyZZNe3q5KRMQrzvs6N7169aJXL/0nKuIV9gJYMQV+nOOcvmAwBYNe4sTX33u3LhERLypXuPnss8/KvcPrrrvunIsRETecOAIfjoHt3zinL58Elz8Edrt36xIR8bJyhZshQ4aUa2cmkwm7/mMVqXwHt8J7f4ND28AaDENegQuHOJfp36CI1HDlCjcOh6Oy6xCR8tr6tfOITV4m1Ilx3tE7qqO3qxIRqTIq7N5SIlLJDAPWvOwcY2M4oEkvuOUdCAnzdmUiIlVKuU8F/+abb2jXrh1ZWVkllmVmZnLhhRfy/fcaxChSKWy58Ok98NWjzmBz0e0w8jMFGxGRUpQ73MyePZtx48YRGhpaYlmdOnX4+9//zgsvvFChxYkIcCwN3hoEvy4EkwWueQauewn8/L1dmYhIlVTucPPrr78yYEDZN9zr378/69evr5CiROSkfRvgtSth708QWNd5G4UefweTyduViYhUWeUec5Oeno7VWvYl3P38/MjIyKiQokQE2PwhLJkABbnQsA0Mfw8atPB2VSIiVV65j9xER0fz22+/lbl806ZNREVFVUhRIjWawwFJj8NHY53BplUc3LlCwUZEpJzKHW4GDhzIY489Rm5ubollJ06cYOrUqQwaNKhCixOpcfKOwaIR8MPzzuneE51HbALreLcuEZFqpNzdUo8++igff/wxrVu3Jj4+njZt2gCwZcsW5syZg91u55FHHqm0QkV83uGd8N5wyPgTLAHOQcOdhnm7KhGRaqfc4SYiIoLVq1czfvx4Jk+ejGEYgPOqxHFxccyZM4eIiIhKK1TEp+38Hj4Y6bylQkik88J8jbt6uyoRkWrJrYv4NW3alGXLlnHkyBG2bduGYRi0atWKevXqVVZ9Ir5v3evwxUNg2KFRF2ewCdX4NRGRc1XuMTdF1atXj4svvpju3btXSLCZM2cOsbGxBAYG0qNHD9atW1eu7d5//31MJlO5730lUqUU5MPn98GyB5zBpsMtMHqZgo2IyHk6p3BTkRYtWkRCQgJTp05lw4YNdOrUibi4OA4cOHDG7Xbt2sUDDzzAZZdd5qFKRSpQ9iF4Zyj8PB8wQd/pcMNrYA3ydmUiItWe18PNrFmzGDduHKNHj6Zdu3bMnTuX4OBg5s+fX+Y2drudESNGMH36dJo3b+7BakUqQNpv8PoVsHsV+NeGWxfBpffqwnwiIhXEqzfOzM/PZ/369UyePNk1z2w207dvX9asWVPmdo8//jjh4eGMHTuWH3744YyvkZeXR15enmv61L2xbDYbNpvN9bzoT6kcamcwJS/DsmQ8Jls2Rr1mFNz8LoS1gQpsE7WzZ6idPUdt7RlVvZ3dqcur4ebgwYPY7fYSZ1lFRESwZcuWUrdZtWoV8+bNY+PGjeV6jcTERKZPn15i/ldffUVwcHCxeStWrChf4XJeamQ7Gwat0z/jgtSPAMgIacdPjeOx/bQd2F4pL1kj29kL1M6eo7b2jKrazjk5OeVe16vhxl3Hjh3j9ttv5/XXX6dhw4bl2mby5MkkJCS4prOysoiJiaF///6um4DabDZWrFhBv379zniLCTk/NbadbTlY/vcPzKlLALB3G0fdfk/Qz1w5//xqbDt7mNrZc9TWnlHV2/lUz0t5eDXcNGzYEIvFQnp6erH56enpREZGllh/+/bt7Nq1i8GDB7vmORwOwHlvq+TkZFq0KH6J+oCAAAICAkrsy2q1lvjllTZPKl6NaufMvc4L86VtArMVrn0OS9c7sHjgpWtUO3uR2tlz1NaeUVXb2Z2avDqg2N/fn65du5KUlOSa53A4SEpKolevXiXWb9u2LZs3b2bjxo2ux3XXXceVV17Jxo0biYmJ8WT5ImeWshZeu8IZbIIbwqjPoOsd3q5KRMTneb1bKiEhgVGjRtGtWze6d+/O7Nmzyc7OZvTo0QCMHDmS6OhoEhMTCQwMpH379sW2r1u3LkCJ+SJe9cu7zmvY2PMhogMMXwh1m3i7KhGRGsHr4WbYsGFkZGQwZcoU0tLS6Ny5M8uXL3cNMk5JScFs9voZ6yLlYy+AFVPgxznO6QuugyGvQECId+sSEalBvB5uAOLj44mPjy912cqVK8+47ZtvvlnxBYmcixNH4MMxsP0b5/QVk6HPg6BwLiLiUVUi3IhUewe3wnt/g0PbwBoMQ+dCu+u9XZWISI2kcCNyvraugA/HQl4m1Ilx3vgyqqO3qxIRqbEUbkTOlWHAmpedY2wMBzTpBbe8AyFh3q5MRKRGU7gRORe2XOfZUL8udE53GQkDnwc/f+/WJSIiCjcibjuWBotug70/gckCAxKh+1268aWISBWhcCPijn0b4P0RcGw/BNaFm9+EFld6uyoRESlC4UakvDZ/CEsmQEEuNGwDw9+DBi3Ovp2IiHiUwo3I2Tgc8O2T8MPzzulWcXDj6xBYx7t1iYhIqRRuRM4kNws+vgv++sI53fteuHoKmD1x60sRETkXCjciZTm803lH74w/wRIA178MHW/xdlUiInIWCjcipdn5PXww0nlLhZBI54X5Gnf1dlUiIlIOCjciRRkG/PQGfPEQGHZo1MUZbEKjvF2ZiIiUk8KNyCkF+fDFg7B+gXO6wy1w3YtgDfJuXSIi4haFGxGA7IPwwSjYvQowQd9p0HuiLswnIlINKdyIpP0G7w+HoyngXxtumget47xdlYiInCOFG6nZ/vwffPx3sGVDvWZw6yIIa+PtqkRE5Dwo3EjNZBjw/XPOi/MBNLvceSuF4PpeLUtERM6fwo3UPPnZ8Ok98Menzuked0P/p8Cifw4iIr5A/5tLzXJ0D7x/K6RtArMVrn0euo7ydlUiIlKBFG6k5khZC4tGQHYGBDeEYe9A00u8XZWIiFQwhRupGTa8A5/fBw4bRHSA4QuhbhNvVyUiIpVA4UZ8m70AVjwGP/7HOX3BdTB0LvjX8m5dIiJSaRRuxHedOAIfjoHt3zinr5gMfR4Es9m7dYmISKVSuBHflPEXvPc3OLwdrMHOozXtrvd2VSIi4gEKN+J7tq5wHrHJy4I6MTD8PYjs4O2qRETEQxRuxHcYBqx5GVZMAcMBTXrBLe9ASJi3KxMREQ9SuBHfYMuFz++FX99zTncZCQOfBz9/r5YlIiKep3Aj1d+xNHh/BOz7GUwWGJAI3e/SHb1FRGoohRup3vZtcAabY/shsK7z/lAtrvR2VSIi4kUKN1J9bf4QlkyAglxo2MY5cLhBC29XJSIiXqZwI9WPwwHfPAGrZjmnW8XBjW9AYKh36xIRkSqhSlzNbM6cOcTGxhIYGEiPHj1Yt25dmet+/PHHdOvWjbp161KrVi06d+7MO++848FqxaNSN8GmDwofPy+A164oDDatB0D7G+Cv5c7lqZu8Wq6IiHif14/cLFq0iISEBObOnUuPHj2YPXs2cXFxJCcnEx4eXmL9+vXr88gjj9C2bVv8/f35/PPPGT16NOHh4cTFxXnhHUilWj4Jdv9f2cv/Wu58nNK0N4xeVvl1iYhIleX1cDNr1izGjRvH6NGjAZg7dy5Lly5l/vz5TJo0qcT6V1xxRbHpiRMn8tZbb7Fq1SqFG1804Gk48Cfs/A42LQJHgfOO3j3uhnpNS64f1tbzNYqISJXi1XCTn5/P+vXrmTx5smue2Wymb9++rFmz5qzbG4bBN998Q3JyMjNnzix1nby8PPLy8lzTWVlZANhsNmw2m+t50Z9SOc6pnUNjsKyajfn3jwBwtB6IffBLEFjnTC90PmVWe/o8e4ba2XPU1p5R1dvZnbq8Gm4OHjyI3W4nIiKi2PyIiAi2bNlS5naZmZlER0eTl5eHxWLhP//5D/369St13cTERKZPn15i/ldffUVwcHCxeStWrDiHdyHuKm871z6xl4t3vkTtvFQcmPmj0TC2Bw+Ab87QTSUu+jx7htrZc9TWnlFV2zknJ6fc63q9W+pc1K5dm40bN3L8+HGSkpJISEigefPmJbqsACZPnkxCQoJrOisri5iYGPr3709oqPPsGpvNxooVK+jXrx9Wq9VTb6PGcaedTZs/wPLFk5hsORi1o3AMfYM2MT1o46FaqzN9nj1D7ew5amvPqOrtfKrnpTy8Gm4aNmyIxWIhPT292Pz09HQiIyPL3M5sNtOyZUsAOnfuzJ9//kliYmKp4SYgIICAgIAS861Wa4lfXmnzpOKdsZ1tufDFg7DhLed08ysx3fgGfrUaeq5AH6HPs2eonT1Hbe0ZVbWd3anJq6eC+/v707VrV5KSklzzHA4HSUlJ9OrVq9z7cTgcxcbVSDV1eAfM63sy2Jjgislw20egYCMiIm7werdUQkICo0aNolu3bnTv3p3Zs2eTnZ3tOntq5MiRREdHk5iYCDjH0HTr1o0WLVqQl5fHsmXLeOedd3jllVe8+TbkfP3xmfNqw3lZENzAeVG+Fld5uyoREamGvB5uhg0bRkZGBlOmTCEtLY3OnTuzfPly1yDjlJQUzObCA0zZ2dncc8897N27l6CgINq2bcu7777LsGHDvPUW5HzYbbBiKvw4xzkd0xNuXgChjbxbl4iIVFteDzcA8fHxxMfHl7ps5cqVxaaffPJJnnzySQ9UJZUucy8sHg17T16R+pJ/wNVTwVL1+npFRKT6qBLhRmqgbV/DR+PgxGEIqANDX4G213q7KhER8QEKN+JZhgPzd4kn7w1lQFQnuPktqN/M25WJiIiPULgRz8nO4JJtz2A5/odzutsYiEsEa6B36xIREZ+icCOesXs1fovvIOx4Ooa1FqbB/4aON3u7KhER8UEKN1K5HA5Y/SIkPY7JsJMVGE3QqMVYoy70dmUiIuKjFG6k8pw4Ap+Mh7++AMDR/ma+N/cnrmFrLxcmIiK+zKtXKBYftm8DvNrHGWwsATBoNvbr/oPdUvJWGCIiIhVJR26kYhkG/PQGfPkw2POhXqzzbKhGncGN29WLiIicK4UbqTh5x+B/E+G3j5zTbQfB9XMgqK5XyxIRkZpF4UYqRvof8MFIOLQVzH7Qdzr0mgAmk7crExGRGkbhRs7fxvfg8/ug4ATUbuS8N1STnt6uSkREaiiFGzl3thPwxYOw4W3ndIur4IbXoVZD79YlIiI1msKNnJtD22HxKEjbDJjgisnQ5wEwW7xdmYiI1HAKN+K+P5bApxMg/xgEN4Qb34AWV3q7KhEREUDhRtxRkA9fT4Uf/+OcbtILbpoPoY28W5eIiEgRCjdSPpl7YfEdsPcn5/Ql/4Srp4DF6tWyRERETqdwI2e39Wv4eBycOAyBdWDIXGg70NtViYiIlErhRsrmsMPKRPj+OcCAqM5wy1vOqw6LiIhUUQo3UrrjB+CjsbDze+d0t7EQNwOsgd6tS0RE5CwUbqSkXf8HH46B42lgrQWD/w0db/Z2VSIiIuWicCOFHA5Y/W9IegIMO4RdALe8DWGtvV2ZiIhIuSnciFPOYfh0PPy13Dnd8W8waBb41/JuXSIiIm5SuBHYtx4+uAMyU8ASAAOfgS6jdNNLEfEKh8NBfn6+a9pms+Hn50dubi52u92Llfm2qtDO/v7+mM3m896Pwk1NZhiw7nX48mFw2KBeM+fZUFGdvF2ZiNRQ+fn57Ny5E4fD4ZpnGAaRkZHs2bMHk/7oqjRVoZ3NZjPNmjXD39//vPajcFNT5R2Dz/4Jv3/snG47CIb8x3kdGxERLzAMg9TUVCwWCzExMa6/4B0OB8ePHyckJKRC/qqX0nm7nR0OB/v37yc1NZUmTZqcV8BSuKmJ0n+HD0bCoW1g9oN+j0PPe9QNJSJeVVBQQE5ODo0aNSI4ONg1/1Q3VWBgoMJNJaoK7RwWFsb+/fspKCjAaj33K+Ar3NQ0GxfC5wlQcAJCo+GmBdCkh7erEhFxjfNwt0viQFYuB47llXv98NoBhIfqml1V0anfvd1uV7iRcrCdgGX/gl/ecU63uBpueB1qNfBuXSIip3G3O+K/a1P4d9LWcq8/8epW3NdPl7ioiipqrI/CTU1waDt8MArSN4PJDFc8DJfdDzq8KyI+YESPJvRrF+GazrXZuWnuGgA+vLsXgVZLsfXDawd4tD7xPIUbX/fHEvh0AuQfg1phcOM8aH65t6sSEakw4aGBxbqZcvILXM/bNQol2F9fdTWN/nT3VQX58MUk58Dh/GPQ5BL4+w8KNiIiUmHmzZtH//79y7Xu3LlzGTx4cCVX5FQlws2cOXOIjY0lMDCQHj16sG7dujLXff3117nsssuoV68e9erVo2/fvmdcv0Y6ugcWXANrX3FO974XRv0PQqO8WpaIiC/KyMhg/PjxNGnShICAACIjI4mLi+P//u//vF1aqWJjYzGZTJhMJoKDg+nQoQNvvPGG2/vJzc3lscceY+rUqeVaf8yYMWzYsIEffvjB7ddyl9eP1S1atIiEhATmzp1Ljx49mD17NnFxcSQnJxMeHl5i/ZUrVzJ8+HAuueQSAgMDmTlzJv379+f3338nOjraC++gitm6Aj4eByeOOK9ZM/RVaHONt6sSEXGbYRicsNlxOBycyLfjl19QrlOUi3ZLFX3ujiCrpdyDW2+88Uby8/N56623aN68Oenp6SQlJXHo0KFzem1PePzxxxk3bhw5OTksXryYcePGERUVRe/evcu9jw8//JDQ0NByb+Pv78+tt97Kiy++yGWXXXaupZeL18PNrFmzGDduHKNHjwach62WLl3K/PnzmTRpUon1//vf/xabfuONN/joo49ISkpi5MiRHqm5SrIXwMoZ8MPzzulGF8HNb0K9WG9WJSJyzk7Y7LSb8uV57aPbk0nntN0fj8eVa6zO0aNH+eGHH1i5ciWXX+7s9m/atCndu3cvtt6sWbNYsGABO3bsoH79+gwePJhnnnmGkJAQAN58803uvfde3n33Xe6//3727NnDwIEDefvtt1m8eDFTp04lMzOT22+/nRdeeAGLxTlIOi8vj0ceeYT33nuPo0eP0r59e2bOnMkVV1xxxrpr165NZGQkAA899BDPPPMMX3/9tSuojBkzhp9//pmffvqJgIAA8vPz6dGjBx06dODtt98G4P333y/RzbRy5UoefPBBfv/9d6xWKxdeeCELFy6kadOmAAwePJh+/fpx4sQJgoKCztq+58qr4SY/P5/169czefJk1zyz2Uzfvn1Zs2ZNufaRk5ODzWajfv36pS7Py8sjL6/w+gdZWVmA8x4aNpvN9bzoz2rneDqWT+/CvNt5CNTedQyOvk+AXwBUofdU7du5mlA7e4baueLZbDYMw8DhcLge3lLe1w8ODiYkJIRPPvmE7t27ExBQ+plYJpOJ2bNn06xZM3bs2EF8fDz/+te/mDNnjuv1cnJy+Pe//83ChQs5duwYN910E0OGDKFu3bp8/vnn7Nixg5tvvplevXoxbNgwACZMmMCff/7JwoULadSoEZ9++ikDBgzg119/pVWrVmXWXbSdP/nkE44cOeK6roxhGMyePZuLLrqIhx56iFmzZvHwww9z9OhRXnzxRVe7rFq1ihEjRrimCwoKGDJkCHfeeSf//e9/yc/PZ926da7XAujSpQsFBQWsWbOm1ADmcDgwDAObzeYKcKe482/NZBiGUe61K9j+/fuJjo5m9erV9OrVyzX/wQcf5LvvvmPt2rVn3cc999zDl19+ye+//05gYMmLMk2bNo3p06eXmL9w4cJiV8Csrhoc20K3XXMILMikwBzAxiZj2Vevp7fLEhFxm5+fH5GRkcTExODv749hGOTa3A84J2x2rnrpJwC++cfFBJ12Knh5BFrN5e6W+uyzz5g4cSK5ubl07NiR3r17c8MNN9C+ffsyt1myZAkJCQls374dcH4nTZgwgQ0bNtCsWTMA7rvvPj744AOSk5NdR3huuukmYmJieOGFF9izZw8XXXQRmzdvJiqqcEzlkCFD6NKlC1OmTCn1tTt27Eh6ejpWq5W8vDwKCgqoV68eX3/9Nc2bN3ett27dOgYNGsS9997LCy+8wGeffeb6rs7MzCQ2NpalS5dyySWXAHDkyBGaN2/O559/fsauqmbNmjFjxgyGDx9eYll+fj579uwhLS2NgoLiXYo5OTnceuutZGZmEhoaWub+oQp0S52Pp59+mvfff5+VK1eWGmwAJk+eTEJCgms6KyuLmJgY+vfv72ocm83GihUr6Nev33ldEdGjDAfm1S9i3vg0JsOBEdYW44YFdGrYiqp628tq2c7VkNrZM9TOFS83N5c9e/YQEhLi+j+9Ds4jCceOHaN27drlChxFx9mEN6hb6aeC33bbbdx000388MMPrF27luXLl/Piiy/y2muvcccddwDw9ddfM3PmTLZs2UJWVhYFBQXk5ubi5+dHcHAwgYGBBAcH06lT4f/gMTExxMbG0qhRI9e8Ro0acfToUUJDQ9m1axd2u52LL764WD15eXmEh4eXGQDMZjMPPPAAo0aNIjU1lYceeoi7776bTp06FWvnvn37cv/99/P000/z4IMPEhcX59pHdnY2AA0aNHC9TmhoKKNGjeLGG2+kb9++9O3bl5tvvrlY8ALn0S6Hw1Fqfbm5uQQFBdGnT58S3+unel7Kw6vhpmHDhlgsFtLT04vNT09Pd/UFluW5557j6aef5uuvv6Zjx45lrhcQEFDqYUKr1VriP6TS5lVJOYfhk7th68m+6E7DMV37PFb/Wt6tq5yqTTtXc2pnz1A7Vxy73Y7JZMJsNhcbOHyqS+PUsrMpus7p+6oswcHBxMXFERcXx5QpU7jzzjuZPn06Y8aMYdeuXVx33XWMHz+ep556ivr167Nq1SrGjh1LQUGBq0ar1Vqi9tLmGYaB2WwmJycHi8XC+vXrS3ThnO3ml2FhYbRu3ZrWrVuzePFiOnToQLdu3WjcuLGrnR0OB6tXr8ZisbB9+/Zi+wsLC8NkMpGZmVls/ptvvsnEiRNZvnw5H3zwAY899hgrVqygZ8/CHoXDhw8TERFRan1ms/OIWVnf0eXl1VPB/f396dq1K0lJhQO+HA4HSUlJxbqpTvfMM8/wxBNPsHz5crp16+aJUquOvevh1cudwcYvEK57CYa8AtUk2IiI1ATt2rVzHd1Yv349DoeD559/np49e9K6dWv2799/3q9x0UUXYbfbOXDgAC1btiz2ONsBgqJiYmIYNmwYDz/8cLH5zz77LFu2bOG7775j+fLlLFiwwLXM39+fdu3a8ccff5Ra1+TJk1m9ejXt27dn4cKFrmXbt28nNzeXiy666Bzecfl5/To3CQkJvP7667z11lv8+eefjB8/nuzsbNfZUyNHjiw24HjmzJk89thjzJ8/n9jYWNLS0khLS+P48ePeegueYRiw9jWYHweZKVC/Odz5NXQZqbt5i4h4yaFDh7jqqqt499132bRpEzt37mTx4sU888wzXH/99QC0bNkSm83GSy+9xI4dO3jnnXeYO3fueb9269atGTFiBCNHjuTjjz9m586drFu3jsTERJYuXerWviZOnMjnn3/OL7/8AsAvv/zClClTeOONN+jduzezZs1i4sSJ7Nixw7VNXFwcq1atck3v3LmTyZMns2bNGnbv3s1XX33F1q1bueCCC1zr/PDDDzRv3pwWLVqc57s/M6+PuRk2bBgZGRlMmTKFtLQ0OnfuzPLly4mIcN4nJCUlpdihq1deeYX8/HxuuummYvuZOnUq06ZN82TpnpObBf/7J/z+iXP6guvg+ped17EREanhTr8reK7N7nr+x/6sUu8tVVF3BQ8JCaFHjx688MILbN++HZvNRkxMDOPGjXMdCenUqROzZs1i5syZTJ48mT59+pCYmFghly9ZsGABTz75JPfffz/79u2jYcOG9OzZk0GDBrm1n3bt2tGvXz9mzJhBjx49uO2227jjjjtcp3rfddddLF26lNtvv53vv/8ei8XC2LFj6datG5mZmdSpU4fg4GC2bNnCW2+9xaFDh4iKimLChAn8/e9/d73Oe++9x7hx4877fZ+NV8+W8oasrCzq1KlTbLS1zWZj2bJlDBw4sOr1naf95ryFwuHtYPaD/k9Cj7ur5dGaKt3OPkTt7Blq54qXm5vLzp07adasWbHBpA6Hg6ysLEJDQ0sdp/HCir90V/AKcLZ2Ls3NN99Mly5divWwlOX333/nqquu4q+//qJOndL/OC/rMwClf3+XxetHbuQMfnkXlt4PBbkQ2th5Ub6Yi8+6mYhITXL6XcHPRncFrzjPPvss//vf/8q1bmpqKm+//XaZwaYiKdxURfk5sOxfsPFd53TLvjD0NajVwLt1iYhUQaffFVw8JzY2ln/84x/lWrdv376VXE0hhZuq5uA2ZzfUgd/BZIYrH4ZL7wcPnMooIiLiCxRuqpLfP4El/4D8Y1ArDG6cB80v93ZVIiIi1YrCTVVQkA9fPQrrXnVON+3tDDahUWfeTkREREpQuPG2oymw+A7Yt945fel9cOWjYNGvRkSkXI6lOR/lVTvS+RCfpW9Qb/rrK/jkLjhxBALrwtBXoc0Ab1clIlK9/LwAvnu6/OtfPgmuPPupy1J9Kdx4g70Avn0KVs1yTjfq4jzNu15Tr5YlIlItdRsNba4pnC44AfNP/qE4Zjn4BRVfX0dtfJ5OwfG0Y2nwzpDCYNP9Luc/PgUbEZFzUzsSGnUufEQWuZlyZMfiyxp19mq4MZlMfPrpp67pLVu20LNnTwIDA+ncuXOZ88Q9CjeetPMHmHsZ7PoB/EPgpvkw8Fnw0wWlRESqqzvuuAOTyeS6m3VERAT9+vVj/vz5rjuan5Kamso11xQeZZo6dSq1atUiOTnZdRPp0uadycqVK12vbzKZCAsLY+DAgWzevLli32g1onDjCQ4HfP8cvH0dZB+A8HZw10pof6O3KxMRkQowYMAAUlNT2bVrF1988QVXXnklEydOZNCgQRQUFLjWi4yMJCCg8A/a7du3c+mll9K0aVMaNGhQ5rzySE5OJjU1lS+//JK8vDyuvfZa8vPzK+5NViMKN5Ut5zC8Nwy+eQIMB3QeAXcmQcNW3q5MRKRqMwzIz3Y+bDmFz8/6yCncR7472xV5uHnbxYCAACIjI4mOjqZLly48/PDDLFmyhC+++II333zTtV7RbimTycT69et5/PHHMZlMTJs2rdR55RUeHk5kZCRdunTh3nvvZc+ePWzZsgWAjIwMIiMjmTFjhmv91atX4+/vX66jQ9WNBhRXpr0/O0/zztwDfoEw8Dnocru3qxIRqR5sOTCjEWag7rnu47mW57bdw/vBv9a5vioAV111FZ06deLjjz/mzjvvLLE8NTWVvn37MmDAAB544AFCQkK4++67S8xzV2ZmJu+//z4A/v7+AISFhTF//nyGDBlC//79adOmDbfffjvx8fFcffXV5/U+qyKFm8pgGLD2VeeF+Rw2qN8cbnkbIjt4uzIREfGgtm3bsmnTplKXRUZG4ufnR0hICJGRzkHOISEhJeaVV+PGjQHIzs4G4LrrrqNt27au5QMHDmTcuHGMGDGCbt26UatWLRITE8/lbVV5CjcVLTcLPvsH/PGpc7rd9XDdyxB45tuzi4jIaazB8PB+HA4HWceOEVq7Nuby3GcvP6fwiM0D28A/+NxeuwIYhoHJZKqQfZ3NDz/8QHBwMD/++CMzZsxg7ty5JdZ57rnnaN++PYsXL2b9+vXFxv/4EoWbipT2m/Oml4e3g9kK/Z+EHn8HD32wRUR8isnk7BpyOMBqdz539ybC/sHn3b10Pv7880+aNWvmkddq1qwZdevWpU2bNhw4cIBhw4bx/fffF1tn+/bt7N/vDIy7du2iQwff7FFQuDlXqZsgY0vh9P6NsO41ZzdUUH1nqAmuD5sXO5eHtYWojqXuSkREfM8333zD5s2bue+++zz+2hMmTCAxMZFPPvmEoUOHApCfn89tt93GsGHDaNOmDXfeeSebN28mPDzc4/VVNoWbc7V8Euz+v9KXnTgMK0/rx2zaG0Yvq/y6RETE4/Ly8khLS8Nut5Oens7y5ctJTExk0KBBjBw58rz2ffXVVzN06FDi4+PLvU1wcDDjxo1j6tSpDBkyBJPJxCOPPEJmZiYvvvgiISEhLFu2jDFjxvD555+fV31VkcLNuRrwdPEjN+C8+nBIOJhKOWwa1rbkPBER8QnLly8nKioKPz8/6tWrR6dOnXjxxRcZNWpU+cYJncH27ds5ePCg29vFx8cza9YsFi9eTHh4OLNnz+bbb78lNNQ5BvSdd96hU6dOvPLKK4wfP/68aqxqFG7OVVRHdTOJiFQFp98VvOBE4fO0TaXfW6oCb8Hw5ptvFruWzZkYp10/Z+PGjSXWOX3erl27zrjPK664osR+AWJiYrDZbK7pos8BYmNjyczMPHPB1ZTCjYiIVG9nuiv4qRtoFqW7gvs8hRsREaneTr8r+NnoruA+T+FGRESqtwruZpLqT/eWEhEREZ+icCMiIlVKaYNjpWaoqN+9wo2IiFQJFosFcF5sTmqmU7/7U5+Fc6UxNyIiUiX4+fkRHBxMRkYGVqvVdX0Yh8NBfn4+ubm5533NGCmbt9vZ4XCQkZFBcHAwfn7nF08UbkREpEowmUxERUWxc+dOdu/e7ZpvGAYnTpwgKCjIYzehrImqQjubzWaaNGly3q+vcCMiIlWGv78/rVq1KtY1ZbPZ+P777+nTpw9Wq9WL1fm2qtDO/v7+FXLUSOFGRESqFLPZTGBgoGvaYrFQUFBAYGCgwk0l8qV2VueliIiI+BSFGxEREfEpCjciIiLiU2rcmJtTFwjKyspyzbPZbOTk5JCVlVXt+xmrMrWzZ6idPUPt7Dlqa8+o6u186nu7PBf6q3Hh5tixY4DzVvAiIiJSvRw7dow6deqccR2TUcOuc+1wONi/fz+1a9d2nUeflZVFTEwMe/bsITQ01MsV+i61s2eonT1D7ew5amvPqOrtbBgGx44do1GjRmc9XbzGHbkxm800bty41GWhoaFV8hfqa9TOnqF29gy1s+eorT2jKrfz2Y7YnKIBxSIiIuJTFG5ERETEpyjcAAEBAUydOpWAgABvl+LT1M6eoXb2DLWz56itPcOX2rnGDSgWERER36YjNyIiIuJTFG5ERETEpyjciIiIiE9RuBERERGfUuPDzZw5c4iNjSUwMJAePXqwbt06b5fkc6ZNm4bJZCr2aNu2rbfLqva+//57Bg8eTKNGjTCZTHz66afFlhuGwZQpU4iKiiIoKIi+ffuydetW7xRbjZ2tne+4444Sn+8BAwZ4p9hqLDExkYsvvpjatWsTHh7OkCFDSE5OLrZObm4uEyZMoEGDBoSEhHDjjTeSnp7upYqrp/K08xVXXFHiM3333Xd7qeJzU6PDzaJFi0hISGDq1Kls2LCBTp06ERcXx4EDB7xdms+58MILSU1NdT1WrVrl7ZKqvezsbDp16sScOXNKXf7MM8/w4osvMnfuXNauXUutWrWIi4sjNzfXw5VWb2drZ4ABAwYU+3y/9957HqzQN3z33XdMmDCBH3/8kRUrVmCz2ejfvz/Z2dmude677z7+97//sXjxYr777jv279/PDTfc4MWqq5/ytDPAuHHjin2mn3nmGS9VfI6MGqx79+7GhAkTXNN2u91o1KiRkZiY6MWqfM/UqVONTp06ebsMnwYYn3zyiWva4XAYkZGRxrPPPuuad/ToUSMgIMB47733vFChbzi9nQ3DMEaNGmVcf/31XqnHlx04cMAAjO+++84wDOfn12q1GosXL3at8+effxqAsWbNGm+VWe2d3s6GYRiXX365MXHiRO8VVQFq7JGb/Px81q9fT9++fV3zzGYzffv2Zc2aNV6szDdt3bqVRo0a0bx5c0aMGEFKSoq3S/JpO3fuJC0trdjnu06dOvTo0UOf70qwcuVKwsPDadOmDePHj+fQoUPeLqnay8zMBKB+/foArF+/HpvNVuwz3bZtW5o0aaLP9Hk4vZ1P+e9//0vDhg1p3749kydPJicnxxvlnbMad+PMUw4ePIjdbiciIqLY/IiICLZs2eKlqnxTjx49ePPNN2nTpg2pqalMnz6dyy67jN9++43atWt7uzyflJaWBlDq5/vUMqkYAwYM4IYbbqBZs2Zs376dhx9+mGuuuYY1a9ZgsVi8XV615HA4uPfee+nduzft27cHnJ9pf39/6tatW2xdfabPXWntDHDrrbfStGlTGjVqxKZNm3jooYdITk7m448/9mK17qmx4UY855prrnE979ixIz169KBp06Z88MEHjB071ouViZy/v/3tb67nHTp0oGPHjrRo0YKVK1dy9dVXe7Gy6mvChAn89ttvGptXycpq57vuusv1vEOHDkRFRXH11Vezfft2WrRo4ekyz0mN7ZZq2LAhFoulxEj79PR0IiMjvVRVzVC3bl1at27Ntm3bvF2Kzzr1Gdbn2/OaN29Ow4YN9fk+R/Hx8Xz++ed8++23NG7c2DU/MjKS/Px8jh49Wmx9fabPTVntXJoePXoAVKvPdI0NN/7+/nTt2pWkpCTXPIfDQVJSEr169fJiZb7v+PHjbN++naioKG+X4rOaNWtGZGRksc93VlYWa9eu1ee7ku3du5dDhw7p8+0mwzCIj4/nk08+4ZtvvqFZs2bFlnft2hWr1VrsM52cnExKSoo+0244WzuXZuPGjQDV6jNdo7ulEhISGDVqFN26daN79+7Mnj2b7OxsRo8e7e3SfMoDDzzA4MGDadq0Kfv372fq1KlYLBaGDx/u7dKqtePHjxf7S2rnzp1s3LiR+vXr06RJE+69916efPJJWrVqRbNmzXjsscdo1KgRQ4YM8V7R1dCZ2rl+/fpMnz6dG2+8kcjISLZv386DDz5Iy5YtiYuL82LV1c+ECRNYuHAhS5YsoXbt2q5xNHXq1CEoKIg6deowduxYEhISqF+/PqGhofzjH/+gV69e9OzZ08vVVx9na+ft27ezcOFCBg4cSIMGDdi0aRP33Xcfffr0oWPHjl6u3g3ePl3L21566SWjSZMmhr+/v9G9e3fjxx9/9HZJPmfYsGFGVFSU4e/vb0RHRxvDhg0ztm3b5u2yqr1vv/3WAEo8Ro0aZRiG83Twxx57zIiIiDACAgKMq6++2khOTvZu0dXQmdo5JyfH6N+/vxEWFmZYrVajadOmxrhx44y0tDRvl13tlNbGgLFgwQLXOidOnDDuueceo169ekZwcLAxdOhQIzU11XtFV0Nna+eUlBSjT58+Rv369Y2AgACjZcuWxr/+9S8jMzPTu4W7yWQYhuHJMCUiIiJSmWrsmBsRERHxTQo3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsR8Tm7du3CZDK57okjIjWLwo2IVIg77rgDk8nE008/XWz+p59+islkKnWblStXYjKZzvhYuXKl27XExMSQmppK+/btz+WtuBStIzQ0lIsvvpglS5ac1z5FpPIp3IhIhQkMDGTmzJkcOXKkXOtfcsklpKamuh633HILAwYMKDbvkksuca2fn59frv1aLBYiIyPx8zv/ewMvWLCA1NRUfv75Z3r37s1NN93E5s2bz3u/IlJ5FG5EpML07duXyMhIEhMTy7W+v78/kZGRrkdQUBABAQGu6blz59K9e3feeOMNmjVrRmBgIADLly/n0ksvpW7dujRo0IBBgwaxfft2135P75Y6dYQoKSmJbt26ERwczCWXXEJycvJZa6xbty6RkZG0bt2aJ554goKCAr799lsADMOgb9++xMXFceo2fYcPH6Zx48ZMmTLFnaYTkQqkcCMiFcZisTBjxgxeeukl9u7dWyH73LZtGx999BEff/yxK6xkZ2eTkJDAzz//TFJSEmazmaFDh+JwOM64r0ceeYTnn3+en3/+GT8/P8aMGVPuOgoKCpg3bx7gDGXg7LZ66623+Omnn3jxxRcBuPvuu4mOjla4EfGi8z9mKyJSxNChQ+ncuTNTp051hYHzkZ+fz9tvv01YWJhr3o033lhsnfnz5xMWFsYff/xxxnE2Tz31FJdffjkAkyZN4tprryU3N9d1RKg0w4cPx2KxcOLECRwOB7Gxsdxyyy2u5dHR0bz66quMHDmStLQ0li1bxi+//FIhXWIicm505EZEKtzMmTN56623+PPPP897X02bNi0WbAC2bt3K8OHDad68OaGhocTGxgKQkpJyxn117NjR9TwqKgqAAwcOnHGbF154gY0bN/LFF1/Qrl073njjDerXr19snZtvvpmhQ4fy9NNP89xzz9GqVavyvj0RqQQKNyJS4fr06UNcXByTJ08+733VqlWrxLzBgwdz+PBhXn/9ddauXcvatWuBsw84tlqtruenzuA6W1dWZGQkLVu2pH///ixYsIBhw4aVCEQ5OTmsX78ei8XC1q1by/W+RKTyKNyISKV4+umn+d///seaNWsqdL+HDh0iOTmZRx99lKuvvpoLLrig3Gdnna/u3bvTtWtXnnrqqWLz77//fsxmM1988QUvvvgi33zzjUfqEZHSKdyISKXo0KEDI0aMcA20rSj16tWjQYMGvPbaa2zbto1vvvmGhISECn2NM7n33nt59dVX2bdvHwBLly5l/vz5/Pe//6Vfv37861//YtSoUR4LXCJSksKNiFSaxx9//KzdPu4ym828//77rF+/nvbt23Pffffx7LPPVuhrnMmAAQNo1qwZTz31FBkZGYwdO5Zp06bRpUsXAKZPn05ERAR33323x2oSkeJMxqmLM4iIiIj4AB25EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKQo3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfMr/A4/b9sokGAY/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/weights /content/drive/MyDrive/resnet/2D"
      ],
      "metadata": {
        "id": "SV6l5yVpJcTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}